# 基于剪枝优化的大模型联邦训练算法设计与实现

## 摘要

## 绪论

### 选题的背景与意义

#### 介绍大模型

【[Report] On the Opportunities and Risks of Foundation Models】

#### 挑战一：训练数据常常不足或不可见

介绍联邦学习【Konecn ˇ y, J.; McMahan, H. B.; Yu, F. X.; Richt ´ arik, P.; ´ Suresh, A. T.; and Bacon, D. 2017. Federated Learning: Strategies for Improving Communication Efficiency. arXiv:1610.05492.  】：个人隐私 在边缘设备上进行机器学习 在大规模边缘设备上分布式机器学习

#### 挑战二：模型过大影响本地训练效率和网络通信效率

上传带宽限制

推理阶段而不是训练阶段

非联邦量化、知识蒸馏、分割学习、预训练对比学习、剪枝

剪枝的优势

#### 挑战三：模型压缩方法如何适应联邦场景：数据隐私

联邦场景中剪枝的优势

#### 挑战四：模型压缩方法如何适应联邦场景：非独立同分布

联邦场景中动态剪枝的优势

基于动态拓扑的自适应剪枝能更好地适应分布在边缘设备上的非独立同分布的数据

#### 挑战五：噪声数据带来的鲁棒性挑战



为了利用大规模的资源受限的边缘设备和非独立同分布的边缘设备数据训练一个大模型，同时考虑模型对噪声数据的鲁棒性

- 将剪枝的思想应用于联邦学习中，资源受限
- 将基于动态拓扑的自适应剪枝算法引入联邦学习的场景中，非独立同分布
- 将基于贡献评估的模型聚合算法引入大模型联邦训练算法中，数据噪声，鲁棒性
- 提高了准确率，同时只需要更少的计算资源和网络通信带宽
- 鲁棒性
- 消融实验：RigL、聚合算法
- 研究了联邦学习中剪枝率对模型训练的影响
- 贡献评估对剪枝率设置的参考作用
- 展示了贡献评估算法的合理性



大模型在性能和泛化能力上具有显著优势，但是大量训练数据的获取是一大挑战，因为训练数据常常不足或不可见，因此常见的解决方法是应用联邦学习的方法通过分布在世界各地的客户端数据和计算能力训练一个全局大模型。在联邦场景下训练大模型的一大挑战是客户端的计算和存储能力受限，因此无法在客户端训练完整的大模型。一种典型的方法是对全局大模型进行剪枝，将剪枝后的小模型发送给客户端进行训练。另外一个挑战是客户端的数据常常是非独立同分布甚至是带有噪声的，若此时为所有的客户端分配相同的剪枝后的小型网络，则会严重影响全局大模型的性能，

本项工作以优化全局大模型的性能为目标，同时考虑边缘设备计算能力和存储能力受限，以及边缘数据非独立同分布甚至是带有数据标签噪声的场景，提出了基于剪枝优化的大模型联邦优化算法。根据调研，提出的联邦学习框架第一次同时解决了上述提到的两个挑战，在最接近现实情况的边缘设备能力受限，且边缘数据非独立同分布和带有数据标签噪声的场景中训练出了性能最好的全局大模型。

联邦学习使边缘设备能够在不透露私有数据的情况下协作地学习模型。大多数现有的联邦学习算法需要在客户端和服务器部署相同架构的模型，然而，由于边缘设备的资源有限，超大规模的模型训练是不切实际的。因此，我们需要在联邦学习中应用剪枝优化等模型压缩的技术，在尽量不损失模型性能的前提下，实现模型计算、存储和通信的优化。另外，**系统异构**是联邦学习中常见的场景，边缘设备的计算和存储能力的差异决定了联邦学习中的剪枝优化方法应尽可能具备动态和自适应的特点。最后，不同设备收集的数据通常是非独立同分布的，因此，基于剪枝优化的联邦学习算法应尽可能具备适应**数据异构**场景的能力。

### 国内外研究现状和相关工作

联邦学习

网络剪枝：彩票假说

联邦量化、知识蒸馏、分割学习、预训练对比学习

联邦剪枝：PruneFL Sub-FedAvg FedDST FedDUAP ZeroFL FedMP

贡献评估：以往考虑公平性更多

现有的基于剪枝优化的联邦学习算法主要围绕剪枝的对象和剪枝的程度进行研究。其中一些工作直接将现有的剪枝方法加入联邦训练的过程，或者预先设定相同的剪枝率，忽视了联邦学习中系统异构的场景。另外一些工作采用了自适应剪枝的方式，为不同的客户端设置不同的剪枝率，虽然这些算法在非独立同分布的数据中有不错的表现，但这些算法的设计回避了，容易造成模型训练的等问题。对基于剪枝优化的联邦学习算法进行研究，使其有效适应系统异构和数据异构的场景，是该研究方向的一个发展趋势。

### 本文的论文结构与相关安排

本文共分为六章，各章节内容安排如下：

第一章绪论。简单说明了本文章的选题背景与意义，总结了国内外研究现状和相关工作。       第二章为基于剪枝优化的大模型联邦训练框架。分为三块介绍了联邦剪枝的训练框架，分别是自适应剪枝模块、本地训练模块和异构模型的聚合模块，其中自适应剪枝模块中的剪枝率决策算法将在第三章中单独介绍。

第三章为剪枝率决策算法。首先对优化的问题进行定义，通过测量实验引入了问题场景和方法中的困难和挑战，例如效率与准确率的权衡、系统异构性和数据价值异构，最后为解决挑战提出剪枝率决策算法。

第四章为实验与结果。对本文提出的模型剪枝算法与FedMP、PruneFL、SynFL、UP-FL、FedProx、FlexCom等基线算法进行比较，比较的指标为测试集准确率和达到指定准确率所需要的训练时间。



## 基于剪枝优化的大模型联邦训练算法

### 大模型联邦训练框架



### 基于动态拓扑的自适应剪枝算法

#### 动态剪枝

彩票

【Do We Actually Need Dense Over-Parameterization? In-Time Over-Parameterization in Sparse Training】



#### 非结构化剪枝

#### 按层剪枝

#### 剪枝标准





### 基于贡献评估的模型聚合算法

贡献的定义



## 实验与结果

## 参考文献

## 附录A

## 致谢

