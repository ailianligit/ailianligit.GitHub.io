# 基于剪枝优化的大模型联邦训练算法设计与实现

## 摘要

## 绪论

### 选题的背景与意义

联邦学习使边缘设备能够在不透露私有数据的情况下协作地学习模型。大多数现有的联邦学习算法需要在客户端和服务器部署相同架构的模型，然而，由于边缘设备的资源有限，超大规模的模型训练是不切实际的。因此，我们需要在联邦学习中应用剪枝优化等模型压缩的技术，在尽量不损失模型性能的前提下，实现模型计算、存储和通信的优化。另外，**系统异构**是联邦学习中常见的场景，边缘设备的计算和存储能力的差异决定了联邦学习中的剪枝优化方法应尽可能具备动态和自适应的特点。最后，不同设备收集的数据通常是非独立同分布的，因此，基于剪枝优化的联邦学习算法应尽可能具备适应**数据异构**场景的能力。

### 国内外研究现状和相关工作

现有的基于剪枝优化的联邦学习算法主要围绕剪枝的对象和剪枝的程度进行研究。其中一些工作直接将现有的剪枝方法加入联邦训练的过程，或者预先设定相同的剪枝率，忽视了联邦学习中系统异构的场景。另外一些工作采用了自适应剪枝的方式，为不同的客户端设置不同的剪枝率，虽然这些算法在非独立同分布的数据中有不错的表现，但这些算法的设计回避了，容易造成模型训练的等问题。对基于剪枝优化的联邦学习算法进行研究，使其有效适应系统异构和数据异构的场景，是该研究方向的一个发展趋势。

### 本文的论文结构与相关安排

本文共分为六章，各章节内容安排如下：

第一章绪论。简单说明了本文章的选题背景与意义，总结了国内外研究现状和相关工作。       第二章为基于剪枝优化的大模型联邦训练框架。分为三块介绍了联邦剪枝的训练框架，分别是自适应剪枝模块、本地训练模块和异构模型的聚合模块，其中自适应剪枝模块中的剪枝率决策算法将在第三章中单独介绍。

第三章为剪枝率决策算法。首先对优化的问题进行定义，通过测量实验引入了问题场景和方法中的困难和挑战，例如效率与准确率的权衡、系统异构性和数据价值异构，最后为解决挑战提出剪枝率决策算法。

第四章为实验与结果。对本文提出的模型剪枝算法与FedMP、PruneFL、SynFL、UP-FL、FedProx、FlexCom等基线算法进行比较，比较的指标为测试集准确率和达到指定准确率所需要的训练时间。



## 实验与结果

## 参考文献

## 附录A

## 致谢

