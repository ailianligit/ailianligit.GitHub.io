# \chapter{基于剪枝优化的大模型联邦训练算法}

## \section{问题及符号定义}

本文提出的大模型联邦训练算法基于联邦学习的框架，利用分布在众多客户端上的本地数据集，以协作的方式训练一个性能良好的联邦模型。在联邦学习的框架中，共有$N$个客户端和一个与所有客户端直接相连的服务器。在每个通信轮次$t=1,2,\cdots,T$，服务器将联邦模型$\theta^t$分发给$N$个客户端。每个客户端$n\in\{1,2,\cdots,N\}$都拥有本地数据集$\mathcal{D}_{n}$，每个迭代轮次$e=1,2,\cdots,E$，客户端$n$利用本地数据集对模型参数进行更新。损失函数（loss function）$f_i(\theta)$表示$\mathcal{D}_{n}$中的特征输入模型后的预测输出和实际输出之间的差距。对于回归任务，损失函数一般为均方误差（mean square error，MSE）。对于分类任务，损失函数一般为交叉熵（cross-entropy）函数。为了导出优化目标，本地经验风险（empirical risk）函数可以表示为$F_n(\theta):=\frac{1}{\left|\mathcal{D}_{n}\right|}\sum_{i\in\mathcal{D}_{n}}f_i(\theta)$，因此，联邦学习优化的目标是全局（联邦）经验风险最小化，在FedAvg算法\cite{mcmahan2017communication}中，聚合的权重表示为$r_n\leftarrow\frac{\left|\mathcal{D}_{n}\right|}{\sum_{n\in\{1,2,\cdots,N\}}\left|\mathcal{D}_{n}\right|}$，而本文将基于贡献评估对这一聚合权重进行改进。联邦学习的目标函数可以表示为：
$$
\min_{\theta}F(\theta)\triangleq\sum_{n=1}^N r_nF_n(\theta)
$$
\begin{equation}
    \label{eq:optimization-goal}
	\min_{\theta}F(\theta)\triangleq\sum_{n=1}^N r_nF_n(\theta)
\end{equation}

为了改进模型的参数使得全局经验风险最小化，常用的方法是随机梯度下降（stochastic gradient descent，SGD）算法。首先，从$\mathcal{D}_{n}$中随机采样小批量数据，然后，基于小批量数据的预测输出和实际输出计算损失函数$f_n(\theta^{t,e}_n)$及其梯度$\nabla f_n(\theta^{t,e}_n)$，最后，基于随机梯度下降对参数进行更新：
$$
\theta^{t,e}_n\leftarrow\theta^{t,e-1}_n-\eta^t\nabla f_n(\theta^{t,e-1}_n)
$$
\begin{equation}
    \label{eq:sgd}
	\theta^{t,e}_n\leftarrow\theta^{t,e-1}_n-\eta^t\nabla f_n(\theta^{t,e-1}_n)
\end{equation}

其中$\eta^t$表示学习率，学习率太大，模型难以收敛，学习率太小，模型收敛慢或根本无法学习。带有动量（momentum）的随机梯度下降使用指数加权平均后的梯度进行参数更新，因为动量带有之前梯度的信息，因此可以加快收敛的速度，同时跳过一些局部的极小值点。此外，随机梯度下降算法中还可以加入权值衰减（weight decay）项，这相当于在目标函数中加上了正则（regularization）项，通过惩罚过大的权值，限制模型的复杂度，防止过拟合现象的发生。

最后，在每个通信轮次$t=1,2,\cdots,T$，服务器需要将客户端训练好的模型聚合起来，融合成为一个全局模型。在FedAvg算法\cite{mcmahan2017communication}中，模型以加权的方式进行聚合：$\theta^{t+1}=\sum_{n=1}^N r_n^t\theta_n^t$。与之稍有不同的是，本文使用参数更新进行聚合，但可以通过简单的推导证明两种聚合方式是等效的，具体的聚合算法将在对应的章节进行阐述。

本文中用到的大部分符号及其含义都在表\ref{tab:superparameters}中列出，与动态剪枝和模型聚合相关的符号的具体含义将在对应的章节进行阐述。



\begin{table}[h] %voc table result
	\centering
	\caption{符号定义}
	\begin{tabular}{*{4}{c}}
		\toprule
        符号 & 定义 & 符号 & 定义\\
        \midrule
        $n$，$N$ & 客户端索引，客户端总数 & $\mathcal{D}_{n}$ & 本地数据集\
        $\alpha$，$\Delta\alpha$ & 剪枝率，逐层剪枝率 & $\eta^t$ & 学习率\\
        $t$，$T$ & 通信轮次，通信总轮数 & $e$，$E$ & 本地迭代轮次，本地迭代总轮数\\
        $\theta^t$，$\theta^{t}_n$ & 联邦模型参数，客户端模型参数 & $\nabla f(\theta^{t,e}_n)$ & 随机梯度\\
        $\Delta\theta^{t}_n$ & 客户端参数更新 & $u_n^t$，$U^t$ & 归一化参数更新，聚合参数更新\\
        $r_n^{t}$ & 客户端重要性分数 & $\gamma$ & 聚合算法权衡系数\\
        $\psi_n^t$ & 客户端余弦梯度夏普利值 & $p^t$ & 剪枝比例系数\\
        $T_{end}$ & 停止动态剪枝的通信轮数 & $\Delta{T}$ & 动态剪枝的间隔通信轮数\\
        \bottomrule
    \end{tabular}
\label{tab:superparameters}
\end{table}

| 符号                       | 定义                         | 符号                         | 定义                         |
| -------------------------- | ---------------------------- | ---------------------------- | ---------------------------- |
| $n$，$N$                   | 客户端索引，客户端总数       | $\mathcal{D}_{n}$            | 本地数据集                   |
| $\alpha$，$\Delta\alpha$   | 剪枝率，逐层剪枝率           | $\eta^t$                     | 学习率                       |
| $t$，$T$                   | 通信轮次，通信总轮数         | $e$，$E$                     | 本地迭代轮次，本地迭代总轮数 |
| $\theta^t$，$\theta^{t}_n$ | 联邦模型参数，客户端模型参数 | $\nabla f_n(\theta^{t,e}_n)$ | 随机梯度                     |
| $\Delta\theta^{t}_n$       | 客户端参数更新               | $u_n^t$，$U^t$               | 归一化参数更新，聚合参数更新 |
| $r_n^{t}$                  | 客户端重要性分数             | $\gamma$                     | 聚合算法权衡系数             |
| $\psi_n^t$                 | 客户端余弦梯度夏普利值       | $p^t$                        | 剪枝比例系数                 |
| $T_{end}$                  | 停止动态剪枝的通信轮数       | $\Delta{T}$                  | 动态剪枝的间隔通信轮数       |

