# 基于剪枝优化的大模型联邦训练算法设计与实现

现有的基于剪枝优化的联邦学习算法主要围绕剪枝的对象和剪枝的程度进行研究。其中一些工作直接将现有的剪枝方法加入联邦训练的过程，或者预先设定剪枝率，忽视了联邦学习中系统异构的场景。另外一些工作采用了自适应剪枝的方式，为不同的客户端设置不同的剪枝率，但仍然回避了数据异构的问题。对基于剪枝优化的联邦学习算法进行研究，使其有效适应**系统异构**和**数据异构**的场景，是该研究方向的一个发展趋势。



### 动机

- 基于**系统异构**的**自适应剪枝**算法会根据边缘设备的计算能力为不同的客户端设置不同的剪枝率，然而，当客户端的数据分布呈现非独立同分布（**non-iid**）的特点时，这样的剪枝率选择方式会造成不公平的现象。假设**数据的分布与边缘设备的计算能力存在相关性**时，某些数据分布的客户端剪枝率会显著高于或低于其他分布的客户端剪枝率，造成全局模型不能很好地学习一些剪枝率过高的数据分布，进而使得**模型准确率**下降。
- 提出疑问及实验验证：
  - 系统异构性对模型准确率和计算时间的影响
  - 数据异构性对模型准确率和计算时间的影响
  - 假设数据的分布与边缘设备的计算能力存在相关性，将边缘设备按照数据分布进行分类，当不同类的边缘设备的剪枝率差距过大（不平衡）时，这时的模型准确率是否会显著低于类间剪枝率平衡的模型准确率
- 目标：模型准确率与计算时间的权衡，尤其是在数据的分布与边缘设备的计算能力存在相关性的情况下



### 联邦剪枝算法框架

- 自适应模型剪枝：

  - 每轮中心服务器根据每个客户端的**计算能力**和**数据分布**来决定特定的剪枝率（**1.自适应剪枝率算法**）

  - 然后中心服务器根据剪枝率将全局模型修剪为子模型（**2.模型剪枝算法**）

  - 发送给客户端进行本地训练

- 本地训练：每一次训练，客户端利用本地数据集对子模型进行迭代更新，迭代一定次数后进行模型聚合


- 模型聚合：
  - 中心服务器基于接收的子模型与存储的额外信息对子模型进行恢复（**3.异构模型的聚合算法**）
  - 通过聚合恢复后的模型对全局模型进行更新

<img src="https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202302/20230211_1676109142.png" alt="image-20230207065103956" style="zoom: 33%;" />



### 自适应剪枝率算法

建立剪枝率与**客户端计算能力**、**数据non-iid程度**的联系，考虑**效率与准确率**之间的平衡

- **客户端计算能力**【FedMP】：计算时间

- **数据non-iid程度**【FedSCR】：模型参数的方差、本地更新的绝对值、本地loss的方差

- 思路1：多臂老虎机【FedMP】
  - 中心服务器player，剪枝率arms
  - 客户端计算能力和数据non-iid程度决定reward，从而计算置信区间上界UCB，拥有最大置信区间上界的区域将被选择
- 思路2：强化学习
- 思路3：数学建模与优化



### 模型剪枝算法



### 异构模型的聚合算法



### 工作量与创新性

- ”自己工作的篇幅不能低于总篇幅的一半“：
  - 每个板块的消融实验、多种思路和方法？
  - 增加基准实验对比？
  - 同步和异步算法？
  - 原型实验与树莓派？



### 实验

- 系统异构：随机数计算时间
- 数据异构