## \section{贡献评估方法的有效性}

\label{sec:contribution-effective}

本节将分别展示样本标签非独立同分布及含有不同比例噪声两种情况下贡献评估方法的有效性。首先，为了让客户端之间的样本标签分布不同，本实验使用\ref{subsec:dataset}节的方法对CIFAR-10数据集进行非独立同分布的划分，让每个类别在不同客户端上的概率分布随机向量采样自狄利克雷分布（dirichlet distribution），参数$\beta$设置为0.1，表示随机向量采样的分布是一个非常不均匀的分布。客户端的总数$N$是20，训练联邦模型直至收敛，然后导出20个客户端的聚合权重。

图\ref{fig:fig_diri_weight}展示了这20个客户端的聚合权重$r_n$及其对应的样本标签分布情况，其中横坐标轴根据$r_n$的数值从大到小对所有客户端进行排序，纵坐标则代表客户端$n$中不同标签的数量。聚合权重$r_n$越大，代表客户端对于联邦训练的贡献越大。从总体趋势上看，客户端的贡献随数据量增大而增大，但也有一些例外。例如虚线框标出的两个客户端的数据量相近，但是聚合权重的数值却相差甚远。观察这两组样本标签的分布可以发现，聚合权重为0.072的客户端的样本标签分布相比聚合权重为0.023的客户端的样本标签分布要更加均衡，因此有着更高的数据价值，对联邦训练的贡献也更大。

为了验证样本标签噪声对客户端贡献评估的影响，本实验首先对所有客户端分配样本标签独立同分布的数据，然后分别在不同的客户端中将不同比例的正确的样本标签替换为错误的样本标签，最后利用这些客户端进行联邦训练，在模型收敛后导出所有客户端的聚合权重。图\ref{fig:fig_noisy_weight}非常直观地说明了，样本标签中噪声比例越小，客户端的聚合权重越大，其对于联邦训练的贡献就越大，且含有相同比例噪声的客户端的聚合权重是接近的。总的来说，两组实验都说明了在客户端之间样本标签质量不同的情况下，将余弦梯度夏普利值作为贡献评估的方法是有效的。

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.90\textwidth]{image/chap02/fig_diri_weight.pdf}
    \caption{客户端$n$的聚合权重$r_n$与样本标签分布的关系}
    \label{fig:fig_diri_weight}
\end{figure}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.90\textwidth]{image/chap02/fig_noisy_weight.pdf}
    \caption{客户端$n$的聚合权重$r_n$与样本标签噪声比例的关系}
    \label{fig:fig_noisy_weight}
\end{figure}



### \subsection{聚合算法的初始权衡系数$\gamma^0$的影响}

\label{subsec:exp-tradeoff-ratio}

本小节研究在客户端样本标签质量存在差异时，基于贡献评估的模型聚合算法的有效性，以及使用不同的初始权衡系数$\gamma^0$对于联邦训练产生的影响。当$\gamma^0=1$时，由等式\ref{eq:gamma}可知，$\gamma^t$始终为1，即加权聚合过程中不考虑贡献评估的作用，仅考虑客户端的数据量。本小节使用的数据集是CIFAR-10，数据划分方式是往不同客户端的独立同分布数据中加入不同比例的噪声。此外，因为本小节主要关注的超参数是初始权衡系数$\gamma^0$，因此其他的超参数将会被固定，例如模型剪枝算法中的初始调整系数$\lambda^0=0$。图\ref{fig:fig_noisy_agg_1}展示了客户端之间样本标签含有的噪声比例不同时，采用不同大小的$\gamma^0$对联邦训练造成的影响。

首先，在客户端之间的样本标签质量不同时，相比基于数据量的聚合算法，基于贡献评估的聚合算法能够显著提高联邦模型的训练效果，使得联邦模型的最优测试准确率和$t=200$轮的测试准确率均有明显的提升。此外，对比整体剪枝率$\alpha$分别为0.0和0.8的两张训练结果图可以发现，$\alpha=0.0$的测试准确率在达到峰值后开始下降，这与$\gamma^0=1.0$的趋势相同，而$\alpha=0.8$的测试准确率并没有出现下降的趋势，这说明在高剪枝率的基础上加上基于贡献评估的聚合算法，能够进一步抑制联邦模型对噪声数据过度拟合，从而提高联邦模型的测试准确率。

\begin{figure}[h!]
    \begin{subfigure}{0.66\textwidth}
        \includegraphics[width=\textwidth]{image/chap03/fig_noisy_agg_1.pdf}
        \caption{初始权衡系数$\gamma^0$与联邦训练效果的关系}
        \label{fig:fig_noisy_agg_1}
    \end{subfigure}
    \begin{subfigure}{0.33\textwidth}
        \includegraphics[width=\textwidth]{image/chap03/fig_noisy_agg_2.pdf}
        \caption{样本标签噪声比例为0.9的客户端的平均聚合权重变化}
        \label{fig:fig_noisy_agg_2}
    \end{subfigure}
    \caption{聚合算法的初始权衡系数$\gamma^0$对联邦训练的影响}
    \label{fig:fig_noisy_agg}
\end{figure}

其次，不同的初始权衡系数$\gamma^0$会对联邦训练造成不同的影响。观察图\ref{fig:fig_noisy_agg_1}可以发现，$\gamma^0$越大，测试准确率越快达到峰值。然而，在整体剪枝率$\alpha=0.0$时，偏大或偏小的$\gamma^0$在训练后期都会导致测试准确率更大幅度的下降，反而$\gamma^0=0.5$的下降幅度最小，在$t=200$轮时有最优的测试准确率。在$\alpha=0.8$时也有类似的现象，$\gamma^0$为0.7和0.5时，联邦模型的测试准确率更高。

为了对这一现象进行解释，图\ref{fig:fig_noisy_agg_2}展示了训练过程中标签噪声比例为0.9的客户端的平均聚合权重的变化情况。噪声比例为0.9的客户端对联邦训练的贡献是微乎其微的，因此理论上其聚合权重应该是非常小的。由等式\ref{eq:gamma}和图\ref{fig:fig_noisy_agg_2}可知，采用0.1到0.7的$\gamma^0$都能在训练过程中探索到更小的聚合权重，而$\gamma^0=0.9$时探索幅度更小，造成联邦训练的效果较差。在这之后，联邦模型开始对标签噪声过度拟合，含有噪声的客户端的聚合权重也开始上升，表示这类客户端对联邦训练产生更多的“贡献”，而这些“贡献”从联邦训练效果上看是负面的。$\gamma^0$越小，这类客户端的聚合权重上升越快，导致联邦模型的训练效果不佳。综上所述，选择一个合适的初始权衡系数$\gamma^0$有助于探索客户端的最优聚合权重，并在训练后期降低过拟合现象造成的负面影响，提升联邦模型的训练效果。

| 剪枝率         | 0.0  | 0.1   | 0.2  | 0.3   | 0.4  | 0.5   | 0.6  | 0.7   | 0.8  | 0.9   | 1.0      |
| -------------- | ---- | ----- | ---- | ----- | ---- | ----- | ---- | ----- | ---- | ----- | -------- |
| 0.0            | 2    |       | 2    |       | 2    | 2     | 2    | 1     | 1    | 1     | 0.47538  |
| 0.8            |      | test1 |      | test2 |      | test4 |      | test5 |      | test6 | 0.532715 |
| noniid 0.5 0.9 |      | 0.56  |      | 0.57  |      | 0.56  |      | 0.58  |      | 0.56  | 0.57     |



## \section{贡献评估与剪枝率的探究性实验}

\label{sec:exp-contribution-ratio}

之前章节的实验已经验证了贡献评估方法用于量化客户端聚合权重的有效性。本节将尝试探究贡献评估方法是否可用于对不同客户端剪枝率的量化。本节将沿用\ref{sec:contribution-effective}小节的实验设置，即准备$N=20$个客户端和标签非独立同分布（$\beta=0.1$的狄利克雷分布）的样本，训练联邦模型至收敛后导出所有客户端的聚合权重，20个客户端聚合权重的具体数值已经展示在\ref{sec:contribution-effective}小节中。接下来，将聚合权重最大的5个客户端视为高贡献客户端，聚合权重最小的5个客户端视为低贡献客户端，分别对这两类分配不同的剪枝率$\alpha_{\text{high}}$和$\alpha_{\text{low}}$，对其余的客户端分配平均剪枝率$\overline{\alpha}=\frac{\alpha_{\text{high}}+\alpha_{\text{low}}}{2}$。然后，基于相同的样本标签分布和相同的初始化参数重新进行联邦训练。联邦模型测试准确率与高低贡献客户端剪枝率之差的关系如图\ref{fig:fig99}所示。

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{image/chap03/fig99.pdf}
    \caption{联邦模型测试准确率与高低贡献客户端剪枝率之差的关系}
    \label{fig:fig99}
\end{figure}

接下来对实验结果进行总结和分析。首先，所有客户端的平均剪枝率越高，联邦训练的测试准确率一般越低，这与\ref{subsec:exp-pruning-ratio}的实验结果基本吻合。对于图中的单条线，也就是平均剪枝率相同的情况，高低贡献客户端剪枝率之差$\alpha_{\text{high}}-\alpha_{\text{low}}$越大，联邦训练的测试准确率越低，而当高贡献客户端的剪枝率远大于低贡献客户端的剪枝率（例如：$\alpha_{\text{high}}=0.8$且$\alpha_{\text{low}}=0.4$，$\alpha_{\text{high}}=0.9$且$\alpha_{\text{low}}=0.5$）时，联邦训练的测试准确率较差。正如\ref{subsec:shapley-contribution}节的分析，高贡献客户端的模型参数更新与联邦模型的参数更新的相似度更高，因此从直观上说，低贡献的客户端相比高贡献的客户端应有着更高的剪枝率。图\ref{fig:fig99}展示的实验结果支持了这一结论，也为基于贡献评估自适应剪枝的思路提供了可能性。



| 0        | 1        | 2        | 3        | 4        | 5        | 6        | 7        | 8        | 9        | 10       | 11       | 12       | 13       | 14       | 15       | 16       | 17       | 18       | 19       |
| -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- |
| 0.036693 | 0.143463 | 0.022392 | 0.013395 | 0.013322 | 0.097979 | 0.00082  | 0.030039 | 0.07451  | 0.095612 | 0.021992 | 0.024536 | 0.001371 | 0.108641 | 0.054097 | 0.135757 | 0.025188 | 0.066354 | 0.033022 | 0.00082  |
| 0.038035 | 0.138636 | 0.018062 | 0.018202 | 0.027399 | 0.09896  | 0.005816 | 0.032438 | 0.069059 | 0.086187 | 0.02408  | 0.024471 | 0.000802 | 0.101577 | 0.053095 | 0.133617 | 0.022667 | 0.069473 | 0.036621 | 0.000802 |
| 0.031099 | 0.119816 | 0.019614 | 0.016635 | 0.028463 | 0.092628 | 0.006936 | 0.030232 | 0.073709 | 0.086995 | 0.034614 | 0.028178 | 0.004555 | 0.100767 | 0.050759 | 0.138475 | 0.023096 | 0.073827 | 0.037469 | 0.002134 |

| index | test1    | test2    | test3    | avg          | rank | rank1 | rank2 | rank3 |      |
| ----- | -------- | -------- | -------- | ------------ | ---- | ----- | ----- | ----- | ---- |
| 15    | 0.135757 | 0.133617 | 0.138475 | **0.13595**  | 1    | 2     | 2     | 1     | 4651 |
| 1     | 0.143463 | 0.138636 | 0.119816 | 0.133971     | 2    | 1     | 1     | 2     | 5293 |
| 13    | 0.108641 | 0.101577 | 0.100767 | 0.103662     | 3    | 3     | 3     | 3     | 4288 |
| 5     | 0.097979 | 0.09896  | 0.092628 | 0.096523     | 4    | 4     | 4     | 4     | 3987 |
| 9     | 0.095612 | 0.086187 | 0.086995 | 0.089598     | 5    | 5     | 5     | 5     | 2821 |
| 8     | 0.07451  | 0.069059 | 0.073709 | **0.072426** |      |       |       |       | 3121 |
| 17    | 0.066354 | 0.069473 | 0.073827 | 0.069884     |      |       |       |       | 2748 |
| 14    | 0.054097 | 0.053095 | 0.050759 | 0.05265      |      |       |       |       | 2595 |
| 18    | 0.033022 | 0.036621 | 0.037469 | 0.035704     |      |       |       |       | 2172 |
| 0     | 0.036693 | 0.038035 | 0.031099 | 0.035275     |      |       |       |       | 2036 |
| 7     | 0.030039 | 0.032438 | 0.030232 | 0.030903     |      |       |       |       | 2109 |
| 10    | 0.021992 | 0.02408  | 0.034614 | 0.026895     |      |       |       |       | 2103 |
| 11    | 0.024536 | 0.024471 | 0.028178 | 0.025728     |      |       |       |       | 1584 |
| 16    | 0.025188 | 0.022667 | 0.023096 | 0.02365      |      |       |       |       | 1504 |
| 4     | 0.013322 | 0.027399 | 0.028463 | **0.023061** |      | 17    |       |       | 3033 |
| 2     | 0.022392 | 0.018062 | 0.019614 | 0.020023     | 16   |       | 17    | 16    | 913  |
| 3     | 0.013395 | 0.018202 | 0.016635 | 0.016077     | 17   | 16    | 16    | 17    | 1178 |
| 6     | 0.00082  | 0.005816 | 0.006936 | **0.004524** | 18   | 19    | 18    | 18    | 693  |
| 12    | 0.001371 | 0.000802 | 0.004555 | 0.002243     | 19   | 18    | 19    | 19    | 26   |
| 19    | 0.00082  | 0.000802 | 0.002134 | 0.001252     | 20   | 20    | 20    | 20    | 5    |

| 剪枝率  | 0.0         | 0.2         | 0.4         | 0.6         | 0.8         |
| ------- | ----------- | ----------- | ----------- | ----------- | ----------- |
| **0.0** | 0.18051     | 0.169320001 | 0.162209998 | 0.173109999 | 0.174859999 |
| **0.2** | 0.205290002 | 0.207354999 | 0.205089999 | 0.211660001 | 0.189490001 |
| **0.4** | 0.44691     | 0.431469998 | 0.432804994 |             | 0.4242      |
| **0.6** | 0.42694     | 0.43971     | 0.43797     |             | 0.424870002 |
| **0.8** | 0.374450001 |             | 0.411130001 | 0.418875001 | 0.42956     |

| 剪枝率  | 0.4             | 0.6         | 0.7             | 0.8             | 0.9             |
| ------- | --------------- | ----------- | --------------- | --------------- | --------------- |
| **0.4** | 0.4511          | 0.42633     | **0.423690003** | **0.429950002** | **0.40312**     |
| **0.6** | **0.428510001** | 0.428060001 | **0.435879999** | **0.432929999** | **0.409780005** |
| **0.7** | 0.413100001     | 0.433719999 | 0.423110002     | **0.43265**     | **0.418679997** |
| **0.8** | 0.350255002b    | 0.41558     | 0.423990002     | 0.40616b        | **0.403010002** |
| **0.9** | 0.31596         | 0.3459      | 0.40028         | 0.399060002     | 0.400299999     |

| 0.5     |                  | 0.6     |                 | 0.7     |                  | 0.8     |             |
| ------- | ---------------- | ------- | --------------- | ------- | ---------------- | ------- | ----------- |
|         |                  | 0.4-0.8 | 0.429950002     | 0.5-0.9 | **0.4064500025** |         |             |
| 0.4-0.6 | 0.42633          | 0.5-0.7 | **0.429785001** | 0.6-0.8 | 0.432929999      | 0.7-0.9 | 0.418679997 |
| 0.5-0.5 | **0.4395800005** | 0.6-0.6 | 0.428060001     | 0.7-0.7 | 0.423110002      | 0.8-0.8 | 0.40616b    |
| 0.6-0.4 | 0.428510001      | 0.7-0.5 | **0.42341**     | 0.8-0.6 | 0.41558          | 0.9-0.7 | 0.40028     |
|         |                  | 0.8-0.4 | 0.350255002b    | 0.9-0.5 | **0.33093**      |         |             |

| 0.5     |             | 0.6     |             | 0.7     |             | 0.8     |             |
| ------- | ----------- | ------- | ----------- | ------- | ----------- | ------- | ----------- |
|         |             | 0.4-0.8 | 0.48355     | 0.5-0.9 | 0.49153     |         |             |
| 0.4-0.6 | 0.49603     | 0.5-0.7 | 0.483385    | 0.6-0.8 | 0.48469     | 0.7-0.9 | 0.47058     |
| 0.5-0.5 | 0.497354999 | 0.6-0.6 | 0.481660001 | 0.7-0.7 | 0.474870002 | 0.8-0.8 | 0.458060001 |
| 0.6-0.4 | 0.496248    | 0.7-0.5 | 0.47701     | 0.8-0.6 | 0.46734     | 0.9-0.7 | 0.45218     |
|         |             | 0.8-0.4 | 0.403855    | 0.9-0.5 | 0.38269     |         |             |
