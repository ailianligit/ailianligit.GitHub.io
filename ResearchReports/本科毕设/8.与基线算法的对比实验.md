## \section{与基线算法的对比实验}

\label{sec:baseline}

本节将本文提出的基于剪枝优化的大模型联邦训练算法和联邦学习、联邦剪枝中的基线算法的训练效果进行对比。首先，本节将先后使用MNIST和CIFAR-10这两个数据集进行训练和测试。其次，数据集的划分方式、模型、实验指标和超参数等实验设置将参照\ref{subsec:model}节的内容。其中，不含标签噪声的实验使用的超参数与\ref{sec:ablation}节实验组6的超参数相同，而含有标签噪声的实验使用的超参数与\ref{sec:ablation}节实验组12的超参数相同。

在本节对比的基线算法中，FedAvg\cite{mcmahan2017communication}和FedProx\cite{li2020federated}是经典的联邦学习算法。在FedAvg算法中，服务器将完全相同的完整的模型发送给所有的客户端，客户端进行本地训练，服务器根据客户端的数据量进行加权聚合。为了改善FedAvg算法在非独立同分布数据上的表现，FedProx算法对FedAvg算法进行了改进，在本地训练的目标函数上加上一个正则项，使得客户端的模型更新方向与服务器端的模型更新方向尽可能接近，以此减轻数据非独立同分布给联邦训练造成的影响。需要说明的是，由于FedAvg和FedProx不是剪枝算法，因此将使用密集的大模型进行联邦训练。将FedAvg和FedProx算法加入对比是为了展示在通信和计算资源不受限制的理想情况下，利用联邦学习的框架训练大模型的效果，同时突出联邦剪枝算法在减少通信和计算量等方面的优势。

PruneFL\cite{jiang2022model}和FedDST\cite{bibikar2022federated}算法在联邦学习的框架中应用了网络剪枝的技术。为了在联邦训练期间减少通信和计算开销，PruneFL算法将网络剪枝引入联邦学习的框架中。首先，PruneFL算法会选择信任的客户端进行初始剪枝，然后在训练过程中进一步剪枝，通过最大化单位时间经验误差来自适应选择要对哪些参数进行剪枝。FedDST算法将动态稀疏训练的思想引入联邦学习中，根据客户端本地的非独立同分布数据自适应调整拓扑结构。PruneFL和FedDST算法缺乏对客户端样本标签质量存在差异的现实情况的考虑，因此将这两种算法加入对比能够展示本算法在样本标签质量存在差异时的鲁棒性。

\begin{table}[h] %voc table result
    \centering
    \caption{MNIST数据集联邦训练$t=200$轮的测试准确率对比}
    \resizebox{0.7\textwidth}{!}{
        \begin{tabular}{c|*{20}{c}}
            \toprule
            算法 & 独立同分布 & 非独立同分布 & 噪声比例不平衡\\
            \midrule
            FedAvg\cite{mcmahan2017communication} & 0.98693 & 0.94217 & 0.83650\\
            FedProx\cite{li2020federated} & 0.98066 & 0.94266 & 0.90570\\
            \midrule
            PruneFL\cite{jiang2022model} & \textbf{0.97638} & 0.88250 & 0.83672\\
            FedDST\cite{bibikar2022federated} & 0.97264 & 0.92948 & 0.79082\\
            本文算法 & 0.97099 & \textbf{0.94287} & \textbf{0.92235}\\
            \bottomrule
        \end{tabular}}
    \label{tab:final-result}
\end{table}

\newpage

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\textwidth]{image/chap03/fig_final_3.pdf}
    \caption{CIFAR-10数据集独立同分布的联邦训练结果对比}
    \label{fig:fig_final_1}
\end{figure}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\textwidth]{image/chap03/fig_final_1.pdf}
    \caption{CIFAR-10数据集非独立同分布的联邦训练结果对比}
    \label{fig:fig_final_2}
\end{figure}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\textwidth]{image/chap03/fig_final_2.pdf}
    \caption{CIFAR-10数据集噪声比例不平衡的联邦训练结果对比}
    \label{fig:fig_final_3}
\end{figure}

\newpage

表\ref{tab:final-result}展示了各个算法使用MNIST数据集训练200轮后联邦模型的测试准确率。相比其他联邦剪枝算法，本文提出的基于剪枝优化的大模型联邦训练算法在样本标签质量存在差异的情况下能够取得最优的性能，联邦模型的测试准确率能够匹配甚至超过非剪枝算法FedAvg和FedProx的精度。PruneFL和FedDST都在联邦学习中应用了动态剪枝的思想，但在样本标签非独立同分布的情况下，FedDST的测试准确率比PruneFL高，因为FedDST算法会针对客户端的异质数据进行动态稀疏训练，而PruneFL缺乏这方面考虑。然而，在样本标签噪声比例不同时，PruneFL的测试准确率高于FedDST的测试准确率，因为这时FedDST的动态稀疏训练反而会让联邦模型学习过多关于标签噪声的知识。本文提出的大模型联邦训练算法在时间的维度上进行动态剪枝，考虑了客户端之间的标签质量差异，在样本标签非独立同分布和噪声比例不同这两个场景中取得了更好的效果。

图\ref{fig:fig_final_1}、图\ref{fig:fig_final_2}、图\ref{fig:fig_final_3}分别展示了各个算法使用CIFAR-10数据集在三种数据划分情况下的联邦训练情况。在测试准确率方面，这三组实验结果与MNIST数据集的实验结果是相似的，即在样本标签质量存在差异的情况下，本文算法相比PruneFL和FedDST这两种联邦剪枝算法的表现更好。在计算量和通信开销方面，这三组实验结果则突出了三种联邦剪枝算法相比FedAvg和FedProx这两种不剪枝算法的优势。观察实验结果可以发现，在客户端样本标签质量存在差异的情况下，本文提出的基于剪枝优化的大模型联邦训练算法利用更少的通信和计算开销实现了更高的测试准确率。在标签噪声比例不平衡的情况下，通过基于贡献评估的聚合算法抑制了对噪声数据的过度拟合，在联邦训练效果上实现了更为突出的优势。
