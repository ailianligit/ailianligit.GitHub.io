# \chapter{国内外研究现状和相关工作}

\label{chap:research}

## \section{联邦学习中的模型压缩}

\label{sec:fed-compression}

正如绪论所述，联邦学习框架中受限的通信和计算能力难以满足如今精度更高，但规模更大的深度学习模型的训练需求，因此在联邦学习中采用一些模型压缩技术是十分必要的。FedGKT\cite{he2020group}设计了一种交替最小化方法的变体，在边缘设备上训练小型网络，并通过双向知识蒸馏定期在大模型和小模型之间迁移知识。Fed-ET\cite{cho2022heterogeneous}提出了一种具有多样性正则化的加权共识精馏方法，考虑客户端模型异构和数据非独立同分布的同时，使用无标签数据实现集成转移（ensemble transfer），但是Fed-ET需要在模型后加一个表示层，并且要求所有模型的表示层的维度保持一致。FedPCL\cite{tan2022federated}基于有监督的对比方式，使用局部原型和全局原型进行知识共享，通过对比学习，最大化融合表示与其对应原型之间的一致性。然而，上述联邦学习模型压缩的方法要么需要有公共数据集，要么知道私有数据的详细信息、统计信息或学习到的知识，存在隐私泄露的风险。



## \section{联邦学习中的网络剪枝}

\label{sec:fed-pruning}

现有的基于剪枝优化的联邦学习算法主要围绕剪枝的对象和剪枝的程度进行研究。PruneFL\cite{jiang2022model}提出了两阶段的剪枝策略和经验误差近似方法，通过最大化单位时间经验误差自适应地选择剪枝的参数。为了适应资源受限且异构的边缘设备，FedMP\cite{jiang2022fedmp}使用多臂老虎机根据每个客户端的计算能力自适应地决定剪枝率，并提出了基于模型残差的聚合策略。ZeroFL\cite{qiu2022zerofl}采用了高度稀疏操作来加速设备上的训练。然而，PruneFL、FedMP和ZeroFL算法都没有考虑客户端之间样本标签质量存在差异的情况。FedDUAP\cite{zhang2022fedduap}使用边缘设备和服务器上的数据动态更新模型，而服务器根据联邦模型的准确率和非独立同分布的程度自适应调整联邦模型的训练。Sub-FedAvg\cite{vahidian2021personalized}将混合剪枝技术应用到联邦学习的框架中，为不同的客户端提供不同的子网络，服务器收到子网络后只在模型参数交集处进行聚合。FedDST\cite{bibikar2022federated}利用了动态稀疏训练的思想，根据本地的数据自适应调整拓扑结构。然而，上述联邦剪枝算法忽视了客户端样本标签质量存在差异时对联邦训练的影响。



## \section{联邦学习中的数据异构}

\label{sec:fed-noniid}

在联邦学习中，数据由分布在世界各地的客户端采集和存储，因此客户端之间的数据的分布容易出现不一致的情况。相比独立同分布的数据，非独立同分布的数据会让模型的训练效果大幅度下降\cite{zhao2018federated}。FedAvg算法\cite{mcmahan2017communication}通过将客户端的数据量占总数据量的比例作为模型聚合的权重，适应了非独立同分布中最简单的数据量不同的情况。FedMo算法\cite{ozdayi2020improving}参考了动量梯度下降算法，将客户端的模型上传到服务器，并在服务器进行动量累加和模型更新。

关注客户端本地异构数据的个性化联邦学习是联邦学习中一个重要的分支。个性化联邦学习的一个策略是让全局模型个性化，提升联邦模型在异构数据上训练的效果，可以分为基于数据和基于模型的两类方法\cite{tan2022towards}。在基于数据的方法中，FedHome算法\cite{wu2020fedhome}利用了数据增强的思想，而FedSAE算法\cite{li2021fedsae}利用了客户端选择的思想。在基于模型的方法中，FedProx算法\cite{li2020federated}通过在客户端优化目标中添加近端项使得本地更新不能远离全局模型的更新，在适应系统异构性的同时减少非独立同分布数据的影响。ARUBA框架\cite{khodak2019adaptive}和FedMD算法\cite{li2019fedmd}则分别利用了元学习和迁移学习的思想进行个性化联邦学习。个性化联邦学习的另一个策略是为客户端提供个性化的解决方法，可以分为基于架构和基于相似性的两类方法。在基于架构的方法中，LG-FedAvg算法\cite{liang2020think}利用了参数解耦的思想，FedGKT算法\cite{he2020group}利用了知识蒸馏的思想。在基于相似性的方法中，FedCurv算法\cite{shoham2019overcoming}利用了多任务学习的思想，HeteroFL算法\cite{diao2020heterofl}利用了模型插值的思想，FedGroup算法\cite{duan2021fedgroup}利用了聚类的思想。



## \section{联邦学习中的标签噪声}

\label{sec:fed-noisy}

处理标签噪声是机器学习和联邦学习中一个常见的挑战，因为标签噪声会降低客户端样本标签的质量，进而影响客户端对联邦训练的贡献大小。与样本标签异构中假设样本标签全部正确不同，标签噪声说明对于相似甚至相同的样本，标签仍然可能出现不一致的情况。在机器学习领域，处理标签噪声的方法可以分为数据级别和算法级别。首先，数据级别的方法通过清洗带有噪声的样本标签来减轻其对模型训练效果的影响。Zeno算法\cite{DBLP:journals/corr/abs-1805-10032}设计了一种拜占庭鲁棒的聚合方法来抵御标签翻转（label-flipping）数据中毒（data poisoning）攻击。然而，Pang Wei Koh等人的研究\cite{DBLP:journals/corr/abs-1811-00741}发现，一些效果最好的数据清洗方法仍然容易受到数据中毒的攻击。其次，算法级别的方法通常会训练一个抗噪的模型。MetaCleaner算法\cite{DBLP:conf/cvpr/ZhangW019}基于元学习的思想，在传统的梯度更新之前生成一些合成的噪声标签对模型进行更新。上述方法都需要访问原始数据，不能直接应用于联邦学习的场景中。



## \section{联邦学习中的贡献评估}

\label{sec:fed-contribution}

所有客户端的数据价值和贡献大小会影响联邦大模型的训练效果。对于数据估值，常见的方法是根据联邦模型的测试准确率\cite{koh2017understanding}、数据量\cite{zhan2021survey}和数据分布的多样性\cite{xu2021validation}来度量客户端的数据价值，但是需要访问原始数据或统计信息。除此之外，客户端模型和全局模型的梯度相似度\cite{xu2021gradient}、基于模型参数的信息增益\cite{sim2020collaborative}也可以用来评估客户端的数据价值。然而，数据的价值并不总是等同于客户端对联邦训练的贡献，因为单个数据价值低的客户端可能会在客户端组合中带来互补的效果，因此需要考虑客户端对联邦合作所带来的边际价值增益\cite{王勇2022联邦学习贡献评估综述}。贡献评估的方法有将联邦排除某个客户端后的组合价值边际损失作为客户端贡献的留一法\cite{wang2019measure}，枚举所有不包含某个客户端时引入该客户端带来的边际贡献期望的夏普利值（shapley value）法\cite{van2018new}，以及追求客户端组合公平的最小核（least core）法\cite{yan2021if}。联邦学习中的贡献评估主要用于实现贡献公平性\cite{song2019profit}和均衡公平性\cite{yang2021federated}，本文则探索在客户端样本标签质量存在差异的情况下，贡献评估方法对于提升联邦大模型训练效果的作用。