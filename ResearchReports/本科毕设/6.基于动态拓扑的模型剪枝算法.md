## \section{基于动态拓扑的模型剪枝算法}

\label{sec:dynamic-pruning}

对于一种网络剪枝算法，需要对剪枝的结构、标准和方法等方面进行设计。首先，\ref{subsec:structure-standard}节对剪枝的结构和标准进行了介绍。然后，\ref{subsec:layer-prune}和\ref{subsec:dynamic-pruning-design}节介绍了剪枝的方法，分别对逐层剪枝算法和基于动态拓扑的剪枝算法的设计细节进行了阐述，并对这两个算法如何改善网络剪枝的效果进行了分析。



### \subsection{剪枝结构与剪枝标准}

\label{subsec:structure-standard}

深度学习模型从卷积层到全连接层存在着大量冗余的参数，网络剪枝将模型中不重要的权重、神经元、滤波器甚至整个网络层剪去，这些被剪掉的权重或结构会在计算时被忽略。网络剪枝在剪枝结构上可以分为结构化（structured）剪枝和非结构化（unstructured）剪枝两类。结构化剪枝\cite{kruschke1991benefits}的对象通常是整个滤波器或网络层，能够通过常见的GPU或其他硬件得到加速，但对滤波器进行剪枝时，滤波器之前和之后的特征图都会发生变化，因此实现起来更加复杂。此外，结构化剪枝是粗粒度的剪枝模式，可能会对原始模型的结构造成破坏性的伤害。非结构化剪枝\cite{han2015learning}的对象是神经元之间的权重连接，虽然这种剪枝会导致剪枝后的模型高度稀疏，只有部分能够加速稀疏矩阵计算的硬件架构能够降低实际上的计算量，但非结构化剪枝的实现更加简单、直接，并且这种细粒度的剪枝模式相比结构化剪枝会更加精准，因此在通常情况下，模型的训练效果更好。由于本文的实验建立在仿真的基础上，通过估计的方式对客户端的通信和计算量进行度量，因此本文提出的剪枝算法只会对卷积层和全连接层中的权重进行修剪，不会修剪偏差（bias），也不会修剪更大粒度的模型结构。

在非结构化剪枝的算法中，剪枝的标准决定了哪些权重会被剪去，以及哪些权重会得到保留。对于网络剪枝，一个广泛使用的标准是剪去绝对值较小的权重\cite{gale2019state}，另外，还有一些方法\cite{blalock2020state}会利用训练过程中产生的梯度信息，根据梯度与相应权重之间的乘积大小进行修剪。本文提出的剪枝算法采用简单且有效的模型权重大小作为剪枝的标准，移除绝对值较小的权重已被证明对模型训练效果的影响最小\cite{han2015learning,evci2018detecting}。因为随机梯度下降算法中引入了权重衰减项，相当于在目标函数上加上了L2正则项，那些对模型训练没有明显贡献的权重会在训练过程中逐渐缩小。因此，在这一标准下，绝对值较大的权重相比绝对值较小的权重更为重要，在网络剪枝中将会优先得到保留。



### \subsection{逐层剪枝算法}

\label{subsec:layer-prune}

在剪枝算法中，给定目标整体剪枝率$\alpha$，需要将模型中比例为$\alpha$的权重剪去。在具体的实现方法上，可以分为全局剪枝和逐层剪枝这两类。其中，全局剪枝对网络中所有参数视为一个整体，剪去绝对值最小的百分之$\alpha$个参数，虽然能够取得不错的效果，但可能导致层崩溃（layer-collapse）\cite{tanaka2020pruning}的现象发生。逐层剪枝的方法对于网络中的每一层进行单独剪枝，各层的剪枝率可以与全局剪枝率$\alpha$相同，也可以有自己的剪枝率$\boldsymbol{\alpha}_l$。本文提出的逐层剪枝算法采用了Erdős–Rényi随机图拓扑\cite{renyi1959random}的思路，让网络层$l$中剩余的权重数与该层前后连接的神经元数$m_{l-1}+m_{l}$成线性的关系，ER公式\cite{mocanu2018scalable}（\ref{eq:layer-ratio-normalize-ER}）对全连接层的剪枝率进行了计算，其中分母$m_{l-1}\times m_{l}$表示未剪枝的情况下该全连接层拥有的总权重数。因为ER公式无法适应卷积层剪枝率的计算，所以ERK（Erdős-Rényi-Kernel）公式\cite{evci2020rigging}（\ref{eq:layer-ratio-normalize-ERK}）将内核（kernel）的大小也考虑进来，其中$w_l$和$h_l$分别表示卷积内核的宽度和高度。值得说明的是，为了让层剪枝率匹配整体的剪枝率，即让逐层剪枝后整个模型的剪枝率仍为$\alpha$，因此还需要对层剪枝率进行归一化。

\begin{equation}
    \label{eq:layer-ratio-normalize-ER}
    \boldsymbol{\alpha}_l:=1-\frac{m_{l-1}+m_l}{m_{l-1}\times m_l}
\end{equation}

\begin{equation}
    \label{eq:layer-ratio-normalize-ERK}
    \boldsymbol{\alpha}_l:=1-\frac{m_{l-1}+m_l+w_l+h_l}{m_{l-1}\times m_l\times w_l\times h_l}
\end{equation}

此前一些工作\cite{evci2020rigging}将Erdős–Rényi随机图拓扑运用到深度学习模型的网络剪枝中，通过实验验证了算法的有效性和对于剪枝效果的提升作用。本文将在基于动态拓扑的剪枝算法中对联邦大模型进行逐层剪枝，帮助大模型在联邦学习的框架中进行压缩和训练。



### \subsection{动态剪枝算法的设计}

\label{subsec:dynamic-pruning-design}

正如绪论所述，经典框架\cite{han2015learning}、扩展框架\cite{gale2019state}和“彩票假说”\cite{frankle2018lottery}都难以在模型训练开始时就对训练的通信和计算成本进行优化，而基于静态拓扑的剪枝算法由于不具备大规模密集模型的过参数化特性\cite{liu2021we}，导致模型的表达能力和训练效果较差。在本文提出的基于剪枝优化的大模型联邦训练算法中，每个通信轮次客户端将剪枝模型上传给服务器后，服务器会对剪枝模型进行聚合和恢复，而下一个通信轮次开始时服务器又会根据\ref{subsec:structure-standard}和\ref{subsec:layer-prune}节介绍的剪枝结构、标准和方法进行重新剪枝，从而导致剪枝模型的网络拓扑在时间维度上始终是动态变化的。

然而，这种剪枝模式容易受到模型初始化的限制，导致一些权重因为始终无法更新而总是被优先剪去。受到生物学领域神经系统进化原理和计算机科学领域进化算法的启发，Decebal Constantin Mocanu等人\cite{mocanu2018scalable}首次提出了动态稀疏训练的概念和SET算法。SET算法在训练过程中以先剪枝再修复的形式动态调整模型的拓扑结构，在时间的维度上实现了与大模型类似的过参数化的特性，实验也证实了动态稀疏训练相对于静态稀疏训练在模型训练效果上的优势。经过简单的对比可以发现，基于动态拓扑的模型剪枝和基于遗传算法的神经架构搜索（neural architecture search，NAS）\cite{xie2017genetic}的思路是非常相似的，这两种技术都以搜索最优子网络为目标，用进化的方式对剪枝模型的参数空间进行探索。

算法\ref{algo:dynamic-prune}展示了基于动态拓扑的剪枝算法的流程。每个通信轮次结束前，服务器会将剪枝模型$\hat{\boldsymbol{\theta}}$恢复为更大规模的联邦模型$\boldsymbol{\theta}$。每个通信轮次开始前，服务器会将联邦模型$\boldsymbol{\theta}$修剪为不同网络拓扑的剪枝模型$\hat{\boldsymbol{\theta}}$。调整系数$\lambda^t$的含义是在剪枝率$\alpha$的基础上再修剪比例为$\lambda^t$的权重，$\lambda^t$越大，代表着对剪枝模型网络拓扑的探索程度越大，反之则越小。为了提升模型训练后期的稳定性，需要在训练过程中逐渐降低剪枝模型网络拓扑的探索程度，因此调整系数会以等式（\ref{eq:f-decay}）的形式衰减，Utku Evci和Tim Dettmers等人的实验\cite{dettmers2019sparse,evci2020rigging}表明，余弦衰减的效果略好于常数、负幂等形式的衰减，因此$\lambda^t$以余弦的形式衰减。最后需要对剪枝模型的整体剪枝率进行恢复，因此算法将以随机的方式逐层恢复一定数量的参数。

\begin{algorithm}[h]
    \KwIn{联邦模型参数$\boldsymbol{\theta}$，剪枝率$\alpha$，初始调整系数$\lambda^0$，通信轮次$t$，总轮数$T$}
    \KwOut{剪枝模型参数$\hat{\boldsymbol{\theta}}$}
    根据等式（\ref{eq:f-decay}）计算本轮调整系数$\lambda^t$\\
    计算扩大剪枝率：$\alpha^{+}\leftarrow\alpha+(1-\alpha)\lambda^t$\\
    \ForEach{层$l$}{
        \textbf{如果} $l$为全连接层\textbf{进行}\\
        \hspace{20pt}应用ER公式（\ref{eq:layer-ratio-normalize-ER}）计算层剪枝率$\boldsymbol{\alpha}_l$\\
        \textbf{如果} $l$为卷积层\textbf{进行}\\
        \hspace{20pt}应用ERK公式（\ref{eq:layer-ratio-normalize-ERK}）计算层剪枝率$\boldsymbol{\alpha}_l$\\
    }
    \ForEach{层$l$}{
        $s_l=$联邦模型第$l$层$\boldsymbol{\theta}_l$的参数数量\\
        归一化层剪枝率：$\boldsymbol{\alpha}_l\leftarrow\alpha\times\frac{\boldsymbol{\alpha}_l\times\sum_l s_l}{\sum_l \boldsymbol{\alpha}_l s_l}$\\
        $\hat{\boldsymbol{\theta}}_l\leftarrow\boldsymbol{\theta}_l$剪去绝对值最小的$s_l \boldsymbol{\alpha}_l$个参数\\
        在$\hat{\boldsymbol{\theta}}_l$上恢复$\boldsymbol{\theta}_l-\hat{\boldsymbol{\theta}}_l$中随机的$s_l \boldsymbol{\alpha}_l$个参数\\
    }
    \caption{基于动态拓扑的模型剪枝算法}
    \label{algo:dynamic-prune}
\end{algorithm}

\begin{equation}
    \label{eq:f-decay}
    \lambda^t:=\frac{\lambda^0}{2}[1+\cos({\frac{t\pi}{T}})]
\end{equation}

基于动态拓扑的模型剪枝算法结合了网络剪枝技术和过参数化特性的优势，在优化模型训练成本的同时，提升了模型的训练效果。动态剪枝算法从训练开始就对联邦模型进行剪枝，并在训练过程中保持一定的整体剪枝率，减少了训练所需的通信和计算资源。此外，基于动态拓扑的模型剪枝算法在训练过程中对剪枝模型的参数空间进行探索，将重要的权重保留下来，在时间维度上实现了过参数化的特性。因此，动态剪枝可以突破静态剪枝中常常遇到的局部最优解，提升联邦模型的表达能力和训练效果。\ref{sec:ablation}节的消融实验可以证明动态剪枝算法在这两方面的优势。此外，\ref{subsec:exp-pruning-ratio}和\ref{subsec:exp-dynamic-ratio}节的超参数实验对剪枝算法中的整体剪枝率$\alpha$和初始调整系数$\lambda^0$的设置进行了讨论。

观察\ref{subsec:exp-pruning-ratio}节的实验结果可以发现，进行适当的剪枝有助于联邦模型适应客户端样本标签非独立同分布的情况，使得联邦模型具备一定的鲁棒性。一众联邦学习领域的研究\cite{zhao2018federated,ozdayi2020improving}认为异构数据会导致客户端之间的模型或梯度差异过大，从而降低联邦模型的训练效果。从这个角度看，适当的剪枝能在尽可能保持模型训练效果的同时，减少客户端之间模型参数的差异。
