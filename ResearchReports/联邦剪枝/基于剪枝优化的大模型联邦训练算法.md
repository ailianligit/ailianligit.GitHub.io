# 一、绪论

## 选题的背景与意义

​       联邦学习使边缘设备能够在不透露私有数据的情况下协作地学习模型。大多数现有的联邦学习算法需要在客户端和服务器部署相同架构的模型，然而，由于边缘设备的资源有限，超大规模的模型训练是不切实际的。因此，我们需要在联邦学习中应用剪枝优化等模型压缩的技术，在尽量不损失模型性能的前提下，实现模型计算、存储和通信的优化。另外，**系统异构**是联邦学习中常见的场景，边缘设备的计算和存储能力的差异决定了联邦学习中的剪枝优化方法应尽可能具备动态和自适应的特点。最后，不同设备收集的数据通常是非独立同分布的，因此，基于剪枝优化的联邦学习算法应尽可能具备适应**数据异构**场景的能力。

## 国内外研究现状和相关工作

​       现有的基于剪枝优化的联邦学习算法主要围绕剪枝的对象和剪枝的程度进行研究。其中一些工作直接将现有的剪枝方法加入联邦训练的过程，或者预先设定相同的剪枝率，忽视了联邦学习中系统异构的场景。另外一些工作采用了自适应剪枝的方式，为不同的客户端设置不同的剪枝率，虽然这些算法在非独立同分布的数据中有不错的表现，但这些算法的设计回避了，容易造成模型训练的等问题。对基于剪枝优化的联邦学习算法进行研究，使其有效适应系统异构和数据异构的场景，是该研究方向的一个发展趋势。

## 本文的论文结构与相关安排

​       本文共分为六章，各章节内容安排如下：       第一章绪论。简单说明了本文章的选题背景与意义，总结了国内外研究现状和相关工作。       第二章为基于剪枝优化的大模型联邦训练框架。分为三块介绍了联邦剪枝的训练框架，分别是自适应剪枝模块、本地训练模块和异构模型的聚合模块，其中自适应剪枝模块中的剪枝率决策算法将在第三章中单独介绍。

​       第三章为剪枝率决策算法。首先对优化的问题进行定义，通过测量实验引入了问题场景和方法中的困难和挑战，例如效率与准确率的权衡、系统异构性和数据价值异构，最后为解决挑战提出剪枝率决策算法。

​       第四章为实验与结果。对本文提出的模型剪枝算法与FedMP、PruneFL、SynFL、UP-FL、FedProx、FlexCom等基线算法进行比较，比较的指标为测试集准确率和达到指定准确率所需要的训练时间。

# 二、基于剪枝优化的大模型联邦训练框架

## 自适应模型剪枝

​       每轮中心服务器根据每个客户端的**训练状态（与计算能力、数据价值的对应关系）**自适应决定剪枝率，然后中心服务器根据剪枝率将全局模型修剪为子模型，将子模型发送给客户端进行本地训练。

### 剪枝方向

- 结构化剪枝或非结构化剪枝
- layer-wise剪枝或全局剪枝

### 剪枝标准

- 权重大小
- 绝对值变化量
- 梯度幅度剪枝
- **梯度的平方（泰勒展开）**

### 剪枝方法

- mask

## 本地训练

​       每一次训练，客户端利用本地数据集对子模型进行迭代更新，迭代一定次数后进行模型聚合。

## 异构模型的聚合

​       中心服务器基于接收的子模型与掩码（mask）等存储的额外信息对子模型进行恢复，通过聚合恢复后的模型对全局模型进行更新。

- 权重与数据质量有关

# 三、剪枝率决策算法

## 问题定义

- 优化问题：

$$\min \sum_{k=0}^{K} T^{k}\left(\alpha_{1}^{k}, \alpha_{2}^{k}, \ldots, \alpha_{N}^{k}\right) $$

$$\text { s.t. }\left\{\begin{array}{l} f\left(\mathbf{x}^{K}\right)<\varepsilon \\ 0 \leq \alpha_{n}^{k}<1, \quad \forall n, \forall k \end{array}\right. $$

## 关键挑战

### A. **剪枝率的决策需要充分考虑训练效率和模型准确性之间的权衡**：

​       **对于单个客户端，从模型准确率和计算时间权衡的角度设计剪枝率**：较大的剪枝率有助于减少通信和计算开销，但是会显著降低模型的精度。相反，较小的剪枝率保证了模型的准确性，但计算和通信开销仍然很高。如图所示，限制模型的训练时间相同，准确率随着剪枝率的增加先上升后下降。当剪枝率比较小时，剪枝后的模型可以比剪枝率为0的原始模型获得更好的准确率，这是因为剪枝率较小的剪枝对模型的准确率影响较小，但是可以减少每轮训练时间，在给定的时间内可以训练更多轮次，从而获得更好的准确性。 然而，随着修剪率的增加，一些对结果重要性较高的神经元可能被删除，从而使准确率大幅下降。**根据实验结果，剪枝率的决策需要充分考虑训练效率和模型准确性之间的权衡。**

### B. 系统异构性对训练时间和模型准确率的影响：

​       当客户端的计算能力不相同时（对应于联邦学习中的cross-device场景），因为中心服务器需要等待所有或固定百分比的客户端上传模型用于大模型的参数更新，因此全局训练时间受限于计算能力较弱的客户端。若限制客户端训练的时间，则会造成计算能力较弱的客户端不能充分训练，从而导致该客户端的子模型和全局模型的测试准确率较低。**因此，需要针对不同客户的计算能力自适应地计算剪枝率。**

### C. **数据异构中的数据价值异构对模型准确率的影响**：

​       当客户端本地数据集的数据价值不相同时（数据异构），若对所有的客户端采取相同的剪枝率，，此时模型的性能虽然能够收敛，但是不一定能收敛到一个最优值，每个客户端的剪枝率也不一定是最优的剪枝率。**因此，需要针对不同客户端本地数据集的数据价值自适应地计算剪枝率。**

## 联邦学习贡献评估

### A. 数据估值指标

- 测试集依赖指标
  - **测试准确率**
- 测试集无关指标
  - 数据统计指标
    - **数据多样性度量**（隐私保护问题、未建立与测试集的联系）：格拉姆行列式价值度量函数：$$v(S)=\sqrt{\left(X_{S}^{T} X_{S}\right)}, X_{S} \in \mathbb{R}^{\mid D_{S}}{ }^{\mid \times d} $$
    - **多指标复合**（隐私保护问题、未建立与测试集的联系）：某特征的取值的均值、方差
  - 模型相似度
    - **梯度相似度**（梯度对齐问题）：$$v(S)=\sum_{t\in[0,\text{iter}]}\cos \left(u_{S}^{t}, u_{N}^{t}\right) / \text { iter }=\sum_{t\in[0,\text{iter}]} \frac{}{\left\|u_{S}^{t}\right\|\left\|u_{N}^{t}\right\|} / \text { iter } $$
    - **参数不确定性**（依赖于贝叶斯等离散模型）$$\mathrm{v}(\mathrm{S})=\mathbb{D}\left(\theta ; \mathrm{D}_{\mathrm{S}}\right)=\mathbb{H}(\theta)-\mathbb{H}\left(\theta \mid \mathrm{D}_{\mathrm{S}}\right), \mathbb{H}(\theta)=-\mathbb{E}[\log \mathrm{p}(\theta)]=-\sum_{\theta \in \theta} \mathrm{p}(\theta) \log \mathrm{p}(\theta) $$

![img](https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202304/20230410_1681119338.png)

### B. 参与方贡献评估方案

- 个体法（适合于参与方数量众多的跨设备联邦场景）
  - 个体信誉法29
  - 个体交叉验证法26
  - 个体互信息法37 41 42
- 夏普利值

![img](https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202304/20230410_1681119266.png)

### C. 贡献评估优化技术

## 基于多臂老虎机的剪枝率决策算法

### A. 在异构边缘计算场景中考虑**数据价值异构**

- 全局大模型的收敛：各客户端对模型收敛的贡献
- 适应异构边缘计算的场景：客户端的完成时间与平均完成时间之间的差距
- 数据价值的评估方法：联邦学习贡献公平性中的**数据评估方法**；**不能直接访问本地数据**；训练过程中**逐步**获得数据价值和边缘贡献的信息；初始的训练就是**不公平**的；
- 决策算法中的奖赏函数：$$R\left(\alpha_{n}^{k}\right)=\frac{ \Delta\text{value}_n^k}{\left|T_{n}^{k}-\frac{1}{N} \sum_{n^{\prime}=1}^{N} T_{n^{\prime}}^{k}\right|} $$

### B. 置信区间上界策略

- 玩家：中心服务器
- 摇臂：剪枝率

$$N_{k}\left(\lambda, \alpha_{n,j}^{k}\right)=\sum_{s=1}^{k-1} \lambda^{k-s} \mathbb{1}_{\{\alpha_{n,j}^{k}\}}  $$

$$\bar{R}_{k}\left(\lambda, \alpha_{n,j}^{k}\right)=\frac{1}{N_{k}\left(\lambda, \alpha_{n,j}^{k}\right)} \sum_{s=1}^{k-1} \lambda^{k-s} R\left(\alpha_{n,j}^{k}\right)\mathbb{1}_{\{\alpha_{n,j}^{k}\}}   $$

$$c_{k}\left(\lambda, \alpha_{n,j}^{k}\right)=\sqrt{\frac{2 \log \left[\sum_{j=1}^{l_{k}} N_{k}\left(\lambda, \alpha_{n,j}^{k}\right)\right]}{N_{k}\left(\lambda, \alpha_{n,j}^{k}\right)}} $$

$$\alpha_{n,j}^{k}=\arg \max \left[\bar{R}_{k}\left(\lambda, \alpha_{n,j}^{k}\right)+c_{k}\left(\lambda, \alpha_{n,j}^{k}\right)\right] $$

# 四、实验与结果

​       对本文提出的两种模型剪枝算法与FedMP、PruneFL、SynFL、UP-FL、FedProx、FlexCom等基线算法进行比较，比较的指标为**测试集准确率**和**达到指定准确率所需要的训练时间**。（测试准确率达到某个指标，或者训练轮次超过限制）

# 其他

## 假设

- 不考虑全局模型过拟合的问题
- 在假定联邦参与方的数据均对任务有利，不存在低贡献或者恶意参与方的情况下，可以认为全体参与方参与下联邦合作训练的全局模型最优。
- 随机初始化的密集神经网络包含一个子网工作，它被初始化，这样当单独训练时它可以在训练最多相同迭代次数后与原始网络的测试精度相匹配。

## Novelty

- 资源受限场景下：数据量不同（PruneFL）- 数据分布不同（FedDst）- 数据噪声（MyAlgor）
- 特征分布 - 标签分布 - 本地数据分布不平衡
- 数据分布：数据量不同、数据量相同分布不同（noniid）、**数据量和分布都不同（狄利克雷）**、加入数据噪声

## **工作量**

- 每个板块的消融实验、多种思路和方法？
- 增加基准实验对比？
- 接入与退出机制？计算能力动态变化？
- 同步与异步算法？
- 原型系统与树莓派？

## **仿真实验**

- 系统异构：随机数计算时间
- 数据异构

## 别的想法

Sub-FedAvg ICDCSW2021 B

Due to the statistical heterogeneity of clients, part of the channels (filters) and parameters are personalized to each client. By iteratively pruning the parameters and channels, we remove the commonly shared parameters of each layer and keep the personalized parameters that can represent the features of local data in each client.   **the clients with similar data (label overlap) have share similar personalized parameters**

FedSCR TPDS2021 A

Parameters in the same channel/filter have a higher probability of getting a similar parameter update pattern

While looking at the changes of the updated value in each parameter, we observe that a large number of parameters stay unchanged, leading to a sparse update matrix, particularly for the Non-IID data. One of the primary reasons is that for the Non-IID data, an edge worker might only contain images from a few classes, causing that only small parts of hidden elements, with related feature extraction, are updated while others remain unchanged.

The parameter update patterns among different workers are diverse when training on the Non-IID data; while the parameter update patterns are more predictable for those workers trained on the IID dataset.

Federated Unlearning WWW2022 A

different channels have a varying contribution to different categories in image classification

PruneFL TNNLS2022 B

mask：importance score

**FedDST** AAAI2022 A

[FedTiny: Pruned Federated Learning Towards Specialized Tiny Models](https://arxiv.org/abs/2212.01977)

Lottery Aware Sparsity Hunting_Enabling Federated Learning on Resource-Limited Edge

ZeroFL ICLR2022 A

[Federated Progressive Sparsification (Purge-Merge-Tune)](https://openreview.net/forum?id=YZIVv_37y2z)

[Complement Sparsification: Low-Overhead Model Pruning for Federated Learning](https://arxiv.org/abs/2212.01977)

[Achieving Personalized Federated Learning with Sparse Local Models](https://arxiv.org/pdf/2201.11380.pdf)

EXPANDING THE REACH OF FEDERATED LEARNING BY REDUCING CLIENT RESOURCE REQUIREMENTS

FjORD: Fair and Accurate Federated Learning under heterogeneous targets with Ordered Dropout  

目标1：降低全局模型训练时间：根据客户端计算能力自适应剪枝

目标2：提高全局模型的准确率：根据客户端数据分布（贡献）自适应剪枝

给每个客户端一个与全局模型对应的重要性分数，根据客户端计算能力决定掩码中0的数量，根据客户端的数据分布决定每个位置的重要性分数

重要性分数：本地数据对于全局模型的重要性（测试准确率、梯度相似度）、本地数据对于全局模型的重要性（loss）、全局模型参数对于全局模型的重要性（参数值、梯度幅值、**梯度平方**）

归一化随机梯度

FedDU利用服务器数据动态确定服务器更新的最佳步骤，同时考虑服务器数据和设备数据的非独立同分布度，以提高全局模型的收敛性和准确性。