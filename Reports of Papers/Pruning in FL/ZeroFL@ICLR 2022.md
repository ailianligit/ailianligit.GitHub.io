# [ZeroFL@ICLR 2022] ZEROFL: EFFICIENT ON-DEVICE TRAINING FOR FEDERATED LEARNING WITH LOCAL SPARSITY  

## Abstract

当可用硬件无法满足有效训练高性能机器学习模型的内存和计算要求时，需要在训练质量或模型复杂性方面做出妥协。 在联邦学习 (FL) 中，节点比传统的服务器级硬件受到更多数量级的限制，并且通常由电池供电，严重限制了可以在此范例下训练的模型的复杂性。 虽然大多数研究都集中在设计更好的聚合策略以提高收敛速度和减轻 FL 的通信成本，但很少有人致力于加速设备上的训练。 这个阶段重复数百次（即每一轮）并且可能涉及数千台设备，占训练联合模型所需时间的大部分以及客户端的总能耗。 在这项工作中，我们首次研究了在 FL 工作负载的训练时引入稀疏性时出现的独特方面。 然后，我们提出了 ZeroFL，这是一个依赖高度稀疏操作来加速设备上训练的框架。 与通过将最先进的稀疏训练框架应用于 FL 设置而获得的竞争基线相比，使用 ZeroFL 和 95% 稀疏度训练的模型可实现高达 2.3% 的准确性。



## Introduction

与通常在云端进行并使用强大硬件的标准集中式训练不同（Hazelwood 等人，2018 年），FL 被设想在智能手机或物联网设备等商品设备上运行，这些设备通常运行电池，这是订单 在计算、内存和功耗方面受到更多限制（Qiu 等人，2021 年）。 这三重因素极大地限制了可以在设备上以联合方式训练的 ML 模型的复杂性，从而限制了它们对上述应用程序的实用性。 为了将复杂 ML 模型的内存和计算足迹调整为 FL 设置，研究界提出了许多方法，包括：使用蒸馏（Hinton 等人，2015 年）在服务器端实现聚合 协作训练单个全局模型的异构模型架构（例如，基于每个设备的计算能力）（Lin 等人，2020 年；Zhu 等人，2021 年）； 群体知识转移算法（He et al., 2020）； 联合 dropout，客户端通过它对全局模型的子模型进行本地训练（Caldas 等人，2019 年），转化为更低的整体通信成本，并且能够更好地支持异构客户端池，无论它们的计算能力如何（Horvath 等人，2021 年）； 更一般地说，更好的聚合策略可以实现更快的收敛（Li et al., 2018; Reddi et al., 2021），以这种方式减少整体设备利用率（例如更少的本地 epoch）和通信轮数。 量化和稀疏性等其他优化技术已在 FL 的上下文中使用，但主要是作为降低通信成本的一种方式（Liu 等人，2021 年；Amiri 等人，2020 年；Shahid 等人，2021 年），但不是 加速设备上的培训。

在训练时使用稀疏操作（例如卷积）最近被证明是在集中设置中加速训练的有效技术（Sun et al., 2017; Goli & Aamodt, 2020; Raihan & Aamodt, 2020）。 尽管他们的 FLOPs 预算减少了高达 90%，但由此产生的模型与经过密集训练的模型一样好或接近，并且整体训练速度提高了 3:3 倍。 加速是通过在前向和/或反向传递期间执行稀疏卷积来实现的，这需要至少一个操作数（即输入、权重、梯度）足够稀疏，并且需要软件和硬件支持此类操作。 然而，目前还不清楚不同的 FL 特定挑战（即数据不平衡、无状态客户端、周期性聚合）将如何限制全局模型的质量。

这项工作考虑了引入高水平稀疏性以加速 FL 工作负载的设备上训练的挑战和机遇，并提供了以下贡献：

联邦学习的第一个框架，它利用稀疏性作为一种机制，通过引入高达 95% 的稀疏权重和激活来加速设备上的训练。 这项工作考虑了三个流行的数据集：用于图像分类的 CIFAR-10 和 FEMNIST 以及用于音频分类的 SpeechCommands。

一项关于在 FL 训练时引入稀疏性时出现的独特方面的研究：非零值之间的重叠程度随着层深度指数的增加而降低，并且全局模型中零值权重的位置在大多数情况下保持不变 训练回合。 我们的讨论为该领域的未来研究奠定了基础。

一种在将最先进的现成稀疏化方法应用于 FL 域时减轻精度下降的技术。 当分别引入 90% 和 95% 的稀疏度时，ZeroFL 的准确度比基线高 +2.3% 和 +1.5%。 此外，ZeroFL 在将本地模型传输到中央服务器时还利用了稀疏性，将通信成本降低了 3:0 倍，同时仍然优于竞争基线。







