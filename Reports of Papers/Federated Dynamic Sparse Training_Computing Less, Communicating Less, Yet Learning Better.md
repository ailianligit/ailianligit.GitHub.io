# [FedDST@AAAI'22] Federated Dynamic Sparse Training: Computing Less, Communicating Less, Yet Learning Better

## Abstract

联合学习 (FL) 可以将机器学习工作负载从云端分配到资源有限的边缘设备。 不幸的是，当前的深度网络不仅对于边缘设备上的推理和训练来说计算量太大，而且对于通过带宽受限的网络进行更新通信来说也太大了。 在本文中，我们开发、实施并通过实验验证了一种称为联合动态稀疏训练 (FedDST) 的新型 FL 框架，通过该框架可以部署和训练复杂的神经网络，并显着提高设备上计算和网络内通信的效率。 FedDST 的核心是一个从目标全网络中提取和训练稀疏子网络的动态过程。 有了这个方案，“一箭双雕：”而不是完整的模型，每个客户端都对自己的稀疏网络进行高效训练，并且只有稀疏网络在设备和云端之间传输。 此外，我们的结果表明，与固定的共享稀疏掩码相比，FL 训练期间的动态稀疏性更灵活地适应 FL 代理中的局部异质性。 此外，**动态稀疏性**自然地将“及时自集成效应”引入训练动态中，甚至在密集训练中也能提高 FL 性能。 在现实且具有挑战性的非 i.i.d. 在 FL 设置下，FedDST 在我们的实验中始终优于竞争算法：例如，在非 iid CIFAR-10 上的任何固定上传数据上限下，在给定相同的上传数据上限时，它比 FedAvgM 获得了 10% 的令人印象深刻的准确性优势； 即使 FedAvgM 的上传数据上限是 2 倍，准确度差距仍为 3%，进一步证明了 FedDST 的有效性。 代码位于：https://github.com/bibikar/feddst。



## Introduction

在**保护个人数据隐私**和在**边缘启用机器学习** (ML) 的愿望的推动下，联邦学习 (FL)（McMahan 等人 2017 年；Kairouz 等人 2019 年）最近成为了实现分布式的实际范例 ML 在大量客户端设备上。 在 FL 系统中，中央云服务器在客户端网络中调解信息传输，这些客户端必须保持其本地数据的私密性。 FL 中的经典方法 (McMahan et al. 2017) 涉及多个同步回合； 在每一轮中，FL 仅使用每个设备上本地可用的数据在设备子集上运行几个本地训练时期。 在本地训练之后，客户端的模型更新而不是本地数据被发送到中央服务器，然后中央服务器将它们全部聚合以更新全局模型。

在 FL 系统中，繁重的计算工作负载从云端分派到资源有限的边缘设备。 为了在边缘使用，FL 系统必须同时优化设备级**本地训练效率**和**网络内通信效率**。 不幸的是，当前的 ML 模型通常过于复杂，无法在边缘设备上进行推理，更不用说训练了。 除了模型的紧凑性，云和设备之间的通信效率也是可取的。 由于不对称的互联网连接，客户端设备（例如手机）通常具有严重的**上传带宽限制**，因此降低联邦学习算法的上传成本至关重要。 高效通信 FL 的许多先前工作都集中在 FL 更新中的结构化和草图稀疏性（Konecnˇ y et al.´ 2017）、最佳客户端抽样（Ribero 和 Vikalo 2020）和其他经典方法。

为了生成用于边缘设备推理的轻量级模型，人们在优化稀疏神经网络 (NN) 方面做出了重大努力（Gale、Elsen 和 Hooker，2019 年；Chen 等人，2020 年、2021 年；Ma 等人，2021 年）。 这些方法显着减少了推理延迟，但严重影响了训练所需的计算和内存资源。 彩票假说 (Frankle and Carbin 2018) 表明**密集 NN 包含稀疏匹配子网络**，这些子网络能够独立训练以达到完全准确度（Frankle 等人 2020）。 更多作品表明稀疏性可以在初始化时出现（Lee、Ajanthan 和 Torr 2019；Wang、Zhang 和 Grosse 2020）或者可以在训练期间以动态形式被利用（Evci 等人 2020）。

本文的总体目标是开发、实施和实验验证一种称为联合动态稀疏训练 (FedDST) 的**新型 FL 框架**，通过该框架可以**部署和训练**复杂的神经网络，同时显着提高设备上**计算和内部计算**的效率。 网络通讯。 FedDST 的核心是一种精心设计的动态稀疏训练联邦方法（Evci 等人，2020 年）。 FedDST 传输客户端的高度稀疏匹配子网络而不是完整模型，并允许每个客户端插入高效的稀疏分布式训练——从而“一石二鸟”。 更重要的是，我们发现 FL 训练期间的动态稀疏性比最先进的算法更能适应 FL 中的**局部异质性**。 动态稀疏性本身会导致及时的自集成效应 (Liu et al. 2021c) 并提高 FL 性能，甚至超过密集训练对应物，这与独立训练中的观察结果相呼应 (Liu et al. 2021c)。 我们将我们的贡献总结如下：

我们首次将动态稀疏训练引入联邦学习，从而无缝集成稀疏 NN 和 FL 范式。 我们的框架名为联合动态稀疏训练 (FedDST)，它利用稀疏性作为统一工具来节省通信和本地培训成本。

通过使用灵活的聚合方法，我们在 FedAvg 之上部署了 FedDST（McMahan 等人，2017 年），没有来自客户端的额外传输开销。 作为一般设计原则，我们的方法很容易扩展到其他 FL 框架，例如 FedProx (Li et al. 2018)。 此外，动态稀疏性的概念被发现可以**适应局部异质性**，并产生**及时自集成**的额外效果，即使在密集基线上也能提高 FL 性能。

大量实验表明，FedDST 显着提高了在病理非独立同分布数据分布的难题上的通信效率。 即使在这些非 iid 设置中，FedDST 在 CIFAR-10 上也比 FedAvgM（Hsu、Qi 和 Brown 2019）提高了 3% 的准确性，同时只需要一半的上传带宽。 我们还提供广泛的**消融**研究，显示 FedDST 对其参数的合理变化的**稳健性**。 这些结果表明稀疏训练是未来 FL 的“首选”选项。



## Related Work

### Federated Learning

在联合学习中（Kairouz 等人，2019 年），一组客户端 j ∈ [N] 在中央协调服务器的参与下协作学习一个或多个模型。 每个客户端都有一小组训练数据 Dj 用于本地训练，但为了保护用户隐私，客户端不共享其本地训练数据。 在这项工作中，我们尝试学习全局模型 θ，旨在最小化全局损失

在 **FedAvg**（McMahan 等人，2017 年；Hsu、Qi 和 Brown，2019 年）算法系列中，训练在交流回合中进行。 开始每一轮 i 时，服务器选择一组客户端 Ci 并将当前服务器模型参数 θi 发送给客户端。 每个客户端 j ∈ Ci 使用其本地训练集对接收到的模型执行 E 轮训练以产生参数 θji，并将其上传到服务器； 在 FedAvg 中，客户端本地训练是通过 SGD 执行的。 然后，服务器使用采样客户端参数的加权平均值更新全局模型。 雷迪等人。 (Reddi et al. 2021) 认为客户端产生的更新可以被解释并用作伪梯度。 因此，他们将 FedAvg 概括为 FedOpt 框架，该框架允许“插入”不同的客户端和服务器优化器。

由于非独立同分布的数据分布、客户端异构性以及边缘计算、内存和带宽有限，现实世界的 FL 设置提出了许多挑战（Kairouz 等人 2019 年；Hong 等人 2021 年）。 客户端计算能力的异质性导致所谓的散乱者问题，其中某些客户端需要“太长时间”来形成模型更新，而服务器必须在没有它们的情况下继续进行。 Hsu 等人（Hsu、Qi 和 Brown 2019）在 FedAvgM 中证明，向客户端优化器添加动量项可以持续提高非 iid 设置中的性能。 李等。 (Li et al. 2018) 提出了 **FedProx**，它为 FedAvg 添加了一个近端惩罚，并允许落后者提交部分更新。

对于高效通信的 FL，Konecny 等人。 (Konecn ˇ y´ et al. 2017) 区分草图更新，其中模型更新在通信期间被压缩，**但在本地训练期间不被压缩**； 和结构化更新，其中本地训练**直接在压缩表示上执行**。 相对较少的现有技术在整个 FL 过程中讨论修剪或权重重新调整。

### Network Pruning

模型剪枝旨在通过移除连接从更大的神经网络中选择稀疏子网络。 传统上，剪枝方法从高度过度参数化的训练模型开始，删除连接，并对剪枝后的模型进行微调。 修剪的共同目标包括节省计算、内存、通信或其他资源。 许多选择标准都是可能的，包括体重幅度（Han、Mao 和 Dally 2015）、最佳脑损伤（LeCun、Denker 和 Solla 1990；Hassibi 等人 1993；Dong、Chen 和 Pan 2017）、零激活（Hu 等人 2016 年）和泰勒展开式（Molchanov 等人 2017 年）。

最近的其他研究提出了多种算法来在初始化时执行“单次”修剪。 李等。 （Lee、Ajanthan 和 Torr 2019）通过对小批量进行采样并按连接的灵敏度对连接进行排序来在初始化时选择连接。 王等。 （Wang、Zhang 和 Grosse 2020）类似地在初始化时对小批量进行采样，但尝试在修剪后保留梯度流。

### Dynamic Sparse Training

动态稀疏训练 (DST) 在整个训练过程中定期移动选定的子网络，始终保持恒定数量的参数。 开创性的工作 (Mocanu et al. 2018) 提出了 **SET** 算法，该算法迭代地修剪最小幅度的权重并增长随机连接。 SET 还按层维护模型密度的特定分布，遵循 Erdos-R enyi 随机图拓扑，该拓扑根据输入和输出连接的数量缩放层的密度。 在 **RigL** (Evci et al. 2020) 中，作者随机初始化稀疏掩码并执行逐层幅度修剪和梯度幅度权重增长。 与 (Mocanu et al. 2018) 一样，他们遵循特定的逐层稀疏分布，并为卷积层引入 ERK 稀疏分布，从而通过连接数和内核大小来缩放它们的密度。 刘等人。 (2021c) 展示 DST 从参数探索中获得的好处； 具体来说，通过探索许多可能的稀疏网络，DST 能够有效地执行**“时间自集成**”，即使在密集网络上也能获得性能优势（Liu et al. 2021a,b）

### Pruning in Federated Learning

据我们所知，只有两个作品解决了整个 FL 过程中的修剪问题。 PruneFL (Jiang et al. 2020) 依赖于在特定客户端选择的初始掩码，然后是类似 FedAvg 的算法，该算法每 ΔR 轮执行掩码重新调整。 然后通过稀疏矩阵操作进行训练。 在掩码调整轮次中，客户端需要上传完整的密集梯度，服务器使用这些梯度来形成聚合梯度 g。 选择掩码时，对应于可修剪权重的索引 j 按 gj2=tj 排序，其中 tj 是在网络中保留连接 j 的时间成本的估计。 通过测量具有各种稀疏性的一轮 FL 的时间成本，通过实验确定估计值 tj。 其次，与 PruneFL 不同，FedDST 是为具有挑战性的、现实的非 iid FL 设置而设计的。 出于这个原因，FedDST 的聚合和动态稀疏训练允许在客户端重新调整掩码，以 PruneFL 的自适应修剪标准无法实现的方式为非 iid 数据提供弹性。 特别是，PruneFL 的客户不会在第一轮之后重新调整掩模； 相反，它们会在某些回合将梯度传输到服务器，服务器使用梯度幅度和层时间来决定下一轮的掩码。 **由于数据异质性意味着无法在客户端之间直接比较梯度大小，因此梯度聚合本质上是不稳定的。** FedDST 通过仅使用客户端提交的权重大小和掩码“投票”来决定服务器上的掩码，从而提供稳定的更新。 我们的实验证明了 FedDST 与 PruneFL 在泛化能力方面的优势。

LotteryFL (Li et al. 2020) 从 LGFedAvg (Liang et al. 2020) 中汲取灵感，并允许客户端通过选择全球网络的本地子集来维护本地表示。 它也可以描述为 FedAvg 的扩展，其中每个客户端 c 维护一个单独的掩码 mc。 在每一轮 r 中，选定的客户端使用本地验证集评估他们的子网络 θr ⊙ mr c。 如果验证精度超过预定义的阈值并且客户端当前的稀疏度 kmr ck0 小于目标稀疏度，则执行幅度剪枝以产生新的掩码 mr c+1 并将相应的权重重置为其初始值。 将 FedDST 与 FL 中的先前修剪工作进行比较。 首先，与 **LotteryFL 生成的稀疏模型系统仅在本地数据集上表现良好**不同，FedDST 生成一个全局稀疏模型，随着时间的推移动态变化，在任何地方都表现良好。 FedDST 在客户端和服务器上执行掩码重新调整，但这些都是相对低开销的操作（逐层幅度修剪和梯度幅度增长）。 而且，FedDST 既不传输密集模型，也不传输梯度，甚至在最开始也不训练密集模型：这与 LotteryFL 形成鲜明对比，使 FedDST 明显更轻。

由于整个训练过程中固定的稀疏预算，FedDST 更新需要非常少的网络带宽，即使在最坏的情况下也是如此。 尽管 PruneFL 也为大多数轮次传输稀疏更新，但它每隔几轮就将全密集梯度传输到服务器以促进掩码重新调整。 LotteryFL 要求客户端传输密集模型，除非其精度达到一定阈值，因此密集传输发生得更频繁。



## Methodology

FedDST 为神经网络的动态稀疏训练提供了一种完全联合的方法。 在这种方法中，我们的目标是**学习一个单一模型，为所有客户端提供良好的准确性**，同时消耗最少的计算、内存和通信资源。 我们的方法旨在即使在病理上非独立同分布的情况下也能表现良好。

我们首先在服务器上初始化服务器网络 θ1 和稀疏掩码 m1，遵循 (Evci et al. 2020) 中描述的逐层稀疏分布。 在每一轮 r，服务器对客户端 Cr 进行采样。 服务器网络和掩码被发送到客户端 c ∈ Cr。 每个客户执行 E 轮的局部训练。 在局部训练的 Ep-th epoch 之后，客户端执行掩码调整，将模型质量的 αr 重新分配给不同的连接。 仅在某些回合进行重新调整，重新调整的频率由ΔR指定

选定的客户端将其新的稀疏网络和掩码（如果需要）上传到服务器，服务器聚合接收到的信息以产生新的全局参数和掩码（θr+1；mr+1）。 服务器端聚合方法将在本节后面讨论。

客户端掩码调整过程很熟悉，灵感来自 RigL (Evci et al. 2020)。 mask 调整的目标是重新分配模型质量的 αr，以寻求更有效的子网络。 我们首先将网络修剪为更高的稀疏度 S + (1 - S)αr，同时保持相同的权重分布。 然后，我们通过梯度 gcr 重新生成相同数量的被修剪的权重，返回到相同的原始稀疏度。 因为一轮中不同的客户端可能会产生不同的掩码，服务器必须聚合多个可能在完全不同的方向探索掩码空间的稀疏网络。 与 (Evci et al. 2020; Dettmers and Zettlemoyer 2019) 一样，我们对 αr 使用余弦衰减更新时间表，

在第一轮，我们有 α1 = α，每次重新分配的权重比例在 Rend 轮衰减到 0。 参数 α 控制掩码空间探索与客户之间就掩码决策达成一致之间的权衡。 较大的 α 值鼓励在掩码空间周围更快地移动，而较小的值鼓励掩码的一致和增量调整。 我们在实验中探索了 α 的影响。

因为服务器不直接从客户端接收梯度，所以它必须仅使用从客户端接收的参数和掩码来决定下一轮的掩码。 由此，我们定义稀疏加权平均值：

该方法的灵感来自 FedAvg（McMahan 等人，2017 年）中使用的加权平均值，其中特定客户端对特定参数的影响由该客户端的数据集大小加权。 但是，稀疏加权平均值也忽略了未提供任何值的客户端的参数值。 特别是，如果客户端已经删除了一个权重，则出于聚合该权重的目的，将忽略该客户端。 特别是在病理性非同源性 FL 设置中，我们发现 FedDST 从这种掩码聚合方法中受益匪浅。 客户端之间不能直接比较随机梯度的大小，因为客户端之间的数据分布差异很大。 出于这个原因，诸如 PruneFL 之类的方法在相同的设置中表现出掩模不稳定问题。 FedDST 使用大量的权重和来自客户的“投票”来解决这个问题。

动态稀疏性带来的准确性增益：时空集成效应。 我们的实验表明，FedDST 不仅节省了通信/计算，而且还提高了性能：这在高度非 i.i.d. 中尤为显着。 设置。 我们将“少即是多”现象归因于 FedDST 独有的潜在时空“集成效应”。

在“空间”方面，我们指的是在 FedDST 中，一个掩码从云端发送到所有客户端，但每个客户端都可以重新调整他们的掩码并根据其非 i.i.d. 重新采样权重。 本地数据。 这些新的稀疏掩码和权重会在云中定期重新组装，让人想起著名的模型子采样和“dropout”的集成效应（Hinton 等人，2012 年），现在沿着 FL 的空间维度（跨客户端）。 也就是说，每个客户端都可以被视为密集云模型的不同采样子网（不是随机的，而是“学习的丢失”），这样可以通过集成这些子网络权重来为云模型训练更强大的权重提供正则化效果 . 请注意，这种类似的效果不会发生在 PruneFL 中，其中所有客户端每次都共享一个掩码。 虽然 LotteryFL 还允许每个客户端拥有自己的掩码，但它会带来沉重的本地计算开销。 在“时间”方面，FedDST 通过时间探索掩码空间，同时还学习权重 θr。 总而言之，它允许跨训练进行连续参数探索，驯服时空过度参数化（Liu et al. 2021c），这可以显着提高稀疏训练的可表达性和泛化性。

从上面的基本示例来看，FedDST 可以轻松适应不同的局部和全局优化器，如 (Reddi et al. 2021) 中所述。 算法 1 显示了 FedDST 的总体轮廓，其中本地训练可以根据需要使用任何优化器。 例如，我们使用 (Hsu, Qi, and Brown 2019) 中描述的具有动量的 SGD 作为我们实验中的局部优化器。 聚合稀疏更新生成的伪梯度也可以与其他全局优化器一起使用。 FedDST 也兼容 FedProx (Li et al. 及其近端惩罚项 kθcr - θrk2。但是，如果此惩罚项直接用于 mask 调整，则该惩罚项将作为已被修剪掉的权重的权重衰减项。这些权重 因此，将不太可能被选择用于再生。因此，在客户端增长中，我们使用与损失相对应的梯度，而没有近端项。



## Experiments

我们使用 MNIST（LeCun、Cortes 和 Burges 2010）和 CIFAR-10（Krizhevsky 2009）**数据集**分布在“病理上非独立同分布”设置中的客户端，类似于（McMahan 等人，2017 年）并匹配（ 李等人 2020）。 我们假设总共有 **400 个客户**。 每个客户被分配到 2 个班级，并从每个班级获得 20 张训练图像。 为了以非独立同分布方式分发 CIFAR-100 (Krizhevsky 2009)，我们对每个类别使用**狄利克雷 (0:1) 分**布，将其样本分发给 400 个客户，如 (Wang et al. 2020; Li, He, 和 Song 2021；Wang 等人 2021）。 这些分布代表了一个具有挑战性和现实的训练环境，只有一小部分训练数据可用并且以严重的非 iid 方式分布在客户之间。 我们在附录中提供了所有数据集的更多详细信息。

### Main Results

我们将 FedDST 与具有竞争力的最先进基准进行比较。 FedAvgM (Hsu, Qi, and Brown 2019) 和 FedProx (Li et al. 2018) 都是为非 iid 设置设计的。 我们将 PruneFL (Jiang et al. 2020) 作为涉及 FL 中动态稀疏性的另一种方法。 如前所述，PruneFL 依赖于客户端上传的随机梯度，因此其掩码在重新配置之间表现出不稳定性。 在 PruneFL 收敛的情况下，它选择了一个全一掩码，恢复了普通的 FedAvg。 请注意，由于 FedDST 的目标是在每一轮中生成一个在所有客户端上都表现良好的模型，因此我们不会与为每个客户端生成单独模型的算法进行比较，例如 LG-FedAvg (Liang et al. 2020) 和 LotteryFL (Li et al. 2020) 等人 2020）。

对于 RandomMask，我们在服务器上随机采样权重，然后在第一轮之前按照 ERK 稀疏分布（Evci 等人 2020）执行逐层幅度剪枝，并在此稀疏网络上执行 FedAvgM。 在整个训练过程中，选择的随机掩码作为全局和局部稀疏掩码保持不变。 RandomMask 代表了这种非独立同分布设置的强大的通信效率基线，其中随机梯度的噪声幅度导致依赖梯度聚合的方法（例如 PruneFL）失败。 此外，此环境中的数据异构性导致 GraSP 选择一个掩码，该掩码适用于最初选择的客户端，但作为全局掩码效果不佳。 尽管环境充满挑战，但 FedDST 仍然比强大的 RandomMask 基线产生了显着的准确性改进。

表 1、2 和 3 提供了 FedDST 和其他算法在给定特定上传带宽限制的情况下实现的准确度。 我们报告在每个限制之前看到的最佳测试准确度，平均 10 次运行。 FedDST 在任何上传限制下始终提供最佳性能，在我们测试的所有设置中相对于 FedAvgM 的上传成本减半。

### Insensitivity to Variations in α

在图 2 中，我们展示了 FedDST 在任何合理的 α 值下都表现良好，即使在我们在本文中探索的非 iid 设置中也是如此。 FedDST 所针对的非独立同分布会导致客户端产生嘈杂的随机梯度。 因此，直接使用梯度的大小来产生蒙版重新调整会导致蒙版发生很大变化。 FedDST 通过仅使用顶部局部随机梯度为特定权重指数“投票”有效地回避了这个问题。 参数 α 指定应将这些“选票”中的多少提交给服务器。 然而，适合的 α 值仍然小于 RigL； 对于 α ∈ [0:001; 0:05]，FedDST 明显优于其他方法。

### Performance at Different Sparsity Levels

在图 3 中，我们展示了 FedDST 的性能对于稀疏度的变化是稳健的。 由于稀疏性直接导致通信节省，FedDST 在相对较高的稀疏性下表现最佳，即使在我们在这里测试的轻量级 NN 上也是如此。 然而，即使在未调整的稀疏度水平上，FedDST 的表现也相当不错，收敛速度也比 FedAvgM 快得多，尤其是在 FL 过程开始时。 因此，我们以 0:5 或 0:8 的稀疏度运行所有 FedDST 实验。



## Conclusion and Broader Impacts

我们介绍了联邦动态稀疏训练 (FedDST)，这是一个通过动态稀疏训练实现高效通信联邦学习的强大框架，即使在病理性非独立同分布数据集上也能很好地工作。 我们通过实验表明，FedDST 始终优于竞争算法，在非独立同分布 CIFAR-10 上的上传带宽仅为 FedAvgM 的一半，其准确性比 FedAvgM 高出 3%。我们进一步证明 FedDST 与其他流行的联邦优化框架（如 FedProx）兼容。 我们的结果表明即使在最困难的 FL 设置中稀疏性也有光明的未来。

FL 有可能在用户数据隐私至关重要的情况下实现学习 NN。 例如，医疗数据集受到严格的法律限制，不能在客户之间交换。 此外，FL 可以在涉及用户数据的现有机器学习设置中提供更强的隐私保证。 FedDST 专注于提高通信效率和性能，使更多 FL 设置在野外变得实用。
