## \section{基于贡献评估的聚合算法}

\label{sec:contribution-aggregation}

为了评估客户端在联邦训练中的贡献，并根据贡献的大小调整客户端的参与程度，本章首先在\label{subsec:shapley-contribution}节介绍了基于余弦梯度夏普利值的贡献评估方法，然后，\label{subsec:contribution-effective}节展示了贡献评估方法在样本标签非独立同分布和加入不同比例的噪声时的有效性，最后，\label{subsec:aggregation-design}节介绍了基于贡献评估的聚合算法的设计细节。



### \subsection{基于余弦梯度夏普利值的贡献评估方法}

\label{subsec:shapley-contribution}

因为数据价值低或者贡献小的客户端可能会为联邦训练提供有限的甚至错误的知识，而这些客户端的大量参与可能会对联邦训练的效果产生负面影响\cite{kairouz2021advances}，因此对客户端进行合理且有效的贡献评估是非常重要的。其中，样本标签的非独立同分布和含噪的比例都会对客户端的数据价值产生影响，从而影响客户端对于联邦模型训练效果的贡献大小。此处需要说明的是，客户端的数据价值和对联邦训练的贡献并不是完全等同的概念，因为一些低价值的客户端可能只有一些少量的但关键的样本，能帮助联邦训练突破局部最优解，因此在联邦学习的贡献评估领域，考虑客户端的边际价值增益是更为合理的选择\cite{王勇2022联邦学习贡献评估综述}。

在联邦学习贡献评估的众多方法中，合作博弈领域的夏普利值法\cite{kuhn1953contributions}通常被认为是一个相对可靠的解决方案，也被广泛用于评估联邦学习框架中各个客户端的贡献。夏普利值的计算方法如等式\ref{eq:shapley-value}所示，其中$\pi \in \Pi$的含义是所有客户端的一种排列，反映了客户端加入排列的先后顺序，而$\mathcal{S}_{\pi, n}$代表排列$\pi$中排在客户端$n$之前的客户端组合，$v$的含义是客户端组合的贡献评估值。因此，夏普利值$\phi_{n}$可以枚举客户端$n$所有的以不同次序加入排列的情况，计算这些情况下客户端$n$带来的期望价值增益，并以此作为其对联邦训练的贡献。具体来说，夏普利值的数值越大，则客户端对联邦训练的贡献也就越大。另外，夏普利值具备的合理性、对称性、零贡献、可加性等性质\cite{dubey1975uniqueness}使得夏普利值法相比其他贡献评估方法更加公平和合理。
$$
\phi_{n}:=\mathbb{E}_{\pi \in \Pi}\left[v\left(\mathcal{S}_{\pi, n} \cup\{n\}\right)-v\left(\mathcal{S}_{\pi, n}\right)\right]
$$
\begin{equation}
    \label{eq:shapley-value}
	\phi_{n}:=\mathbb{E}_{\pi \in \Pi}\left[v\left(\mathcal{S}_{\pi, n} \cup\{n\}\right)-v\left(\mathcal{S}_{\pi, n}\right)\right]
\end{equation}

然而，夏普利值法并不适用于本文的场景。因为计算夏普利值需要枚举客户端所有的以不同次序加入排列的情况，复杂度高达$O(2^N)$，而本文的目标是训练一个性能良好的联邦模型，因此在贡献评估上花费大量的时间是不必要的。另外一些夏普利值的估计方法\cite{dai2018toward,sim2020collaborative}则需要一个辅助的验证数据集，不符合本文设置的场景。为了克服上述挑战，CGSV算法\cite{xu2021gradient}提出用余弦梯度夏普利值对真实的夏普利值进行近似，并通过理论证明了二者之间仅存在一个有界的误差，因此无需高复杂度的计算和辅助的验证数据集。余弦梯度夏普利值的计算方法如等式\ref{eq:cos-shapley}所示，其中$u_n^t$代表客户端$n$在通信轮次$t$的参数更新，而$U^t$表示通过加权聚合后的联邦参数更新。余弦梯度夏普利值反映了客户端模型参数更新与联邦模型参数更新之间的余弦相似度，$u_n^t$和$U^t$的余弦相似度越大，客户端$n$的对联邦训练的贡献越大，反之则贡献越小。
$$
\psi_n^t:=\cos (u_n^t,U^t)
$$
\begin{equation}
    \label{eq:cos-shapley}
    \psi_n^t:=\cos (u_n^t,U^t)
\end{equation}

为了让客户端的贡献评估更加准确和稳定，其值以迭代的方式进行计算。\label{subsec:aggregation-design}节将客户端的贡献与其聚合权重联系起来，通过贡献评估调整客户端对联邦训练的参与程度，因此$r_n^{t}$既代表了客户端$n$在通信轮次$t$的聚合权重，也代表了客户端$n$在联邦训练开始后的贡献。初始聚合权重$r_n^0$设置为客户端$n$的数据量占总数据量的比例，而等式\ref{eq:important-score}展示了每个通信轮次中每个客户端的聚合权重的计算方式，其中$\gamma$是权衡系数，$\gamma=1$时整个联邦学习的框架退化为FedAvg算法。$\gamma$的值越大，则贡献评估更看重训练后期客户端的贡献，有效减轻模型参数随机初始化产生的噪声。$\gamma$的值越小，则贡献评估更看重训练前期客户端的贡献，或者更多地考虑客户端数据量地影响。\label{subsec:exp-aggregation-superparameters}对$\gamma$的设置进行了讨论。值得注意的是，在等式\ref{eq:important-score}之后，还需要对聚合权重进行归一化，以保证所有客户端的聚合权重之和为1。
$$
r_n^{t+1}:=\gamma r_n^{t} + (1-\gamma)\psi_n^t
$$
\begin{equation}
    \label{eq:important-score}
    r_n^{t+1}:=\gamma r_n^{t} + (1-\gamma)\psi_n^t
\end{equation}



### \subsection{贡献评估方法的有效性}

\label{subsec:contribution-effective}

数据异构

**噪声数据**

结果表明，所提出的方法有效地识别了带有噪声标签的参与者



### \subsection{聚合算法的设计}

\label{subsec:aggregation-design}

贡献评估方法常用于联邦学习的激励机制和公平性的设计中，本节将讨论贡献评估对于客户端参与程度和联邦模型训练效果的作用。

联邦梯度聚合根据参与方贡献加权[26]，即降低低贡献参与方梯度对模型参数更新的影响。  

参与程度 降低噪声标签对联邦学习性能的影响

非独立同分布时加速训练

因此，基于贡献评估调整客户端的参与程度对联邦模型训练效果的提升具有积极的作用。



在每个通信轮次$t=1,2,\cdots,T$，服务器需要将客户端训练好的模型聚合起来，融合成为一个全局模型。在FedAvg算法\cite{mcmahan2017communication}中，模型以加权的方式进行聚合：$\theta^{t+1}\leftarrow\sum_{n=1}^N r_n^t\theta_n^t$。与之稍有不同的是，本文使用参数更新进行聚合，可以通过简单的推导证明两种聚合方式是等效的。$\Delta\theta^{t}_n$表示客户端$n$在通信轮次$t$训练前后模型参数的变化，通过训练后的模型参数与训练前的模型参数相减得到，并通过归一化防止梯度爆炸（gradient explosion）：$u_n^t\leftarrow\frac{\Delta\theta_n^{t}}{\lVert\Delta\theta_n^{t}\rVert}$。服务器接收到客户端发送的参数更新后，加权聚合得到聚合参数更新：$U^t\leftarrow\sum_{n=1}^Nr^{t}_n u_n^t$，最后更新联邦模型参数：
$$
\theta^{t+1}\leftarrow\theta^{t}+U^t
$$
\begin{equation}
    \label{eq:param-update}
	\theta^{t+1}\leftarrow\theta^{t}+U^t
\end{equation}



CGSV算法【】和FOC算法【】的实验证实了

节的实验

所提出的方法有效地识别了带有噪声标签的参与者，并减少了他们对 FL 模型性能的影响

超参数实验

剪枝率 贡献评估实验



![image-20230314225313619](https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230314_1678805682.png)

![image-20230314215815586](https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230314_1678802299.png)

![image-20230314215830449](https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230314_1678802313.png)



## \section{聚合算法的消融实验和超参数实验}

\label{subsec:exp-aggregation}

## \subsection{消融实验}

\label{subsec:exp-aggregation-ablation}



## \subsection{超参数实验}

\label{subsec:exp-aggregation-superparameters}

超参数变化 **噪声数据**

--distribution iid dirichlet
--beta 0.1 0.5

--sparsity 0.5

--grad-agg
--tradeoff 0.0 0.2 0.4 0.6 0.8 1.0

--outfile
--device

稳定性与探索之间的权衡

| 调整率 | non           | 0.0       | 0.2       | 0.4            | 0.6           | 0.8           | 1.0           |
| ------ | ------------- | --------- | --------- | -------------- | ------------- | ------------- | ------------- |
| 0.1    | **0.52653** a | 0.38625 c | 0.45494 a | **0.3252 b+c** | **0.4308 x**  | **0.39197 b** | 0.416720003 b |
| 0.5    | **0.61985** a | 0.53255 a | 0.56927 a | **0.56358 a**  | **0.57232 x** | **0.56498 a** | 0.626300001 a |
| iid    | **0.66816** a | 0.6558 a  | 0.65311 a | 0.660710007 a  | 0.65535 a     | 0.64995 a     | 0.65926 a     |

