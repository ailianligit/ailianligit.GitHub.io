## \section{基于贡献评估的聚合算法}

\label{sec:contribution-aggregation}

为了评估客户端在联邦训练中的贡献，并根据贡献的大小调整客户端的参与程度，本章首先在\ref{subsec:shapley-contribution}节介绍了基于余弦梯度夏普利值的贡献评估方法，然后，\ref{subsec:contribution-effective}节展示了贡献评估方法在样本标签非独立同分布和加入不同比例的噪声时的有效性，最后，\ref{subsec:aggregation-design}节介绍了基于贡献评估的聚合算法的设计细节。



### \subsection{基于余弦梯度夏普利值的贡献评估方法}

\label{subsec:shapley-contribution}

在样本标签非独立同分布且带有噪声的情况下，某些客户端可能会为联邦训练提供有限的甚至错误的知识，而这些客户端的大量参与可能会对联邦训练的效果产生负面影响\cite{kairouz2021advances}，因此对客户端进行合理且有效的贡献评估是非常重要的。其中，样本标签的非独立同分布和含噪的比例都会对客户端的数据价值产生影响，从而影响客户端对于联邦模型训练效果的贡献。此处需要说明的是，客户端的数据价值和对联邦训练的贡献并不是完全等同的概念，因为一些低价值的客户端可能只有一些少量的但关键的样本，能帮助联邦训练突破局部最优解，因此在联邦学习的贡献评估领域，考虑客户端的边际价值增益是更为合理的选择\cite{王勇2022联邦学习贡献评估综述}。

在联邦学习贡献评估的众多方法中，合作博弈领域的夏普利值法\cite{kuhn1953contributions}通常被认为是一个相对可靠的解决方案，也被广泛用于评估联邦学习框架中各个客户端的贡献。夏普利值的计算方法如等式\ref{eq:shapley-value}所示，其中$\pi \in \Pi$的含义是所有客户端的一种排列，反映了客户端加入排列的先后顺序，而$\mathcal{S}_{\pi, n}$代表排列$\pi$中排在客户端$n$之前的客户端组合，$v$的含义是客户端组合的贡献评估值。因此，夏普利值$\phi_{n}$可以枚举客户端$n$的所有以不同次序加入排列的情况，计算这些情况下客户端$n$带来的期望价值增益，并以此作为其对联邦训练的贡献。具体来说，夏普利值的数值越大，则客户端对联邦训练的贡献也就越大。另外，夏普利值具备的合理性、对称性、零贡献、可加性等性质\cite{dubey1975uniqueness}使得夏普利值法相比其他贡献评估方法更加公平和合理。
$$
\phi_{n}:=\mathbb{E}_{\pi \in \Pi}\left[v\left(\mathcal{S}_{\pi, n} \cup\{n\}\right)-v\left(\mathcal{S}_{\pi, n}\right)\right]
$$
\begin{equation}
    \label{eq:shapley-value}
	\phi_{n}:=\mathbb{E}_{\pi \in \Pi}\left[v\left(\mathcal{S}_{\pi, n} \cup\{n\}\right)-v\left(\mathcal{S}_{\pi, n}\right)\right]
\end{equation}

然而，夏普利值法并不适用于本文的场景。因为计算夏普利值需要枚举客户端所有的以不同次序加入排列的情况，复杂度高达$O(2^N)$，而本文的目标是训练一个性能良好的联邦模型，因此在贡献评估上花费大量的时间是不必要的。另外一些夏普利值的估计方法\cite{dai2018toward,sim2020collaborative}则需要一个辅助的验证数据集，不符合本文设置的场景。为了克服上述挑战，CGSV算法\cite{xu2021gradient}提出用余弦梯度夏普利值对真实的夏普利值进行近似，并通过理论证明了二者之间仅存在一个有界的误差，因此无需高复杂度的计算和辅助的验证数据集。余弦梯度夏普利值的计算方法如等式\ref{eq:cos-shapley}所示，其中$u_n^t$代表客户端$n$在通信轮次$t$的参数更新，而$U^t$表示通过加权聚合后的联邦参数更新。余弦梯度夏普利值反映了客户端模型参数更新与联邦模型参数更新之间的余弦相似度，$u_n^t$和$U^t$的余弦相似度越大，客户端$n$的对联邦训练的贡献越大，反之则贡献越小。
$$
\psi_n^t:=\cos (u_n^t,U^t)
$$
\begin{equation}
    \label{eq:cos-shapley}
    \psi_n^t:=\cos (u_n^t,U^t)
\end{equation}

为了让客户端的贡献评估更加准确和稳定，其值以迭代的方式进行计算。\ref{subsec:aggregation-design}节将客户端的贡献与其聚合权重联系起来，通过贡献评估调整客户端对联邦训练的参与程度，因此$r_n^{t}$既代表了客户端$n$在通信轮次$t$的聚合权重，也代表了其在联邦训练开始后的贡献。初始聚合权重$r_n^0$设置为客户端$n$的数据量占总数据量的比例，而等式\ref{eq:important-score}展示了每个通信轮次中每个客户端的聚合权重的计算方式，其中$\gamma$是权衡系数，$\gamma=1$时整个联邦学习的框架退化为FedAvg算法。$\gamma$的值越大，则贡献评估更看重训练后期客户端的贡献，有效减轻模型参数随机初始化产生的噪声。$\gamma$的值越小，则贡献评估更看重训练前期客户端的贡献，或者更多地考虑客户端数据量的影响。\ref{subsec:exp-aggregation-1}节对$\gamma$的设置进行了讨论。值得注意的是，在等式\ref{eq:important-score}之后，还需要对聚合权重进行归一化，以保证所有客户端的聚合权重之和为1。
$$
r_n^{t+1}:=\gamma r_n^{t} + (1-\gamma)\psi_n^t
$$
\begin{equation}
    \label{eq:important-score}
    r_n^{t+1}:=\gamma r_n^{t} + (1-\gamma)\psi_n^t
\end{equation}



### \subsection{贡献评估方法的有效性}

\label{subsec:contribution-effective}

本节将分别展示样本标签非独立同分布及带有不同噪声两种情况下贡献评估方法的有效性。首先，为了让客户端之间的样本标签分布不同，本实验将使用\ref{subsec:dataset}节的方法对CIFAR-10数据集进行非独立同分布的划分，让每个类别在不同客户端上的概率分布随机向量采样自狄利克雷（Dirichlet）分布，参数$\beta$设置为0.1，表示随机向量采样的分布是一个非常集中的分布。客户端的总数$N$是20，训练联邦模型直至收敛，然后导出20个客户端的聚合权重。实验采用的模型和与\ref{subsec:model}节相同，其余超参数的设置与\ref{subsec:superparameter}节的设置相同。

图\ref{fig:fig1}展示了这20个客户端的样本标签分布情况及其对应的聚合权重$r_n$，其中横坐标轴根据$r_n$的数值从大到小对所有客户端进行排序，纵坐标则代表客户端$n$中不同标签的数量。聚合权重$r_n$越大，代表客户端对于联邦训练的贡献越大。从总体趋势上看，客户端的贡献随数据量增大而增大，但也有一些例外。例如红色方框标出的两个客户端的数据量相近，但是聚合权重的数值却相差甚远。观察这两组样本标签的分布可以发现，聚合权重为0.072的客户端的样本标签分布相比聚合权重为0.023的客户端的样本标签分布要更加均衡，与联邦验证数据集的样本标签分布也更为接近，因此有着更高的数据价值，对联邦训练的贡献也更大。

 [fig1.pdf](..\..\OneDrive - 中山大学\fig1.pdf)

为了验证样本标签噪声对客户端贡献评估的影响，本实验首先对所有客户端分配样本标签独立同分布的数据，然后分别在不同客户端中将不同比例的正确的样本标签替换为错误的样本标签，最后利用这些客户端进行联邦训练，在模型收敛后导出所有客户端的聚合权重。图\ref{fig:fig2}非常直观地说明了，样本标签中所含噪声的比例越大，则客户端的聚合权重越小，其对于联邦训练的贡献也就越小，而样本噪声比例相同的客户端的聚合权重是接近的。总的来说，两组实验都说明了在样本标签非独立同分布和质量不同的情况下，将余弦梯度夏普利值作为贡献评估的方法是有效的。

 [fig2.pdf](..\..\OneDrive - 中山大学\fig2.pdf) 



### \subsection{聚合算法的设计}

\label{subsec:aggregation-design}

贡献评估方法常用于联邦学习的激励机制和公平性的设计中\cite{王勇2022联邦学习贡献评估综述}，本节将讨论贡献评估对于调整客户端参与程度和改善联邦模型训练效果的作用。在样本标签非独立同分布及其质量存在差异的情况下，客户端对于联邦训练的贡献是有差异的。低贡献客户端的大量参与会对联邦模型的训练效果产生影响\cite{kairouz2021advances}，具体来说，低贡献客户端的参数更新方向会干扰联邦模型的参数更新方向，增加联邦模型训练收敛的时间，并且可能让联邦模型收敛到一个损失较大的局部最优解。因此，一个直观的想法是在客户端的贡献评估和聚合权重之间建立联系，让联邦模型的参数更新按客户端的贡献进行加权，降低低贡献客户端在联邦训练中的的参与程度，减轻其对于联邦模型参数更新的影响。

算法\ref{algo:aggregation}展示了基于贡献评估的聚合算法的流程。在每个通信轮次$t=1,2,\cdots,T$，服务器需要将客户端训练好的模型聚合起来，融合成为一个全局模型。在FedAvg算法\cite{mcmahan2017communication}中，模型以加权的方式进行聚合：$\theta^{t+1}\leftarrow\sum_{n=1}^N r_n^t\theta_n^t$。与之稍有不同的是，本文使用参数更新进行聚合，可以通过简单的推导证明两种聚合方式是等效的。$\Delta\theta^{t}_n$表示客户端$n$在通信轮次$t$训练前后模型参数的变化，通过训练后的模型参数与训练前的模型参数相减得到，并通过归一化防止梯度爆炸（gradient explosion）：$u_n^t\leftarrow\frac{\Delta\theta_n^{t}}{\lVert\Delta\theta_n^{t}\rVert}$。服务器接收到客户端发送的参数更新后，加权聚合得到聚合参数更新：$U^t\leftarrow\sum_{n=1}^Nr^{t}_n u_n^t$，最后更新联邦模型参数：
$$
\theta^{t+1}\leftarrow\theta^{t}+U^t
$$
\begin{equation}
    \label{eq:param-update}
	\theta^{t+1}\leftarrow\theta^{t}+U^t
\end{equation}

![image-20230314225313619](https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230314_1678805682.png)

![image-20230314215815586](https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230314_1678802299.png)

![image-20230314215830449](https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230314_1678802313.png)

CGSV算法\cite{xu2021gradient}和FOC算法\cite{chen2020dealing}的实验证实了基于贡献评估的聚合算法对于联邦模型训练效果的改善，尤其是在样本标签非独立同分布和带有噪声的情况下。\ref{subsec:exp-aggregation-1}节的消融实验也验证了基于余弦梯度夏普利值的聚合算法的作用，降低了低贡献客户端在联邦训练中的参与程度，此外，\ref{subsec:exp-aggregation-1}节的超参数实验还对权衡系数$\gamma$的设置进行了讨论。最后，\ref{subsec:exp-aggregation-2}节的探究性实验则试图在贡献评估和剪枝率之间建立联系，探究基于贡献评估的自适应剪枝对联邦模型训练效果的影响。
