### [机器学习系统](https://proceedings.neurips.cc/paper_files/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf)

![image-20230425193939571](https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202304/20230425_1682422781.png)



### 研究方向：

图联邦学习

**模型压缩：剪枝 蒸馏**

NAS

超参数优化

公平联邦学习

**边缘计算任务调度**

联邦学习模型异构 

个性化联邦学习：联邦学习数据异构

**大模型训练**

时间序列

few-shot

预训练大模型

TinyML

持续学习

鲁棒机器学习

轻量化AI



### 参考资料：

犀牛鸟计划

知乎问题

B站视频

B站专栏

prompt tuning lora PEFT

网络经济实验室、陈旭、陈亮、张晓溪

脉脉、求职软件、华为云、阿里云、运筹优化offer

边缘计算论文

NeurIPS/ICML/ICLR2023

剪枝与噪声的关系

联邦学习noniid理论

大模型训练+预训练对比学习论文

联邦NAS

联邦参数优化

参考文献文件夹

MoE、fedml

A Coalition Formation Game Approach for Personalized Federated Learning

Resource-Adaptive Federated Learning with All-In-One Neural Composition

Federated Continual Learning with Weighted Inter-client Transfer

Federated Online Learning Based Recommendation Systems for Mobile Social Applications

Federated Learning on Non-IID Data Silos: An Experimental Study



选择方向的维度兴趣：机器学习 数据驱动决策 博弈 运筹 序列决策 分布式优化 分布式计算 在线优化 随机优化 时间序列 隐私计算 强化学习 联邦学习数学（重要性）：优化 统计 运筹 博弈计算机（无先后顺序）：体系结构 数据库 分布式系统 并行计算产学研热点（无先后顺序）：通用AI 个性化AI 大模型 基础模型 模型压缩 隐私计算就业（数理基础）：证券 互联网大厂 银行 事业单位 算法工程师 量化研究员 系统工程师深造（热点问题 好发论文）：机器学习 强化学习 序列决策 随机优化 博弈论与机制设计 在线优化 计算/网络经济学 联邦学习



产学研热点方向：通用AI 个性化AI 大模型 基础模型 模型压缩 隐私计算 可解释性AI阿里：大小模型协同进化、高精度医疗导航、全域隐私计算、云网端融合百度：超大规模预训练模型呈现知识增强、跨模态统一建模、多学习方式共同演进的趋势，并逐渐实用化；隐私计算技术备受关注，将成为数据价值释放的突破口和构建信任的基础设施；绿色低碳更多纳入AI蓝图，助力实现碳达峰碳中和目标华为：通用AI、可信AI谷歌：More Capable, General-Purpose ML Models；Continued Efficiency Improvements for ML；ML Is Becoming More Personally and Communally Beneficial；Growing Benefits of ML in Science, Health and Sustainability；Deeper and Broader Understanding of ML



机器学习 (ML) 任务是当今边缘计算网络中的主要工作负载之一。 现有的边缘-云调度程序将请求的资源量分配给每个任务，无法最好地利用有限的边缘资源来执行 ML 任务。 本文提出了 TapFinger，一种用于边缘集群的分布式调度程序，它通过共同优化任务放置和细粒度多资源分配来最小化 ML 任务的总完成时间。 为了了解任务的不确定资源敏感性并启用分布式调度，我们采用多代理强化学习（MARL）并提出了几种使其高效的技术，包括作为 MARL 主干的异构图注意网络，定制任务选择阶段 演员网络，以及贝叶斯定理和掩蔽方案的整合。 我们先实现一个单任务调度版本，每次最多调度一个任务。 然后我们推广到多任务调度情况，其中同时调度一系列任务。 我们的设计可以减轻扩展的决策空间并产生快速收敛到最佳调度解决方案。 使用合成和测试床 ML 任务跟踪的大量实验表明，与最先进的调度程序相比，TapFinger 可以将平均任务完成时间减少多达 54.9%，并提高资源效率。

边缘计算是一种分布式计算范式，可将云功能扩展到边缘，以获得更好的服务质量 (QoS) 和数据隐私保护。 通过将服务和资源移动到更靠近最终用户的位置，它可以提供高可用性服务并显着降低服务延迟。 作为当今主要的应用程序工作负载之一，基于边缘的机器学习 (ML) 应用程序，从流量预测到生产工作流监控，通常处理在边缘生成的在线数据流 [2]。 由于边缘设备的资源限制，这些 ML 任务已部署在边缘集群 [2]、[3] 中，例如 NVIDIA EGX [4]、Microsoft Azure Edge [5] 和 AWS Outposts [6]。 它们由编排工具管理，可以在足够的 CPU 和 GPU 以及定制的软件工具包和网络接口卡上运行，例如，用于加密的物联网传感器数据 [4]。 然而，边缘集群的资源仍然有限。 优化基于边缘的 ML 应用程序 QoS 的核心是有效利用资源，同时及时学习所需的 ML 模型

对于各种模型和数据集，ML 训练和推理任务具有不确定性和多样性的性能 [7]、[8]、[9]，难以实现优化的资源效率。 YARN [10]、Kubernetes [11]、KubeEdge [12] 和 OpenYurt [13] 等实用调度程序通常采用预设规则进行资源分配。 这些策略依赖于任务的准确资源估计，而 ML 任务的资源需求通常具有弹性和不确定性（例如，模型收敛所需的时间量），适应各种性能资源权衡 [14]。 已经提出基于学习的云边缘调度程序来解决这种不确定性 [14]、[15]、[16]、[17]、[18]。 然而，它们不能推广到我们的场景，在我们的场景中，需要更好地编码更复杂的决策依赖关系，例如，为了进一步解决问题输入和决策变量的高维性。 事实上，细粒度的资源分配和战略性任务布置对于最大化边缘 ML 任务的总体性能非常重要。 如图 1 所示，由于数据强度和低延迟要求，移动边缘设备需要将其 ML 任务卸载到“正确”的边缘集群，以在最短时间内实现模型收敛。 此外，不同的资源，例如 CPU 和 GPU，会影响任务性能，需要多资源分配方案。 考虑到动态网络连接、作业干扰 [19] 和多资源竞争的复杂性，我们问：如何设计一个可扩展的、细粒度的、有远见的、为边缘 ML 定制的资源调度器？

为实现这一点，我们提出了 TapFinger，这是一种分布式调度程序，用于联合优化任务放置和跨边缘集群的细粒度多资源分配，目标是最大限度地减少 ML 任务的总完成时间。 为实现这一目标，我们面临以下基本挑战。

细粒度的资源分配。 与现有的将请求的资源量分配给每个任务 [8]、[15] 的边缘云调度程序不同，根据需求和供应进行细粒度资源供应 [9] 可以实现更好的资源效率和应用程序 QoS。 边缘调度器面临的挑战是，预测每个并发运行的任务的性能，并从巨大的解决方案空间中战略性地选择最佳资源量，以最大化总体任务性能，例如，实现特定目标所需的训练时间 准确性

不同资源的不确定影响。 大多数 ML 任务调度程序在云 [9]、[17]、[20] 或边缘设置 [3] 中分配单一类型的资源，例如 GPU，未能捕获多种类型的资源对任务性能的影响 . 多资源分配问题通常是 NPard 问题，即使对问题输入 [21] 有完美的了解，当任务性能在给定资源的情况下未知时，这更具挑战性。 强化学习 (RL) 可以有效地处理不确定性 [22]、[23]、[24]，但对于具有复杂约束的在线组合问题仍未得到充分探索。

跨边缘集群的分布式调度。 实际的边云集群通常由中央协调器 [10]、[11] 管理。 然而，集中调度处理多个地理区域的全局信息并且通常具有较差的可扩展性。 因此，分散式方法更适合减少决策空间，并可实现更好的系统可靠性。 尽管如此，如果在每个边缘集群中独立进行自我优化决策，分散调度可能会导致次优任务性能。 分布式调度器之间的有效交互对于优化整个边缘网络中的全局资源效率至关重要。

DL 工作负载的资源调度。 尽管通用任务调度算法，如 Dominant Resource Fairness [28]、Shortest Remaining Job First (SRJF) [29]、Tetris [30] 及其改进的变体 [31]、[32]、[33] 已得到广泛研究， 针对机器学习 (ML) 工作负载量身定制的策略还为时过早 [34]。 几个开创性的调度框架捕获了 DL 任务的不确定执行时间，旨在最小化完成时间。 彭等。 [7] 将 Optimus 设计为通过预测训练速度作为每个任务分配资源的函数来安排分布式 DL 训练任务。 然后，调度程序可以增量调整所有任务的参数服务器和工作人员的数量。 为了利用 DL 任务中的循环模式，Xiao 等人。 [20] 基于现有的 DL 框架开发原语，以实现高效的时间切片和分析驱动的内省。 Tiresias [8] 结合最少获得的服务调度和多级反馈队列来设计抢占式调度算法。 在 [9] 中，提出了 Apathetic Future Share 算法以实现高效的资源共享，并实现了专用的弹性共享 DL 训练系统来验证所提出算法的优势。 最近的一些工作使用多资源流水线和作业间交错 [35]、[36]、新颖的分析方法 [3]、[37] 或新的性能指标 [9]、[38] 实现了 DL 任务的弹性 GPU 集群调度 ]. 王等。 [39] 提出了一种用于边缘云网络的在线抢占式 ML 任务调度算法。 通常，这些是基于规则的算法，依赖于对任务特征的准确估计。 相反，本文旨在实现一个自我优化框架，无需手工制作预测模型来捕获不确定的任务性能。



### 重点考虑的研究方向（优化+机器学习）：

- 分布式机器学习、机器学习系统与运筹优化


- 模型压缩、大模型训练与运筹优化：NAS、超参数优化


- 面向边云协同网络中分布式机器学习的动态优化与资源调度




### 研究方向应考虑的角度：

- 热门中的冷门


- 好不好发论文
- 工业界需求


- 兴趣：运筹优化


- 找工作：机器学习


- 脚踏实地且有意义的方向


- 国家重视实体经济


- 掌握一门手艺
- 高质量数据、高算力、大模型
- NeurIPS/ICLR/ICML顶会方向
- 犀牛鸟计划等产学研结合方向



### OPPO

2024届暑期实习

方向一：负责推荐、搜索、广告算法研发，覆盖广告、信息流、视频、应用商店、全局搜索等多个场景；

方向二：AI技术业务赋能，利用机器学习，深度学习等前沿技术，深度结合信息流、应用商店、搜索、语音助手等核心业务场景解决自然语言处理、语音和图像识别等多领域问题，整体提升用户体验和业务价值；

方向三：ColorOS上的AI产品开发和研究，学习用户行为习惯，优化手机系统性能，探索计算机视觉和自然语言处理在ColorOS业务上的应用，整体提升ColorOS的用户体验；

**方向四：机器学习框架方向，深入优化现有机器学习框架，提升推理框架性能等；**

**方向五：深度学习模型优化、压缩，设备端算法落地等；**

方向六：负责图像检测，识别，语义分割等相关核心算法研究及落地；

方向七：负责语音识别，语音唤醒，回声消除等相关核心算法研究及落地；

方向八：图计算技术（图分析、图神经网络等）的核心算法研究及落地，参与图计算平台的研发；

方向九：行为时序预测技术的先进算法研究及落地；

**方向十：隐私安全计算（联邦学习，差分隐私，同态加密，可信执行环境等）算法研究及落地；**

方向十一：研究探索多领域运动健康方向，对健康数据研究和应用。