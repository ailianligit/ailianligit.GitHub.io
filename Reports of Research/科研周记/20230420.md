### [Efficient Deep Learning](https://hanlab.mit.edu/)

![image-20230417173556554](https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202304/20230417_1681724160.png)

- 模型压缩和加速、TinyML和智能物联网 (IIoT)、高效训练和推理

- Efficient Deep Learning of HAN Lab

  - [Once-for-All: Train One Network and Specialize it for Efficient Deployment](https://ofa.mit.edu/)
    - 解耦训练和搜索
    - 渐进式收缩算法、广义剪枝方法
    - 可以获得数量惊人的子网络

  - [MCUNet](https://mcunet.mit.edu/)
    - 在物联网设备上进行微型深度学习
    - 算法-系统协同设计框架
    - 高效的网络架构搜索（TinyNAS）和轻量推理引擎（TinyEngine）
  - [TinyML](https://tinyml.mit.edu/)：嵌入式机器学习
    - TinyML项目旨在通过需要更少的计算、更少的工程师和更少的数据来提高深度学习AI系统的效率，以促进边缘AI和AIoT的巨大市场。
    - 优势：减少延迟时间、节能、减少带宽、数据隐私
    - [TensorFlow Lite for Microcontrollers](https://www.tensorflow.org/lite/microcontrollers)：在微控制器上推理



### 神经架构搜索（NAS）

![img](https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202304/20230417_1681722506.png)

- **Search Space**
- **Search Strategy**
  - Reinforcement Learning (RL)
  - Evolutionary Algorithm (EA)
  - Gradient Based (GB)
- **Performance Estimation Strategy**



### [One-shot NAS](https://zhuanlan.zhihu.com/p/74985066)

![img](https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202304/20230417_1681722554.png)

- [Once-for-All: Train One Network and Specialize it for Efficient Deployment](https://ofa.mit.edu/)
  - ICLR2020：OFA(Once for All): 高效率部署：https://zhuanlan.zhihu.com/p/164695166



### [AutoML](https://zhuanlan.zhihu.com/p/143492567)

- 搜索方法
  - 随机搜索与栅格搜索
  - 强化学习
  - 进化算法
  - 贝叶斯优化
- 特征工程
- 数据增强
- 模型架构的优化：NAS
- 模型结构参数的优化：多尺度融合
- 激活函数
- 归一化方法
- 优化方法
- 优化目标：搜索合适的损失函数的超参数
- 模型优化
  - AutoML for Model Compression：限制剪枝率探索最优精度、限制精度探索最大剪枝率
  - HAQ：混合精度量化框架
  - N2N learning：用强化学习做知识蒸馏



### [Ray: Distributed AI Framework](https://thenewstack.io/how-ray-a-distributed-ai-framework-helps-power-chatgpt/)

- distributed computing ecosystem as a service



### [Hyperparameter Optimization](https://speakerdeck.com/richardliaw/a-modern-guide-to-hyperparameter-optimization)

- [Ray Tune](https://docs.ray.io/en/latest/tune/index.html)：可扩展的超参数调整



### [Data-centric AI](https://github.com/daochenzha/data-centric-AI)

- 训练数据开发（training data development）：构建足够数量的高质量数据，以支持机器学习模型的训练

- 推理数据开发（inference data development）：构建模型推理的数据

- - 评估模型的某种能力，比如构建对抗攻击（Adversarial Attacks）数据以测试模型的鲁棒性
  - 解锁模型的某种能力，比如提示工程（**Prompt Engineering**）

- 数据维护（data maintenance）：确保数据在动态环境中的质量和可靠性



### 研究生计划：

- 三条腿：优化、机器学习、机器学习系统


- 三只脚：科研、实习/项目/竞赛、网课/上课


- 尽早达到毕业要求


- 重视理论：优化
- 重视工程：「真正让我意识到，如果要创造影响力，你应该去写一些基础的东西，或者在工程上有所建树，而不是说在一些 research 方面有所建树。」

- 机器学习：关注AI前沿知识




### 科研习惯：

- 科研计划与科研周记
  - 以每次组会为分界线，组会结束的当晚做一周科研计划
  - 组会的当天上午对科研计划完成情况和科研周记内容进行总结，科研周记内容用于组会展示
- 科研周记、调研报告与科研报告
  - 科研周记
  - 调研报告：调研某一领域的工作
  - 科研报告：科研进展报告
- 每周两篇相关方向前沿文章
- 每周至少上一节课程
- 每周至少做一次项目
- 每天晚上、组会时间看科研新闻
- 每周至少和刘佳豪、周老师讨论一次
- 时间优先级：
  - 工作日白天：科研
  - 工作日晚上：科研、项目
  - 周末白天：科研、网课、项目
  - 周末晚上：科研、网课、项目



### 组会攻略

- 每周看两篇论文
- 看论文的原因是什么
- 解决了什么问题



### 就业和实习方向：

- 大厂核心项目
- 机器学习系统工程师
- 机器学习算法工程师

- 运筹优化算法工程师


- 搜广推算法工程师


- 风控算法工程师




### 就业方向应考虑的角度：

- 热门中的冷门


- 兴趣：运筹优化


- 找工作：机器学习


- 创造性的方向，不会被AI取代


- 国家重视实体经济


- 掌握一门手艺


- work life balance


- 运筹优化背景+机器学习工具


- 有开发能力的算法工程师
