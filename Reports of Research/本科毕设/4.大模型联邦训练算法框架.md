## \section{大模型联邦训练算法框架}

\label{sec:framework}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\textwidth]{image/chap02/fig_framework.pdf}
    \caption{基于剪枝优化的大模型联邦训练算法框架}
    \label{fig:framework}
\end{figure}

本节将对基于剪枝优化的大模型联邦训练算法的框架进行概述，图\ref{fig:framework}形象展示了整个算法的流程，而算法\ref{algo:framework}则展示了更多的设计细节。本文中的大模型的含义是相比边缘设备上的经过压缩的小模型，在服务器上进行测试的模型是更大规模的模型，并且这个大模型也是算法训练的目标。

\newpage

\begin{algorithm}[h]
    \KwIn{客户端$n\in\{1,2,\cdots,N\}$及其本地数据集$\mathcal{D}_{n}$，剪枝率$\alpha$，学习率$\eta^t$，剪枝算法的初始调整系数$\lambda^0$，聚合算法的初始权衡系数$\gamma^0$}
    \textbf{初始化}: 联邦模型参数$\boldsymbol{\theta}^1$，客户端聚合权重$r_n^{1}\leftarrow \frac{\left|\mathcal{D}_n\right|}{\sum_{n\in\{1,2,\cdots,N\}} \left|\mathcal{D}_n\right|}$\\
    \ForEach{通信轮次$t=1,2,\cdots,T$}{
        $\hat{\boldsymbol{\theta}}^{t}\leftarrow$基于动态拓扑的剪枝算法（$\boldsymbol{\theta}^{t}$，$\alpha$, $\lambda^0$，$t$，$T$）\\
        服务器将剪枝模型$\hat{\boldsymbol{\theta}}^{t}$分发给$N$个客户端\\
        \ForEach{客户端$n\in\{1,2,\cdots,N\}$并行}{
            接收剪枝模型：$\hat{\boldsymbol{\theta}}^{t,0}_n\leftarrow\hat{\boldsymbol{\theta}}^{t}$\\
            \ForEach{本地迭代轮次$e=1,2,\cdots,E$}{
                使用SGD算法进行本地更新：$\hat{\boldsymbol{\theta}}^{t,e}_n\leftarrow\hat{\boldsymbol{\theta}}^{t,e-1}_n-\eta^t\nabla f_n(\hat{\boldsymbol{\theta}}^{t,e-1}_n)$\\
            }
            客户端上传参数更新：$\Delta\hat{\boldsymbol{\theta}}^{t}_n\leftarrow\hat{\boldsymbol{\theta}}^{t,E}_n-\hat{\boldsymbol{\theta}}^{t,0}_n$\\
        }
        服务器接收客户端参数更新$\Delta\hat{\boldsymbol{\theta}}^{t}_n,n\in\{1,2,\cdots,N\}$\\
        $\hat{\boldsymbol{\theta}}^{t+\frac{1}{2}}$，$r^{t+1}\leftarrow$基于贡献评估的聚合算法（$\hat{\boldsymbol{\theta}}^{t}$，$r^{t}$，$\Delta\hat{\boldsymbol{\theta}}^{t}$，$\gamma^0$，$t$）\\
        恢复为联邦大模型：$\boldsymbol{\theta}^{t+1}\leftarrow\boldsymbol{\theta}^{t}-\hat{\boldsymbol{\theta}}^{t}+\hat{\boldsymbol{\theta}}^{t+\frac{1}{2}}$
    }
    \caption{基于剪枝优化的大模型联邦训练算法}
    \label{algo:framework}
\end{algorithm}

每一个通信轮次$t=1,2,\cdots,T$开始，服务器上有一个联邦大模型$\boldsymbol{\theta}^t$，为了让这个大模型能够在通信带宽和边缘计算能力受限的联邦学习框架中训练，算法首先对$\boldsymbol{\theta}^t$进行压缩。\ref{sec:dynamic-pruning}节介绍了基于动态拓扑的模型剪枝算法，在剪枝的过程中，首先将整体的剪枝率$\alpha$放大为$\alpha^{+}$，剪去模型中绝对值最小的百分之$\alpha^{+}$个权重，然后随机恢复一定数量的权重，使得模型整体的剪枝率从$\alpha^{+}$恢复为$\alpha$。这一算法基于动态稀疏训练的思想，在训练过程中对剪枝模型的网络拓扑进行动态调整。\ref{sec:ablation}节的消融实验可以证明，在相同的通信和计算需求下，动态剪枝相比静态剪枝和参数量相同但规模更小的密集型网络有更好的联邦训练效果。

然后，服务器会向$N$个客户端分发剪枝模型$\hat{\boldsymbol{\theta}^t}$。因为服务器发送的是经过压缩的模型，所以通信的成本和客户端的计算量会有所降低。客户端接收到剪枝模型后，利用本地数据集$\mathcal{D}_{n}$和本地的计算资源进行训练，使用随机梯度下降算法对剪枝模型$\hat{\boldsymbol{\theta}}^{t}_n$进行更新，然后将参数更新$\Delta\hat{\boldsymbol{\theta}}^{t}_n$上传给服务器。

服务器接收客户端的参数更新后，就进入了\ref{sec:contribution-aggregation}节介绍的基于贡献评估的模型聚合算法。服务器首先会对接收到的参数更新进行归一化，然后加权聚合为联邦的参数更新，并利用聚合参数更新对联邦模型的参数进行更新。本文将更能体现客户端数据价值和贡献大小的余弦梯度夏普利值作为客户端模型聚合的权重。在客户端标签质量存在差异的情况下，基于贡献评估的模型聚合算法能够提升联邦训练的效果，使联邦大模型具备一定的鲁棒性。

