英文首字母大写

相关工作：标签质量

学习率

内核 前向传播 反向传播 英文



标签噪声是机器学习中的一个常见问题，可能导致联邦学习参与者之间的标签质量差异。 与联邦学习中参与者可能具有不同数据分布但具有正确标签的非 IID 问题不同，标签质量差异反而关注标签可能不一致的情况，即使参与者被赋予相同的实例集。

在传统的机器学习设置中，有两类方法来处理这个问题：1）在数据级别和 2）在算法级别。 在数据层面，现有方法通常旨在清理噪声标签以减轻其影响。 克雷图等人。 [2] 使用一小部分训练数据生成多个模型并为每个输入生成临时标签。 这用于确定是否存在噪声标签。 谢等。 [8] 设计了拜占庭稳健的聚合器来防御对卷积神经网络的标签翻转数据中毒攻击。 然而，Koh 等人。 [4] 最近发现联合数据清理方法仍然容易受到数据中毒攻击。

在算法层面，现有方法通常旨在训练抗噪声模型。 纳塔拉扬等人。 [7] 从理论角度研究了标签噪声在二元分类中的影响，并提出了一种简单的加权代理损失来建立强大的经验风险界限。 由于深度学习模型很容易过度适应标签噪声，Zhang 等人。 [13] 使用元学习来训练深度模型，其中生成合成噪声标签以在常规梯度更新之前更新模型。 然而，这些现有方法不能直接应用于联邦学习的背景下，因为它们需要访问原始数据。

在 FL 中，标签噪声也与非 IID 问题有关。 赵等。 [14] 发现非 IID 参与者在 FL 中产生了一个糟糕的全球模型，因为参与者数据中的大地球移动距离 (EMD) 使他们的模型多样化。 然而，拟议的数据共享策略需要更多的沟通，并有稀释参与者信息的风险。 此外，EMD 的计算要求 FL 协调员能够访问参与者的原始数据，这在 FL 设置下是不允许的。

据我们所知，目前还没有关于减轻 FL 设置下标签噪声影响的已发表作品。