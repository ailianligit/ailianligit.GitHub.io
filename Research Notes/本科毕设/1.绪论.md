# \chapter{绪论}

\label{chap:overview}

## \section{选题背景与意义}

\label{sec:background}

近年来，深度学习领域涌现出越来越多规模庞大的模型，并且模型的参数量成指数级增长\cite{bommasani2021opportunities}。以最近风靡全球的人工智能聊天机器人ChatGPT为例，其前身为大规模预训练语言模型GPT。2018年发布的GPT-1\cite{radford2018improving}的参数量为1.17亿，数据量约为5GB；2019年发布的GPT-2\cite{radford2019language}参数量上升到15亿，预训练的数据量也激增到40GB；一年后，有着1750亿参数的GPT-3\cite{brown2020language}横空出世，其预训练的数据量更是达到了惊人的45TB。这些庞大的模型能够处理高复杂度和多模态的任务，并且在这些任务上能够取得相当高的精度。按照传统机器学习的观点，模型的复杂度需要与数据集的规模相匹配，模型过于复杂可能会导致过拟合现象的产生\cite{ying2019overview}。然而，对于参数量远远多于传统机器学习模型的深度神经网络来说，参数量与测试准确率的关系并非如此。Mikhail Belkin等人的研究\cite{belkin2019reconciling}发现，随着模型容量从小到大，模型的测试准确率先增加后减小，而后再次增加，且逐渐刷新最优的测试准确率。因此，这种在传统机器学习中导致过拟合的过参数化（over-parameterized）特性在现代深度学习中反而变成了优点，合理地增加神经网络的宽度和深度可以获得肉眼可见的性能提升。凭借着优越的性能，大模型相关领域的研究正得到众多科研工作者、工业界人士甚至是全社会的广泛关注。

对于一个规模庞大的深度学习模型的训练来说，充足且优质的数据是必不可少的。然而，对于一些特定的或者复杂的任务来说，训练数据往往不够充足，数据的质量也参差不齐。近些年来，边缘计算的发展促进了深度学习模型在各类边缘设备上的部署和应用，边缘智能的提供方可以通过边缘设备采集数量庞大的训练数据，甚至利用原始数据直接在边缘设备上进行深度学习的训练。其中，仅利用边缘设备有限的数据难以训练强大的深度学习模型，而数据持有方出于隐私保护的考虑，往往会拒绝分享原始的数据。在Brendan McMahan等人于2017年提出的联邦学习（federated learning，FL）\cite{mcmahan2017communication}的概念中，客户端（clients）无需上传自己的数据，而是以迭代的方式，首先在本地用自己的数据训练模型，然后将本地的模型上传给服务器，最后服务器端通过模型聚合得到一个强大的联邦模型。联邦学习是一种新型的分布式机器学习范式，能够在保护隐私的基础上，利用众多边缘设备的本地数据和计算资源进行联邦大模型的训练。

利用联邦学习的框架训练大模型并不是完美无缺和一劳永逸的。首先，正如前面所述，大模型的参数量是非常大的。对于如今有限的云边传输带宽，尤其是从客户端到服务器更加有限的上传带宽，过多的数据传输量会带来巨大的通信开销，影响网络传输的效率。其次，过多的模型参数也会导致训练过程中需要更多的计算资源。对于大多数的物联网边缘设备来说，其计算能力远远弱于云端服务器的计算能力。因此在联邦学习中，直接将服务器端的联邦大模型通过有限带宽的网络传输给有限资源的边缘设备进行训练和推理是不切实际的。对于这一挑战，网络剪枝（network pruning）\cite{han2015learning}、知识蒸馏（knowledge distillation）\cite{hinton2015distilling}、参数量化（parameter quantization）\cite{courbariaux2015binaryconnect,courbariaux2016binarized}等技术可以对规模庞大的深度学习模型进行压缩。其中，知识蒸馏通常需要服务器端有公共数据集，或者获取客户端学习的知识，而参数量化对硬件的要求更高，通常只在特定的硬件上更有效。因此，网络剪枝技术更加适应联邦学习框架重视隐私保护的特点，同时更加适应普遍的硬件条件。

网络剪枝是模型压缩中一类通用且有效的技术，但这并不意味着网络剪枝可以完全解决上述挑战。首先，常见的网络剪枝框架是先训练、后修剪、再微调\cite{han2015learning}，或者在训练过程中逐渐修剪越来越多的权重并省去了微调的过程\cite{gale2019state}，又或者如“彩票假说”（lottery ticket hypothesis）\cite{frankle2018lottery}在每轮迭代中对完整的模型进行修剪。然而，这些方法对于训练过程中的通信和计算成本的优化非常有限。从另一个方面说，若采用静态拓扑的方式\cite{molchanov2016pruning}从随机初始化开始对模型进行剪枝，即使有效减少了模型的参数量，其训练的效果通常远远不如完整的密集型网络\cite{mocanu2016topological}，甚至有可能不如同等参数数量但规模更小的密集型网络\cite{evci2019difficulty}。Mocanu等人提出的“稀疏进化训练”（sparse evolutionary training，SET）\cite{mocanu2018scalable}和Utku Evci等人提出的“作弊彩票”（the rigged lottery，RigL）\cite{evci2020rigging}本质上都是基于动态拓扑的剪枝方法，能对参数空间进行充分的探索，从而将较为重要的连接或结构保留下来，具备表达和泛化能力强、训练和推理成本低的特点\cite{liu2021we}。因此，本文将借助动态剪枝的思想减少大模型联邦训练算法的通信量和计算量。

对于众多边缘设备上的数据，样本标签的质量也会对大模型联邦训练的效果产生影响。联邦学习一个重要的特征是分布在不同客户端上的数据常常不能满足独立同分布的性质，因为每个客户端采集数据的方式、对象、能力不尽相同，因此不同客户端之间的数据分布更有可能是非独立同分布的。数据非独立同分布可以分为特征分布不同（feature distribution skew）、标签分布不同（label distribution skew）、相同标签不同特征、相同特征不同标签和数据量不同（quantity skew）五种情况\cite{kairouz2021advances}。其中，客户端之间标签分布不同相比特征分布不同通常更能损害联邦大模型的训练效果，而大部分工作（包括本文）不涉及相同标签不同特征、相同特征不同标签这两类情况。样本标签非独立同分布是指每个客户端拥有样本标签的种类和数量不同，而标签噪声意味着某些样本标签可能在采集过程中出错，这两种情况都会影响样本标签的质量和客户端的数据价值，从而影响客户端对于联邦训练的贡献和联邦模型的训练效果\cite{zhao2018federated}。因此，本文将重点关注客户端之间的样本标签质量差异，尝试从数据价值和贡献评估的角度调整客户端对联邦训练的参与程度，提升联邦模型的训练效果。



## \section{本文的主要贡献}

\label{sec:contribution}

为了解决\ref{sec:background}节提到的诸多挑战，本文提出了一个新颖的基于剪枝优化的大模型联邦训练算法。该算法的目标是训练一个性能良好的联邦大模型，减少通信和计算资源的消耗，同时对客户端之间标签质量存在差异的情况具备鲁棒性。具体来说，本文提出的大模型联邦训练算法利用基于动态拓扑的剪枝技术对全局大模型进行压缩，在尽可能保持训练效果的同时减少模型的参数量，本地训练完成后，利用基于贡献评估的聚合技术对分布在不同边缘设备上的模型进行聚合，根据边缘设备的贡献调整其在联邦训练中的参与程度，最后利用模型残差将聚合后的模型恢复为大规模的联邦模型。需要特别说明的是，因为通信带宽和边缘设备计算能力的限制，服务器端需要先进行模型压缩才能发送给客户端进行训练，因此本文中的大模型的含义是相比边缘设备上的经过压缩的小模型，在服务器上进行测试的模型是更大规模的模型，并且这个大模型也是算法训练的目标。总的来说，本文的贡献可以总结为以下几个方面：

\begin{enumerate}
    \item 将基于动态拓扑的剪枝算法应用于联邦学习的框架中，减少大模型联邦训练算法的通信量和计算量，并通过消融实验验证了动态剪枝算法的有效性，还研究了剪枝算法中的超参数对联邦训练的影响。
    \item 将基于贡献评估的聚合算法应用于联邦学习的框架中，使得大模型联邦训练算法对客户端之间标签质量存在差异的情况具备鲁棒性。本文通过实验展示了贡献评估方法的合理性，验证了聚合算法的有效性，还研究了聚合算法中的超参数对联邦训练的影响。
    \item 本文通过实验说明，相比其他现有的联邦剪枝算法，本文提出的大模型联邦训练算法能够用更少的通信和计算开销，在MNIST、CIFAR-10等真实的图像数据集上实现更优的准确率，同时减轻样本标签质量差异对联邦训练的影响。此外，本文还通过实验探究了基于贡献评估自适应剪枝的可行性。
\end{enumerate}



## \section{本文的论文结构与相关安排}

\label{sec:arrangement}

本文共分为四章，各章节内容安排如下：

第一章绪论。简单说明了本文的选题背景与意义，对本文的主要贡献进行了总结。

第二章为国内外研究现状和相关工作。本章对联邦学习中的模型压缩、网络剪枝、数据异构、标签噪声和贡献评估等领域的研究现状和相关工作进行了总结。

第三章为基于剪枝优化的大模型联邦训练算法。首先对算法的问题和相关的符号进行了定义，然后从整体上概述了大模型联邦训练算法的框架，之后分别介绍了基于动态拓扑的剪枝算法和基于贡献评估的聚合算法这两个模块的技术细节。

第四章为实验与结果。本章首先介绍了数据集及其划分方式、模型、实验指标和超参数等实验设置，然后将本文提出的基于剪枝优化的大模型联邦训练算法与FedAvg、FedProx、PruneFL和FedDST等基线算法进行了对比。之后，通过实验先后验证了基于余弦梯度夏普利值的贡献评估方法、基于动态拓扑的模型剪枝算法和基于贡献评估的模型聚合算法的有效性。最后，通过实验探究了算法中的超参数对联邦训练的影响，以及基于贡献评估自适应剪枝的可行性。

第五章为结论。本章对基于剪枝优化的大模型联邦训练算法的设计和实现方法进行了总结，回顾了一些重要的实验结果和结论，在此基础上提出了一些改进算法和进一步研究的方向。
