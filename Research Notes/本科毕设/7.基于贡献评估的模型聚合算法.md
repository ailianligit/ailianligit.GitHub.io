## \section{基于贡献评估的模型聚合算法}

\label{sec:contribution-aggregation}

为了评估客户端在联邦训练中的贡献，并根据贡献的大小调整客户端的参与程度，本章首先在\ref{subsec:shapley-contribution}节介绍了基于余弦梯度夏普利值的贡献评估方法，然后，\ref{subsec:aggregation-design}节介绍了基于贡献评估的模型聚合算法的设计细节。

### \subsection{基于余弦梯度夏普利值的贡献评估方法}

\label{subsec:shapley-contribution}

在样本标签非独立同分布且带有噪声的情况下，某些客户端可能会为联邦训练提供有限的甚至错误的知识，而这些客户端的大量参与可能会对联邦训练的效果产生负面影响\cite{kairouz2021advances}，因此对客户端进行合理且有效的贡献评估是非常重要的。其中，样本标签的非独立同分布和含有噪声的比例都会对客户端的数据价值产生影响，从而影响客户端对于联邦训练的贡献。此处需要说明的是，客户端的数据价值和对联邦训练的贡献并不是完全等同的概念，因为一些低价值的客户端可能只有一些少量的但关键的样本，能帮助联邦训练突破局部最优解，因此在联邦学习的贡献评估领域，考虑客户端的边际价值增益是更为合理的选择\cite{王勇2022联邦学习贡献评估综述}。

在联邦学习贡献评估的众多方法中，合作博弈领域的夏普利值法\cite{kuhn1953contributions}通常被认为是一个相对可靠的解决方案，也被广泛用于评估联邦学习框架中各个客户端的贡献。夏普利值的计算方法如等式（\ref{eq:shapley-value}）所示，其中$\pi \in \Pi$的含义是所有客户端的一种排列，反映了客户端加入排列的先后顺序，而$\mathcal{S}_{\pi, n}$代表排列$\pi$中排在客户端$n$之前的客户端组合，$v$的含义是客户端组合的贡献评估值。因此，夏普利值$\phi_{n}$可以枚举客户端$n$的所有以不同次序加入排列的情况，计算这些情况下客户端$n$带来的期望价值增益，并以此作为其对联邦训练的贡献。具体来说，夏普利值的数值越大，则客户端对联邦训练的贡献也就越大，反之则越小。另外，夏普利值具备的合理性、对称性、零贡献、可加性等性质\cite{dubey1975uniqueness}使得夏普利值法相比其他贡献评估方法更加公平和合理。

\begin{equation}
    \label{eq:shapley-value}
	\phi_{n}:=\mathbb{E}_{\pi \in \Pi}\left[v\left(\mathcal{S}_{\pi, n} \cup\{n\}\right)-v\left(\mathcal{S}_{\pi, n}\right)\right]
\end{equation}

然而，夏普利值法并不适用于本文的场景。因为计算夏普利值需要枚举客户端所有以不同次序加入排列的情况，复杂度高达$O(2^N)$，而本文的目标是训练一个性能良好的联邦模型，同时减少通信和计算资源的消耗，因此在贡献评估上花费大量的时间是不必要的。另外一些夏普利值的估计方法\cite{dai2018toward,sim2020collaborative}则需要一个辅助的验证数据集，不符合本文设置的场景。为了克服上述挑战，CGSV算法\cite{xu2021gradient}提出用余弦梯度夏普利值对真实的夏普利值进行近似，并通过理论证明了二者之间仅存在一个有界的误差，因此无需高复杂度的计算和辅助的验证数据集。余弦梯度夏普利值的计算方法如等式（\ref{eq:cos-shapley}）所示，其中$\boldsymbol{u}_n^t$代表客户端$n$在通信轮次$t$的参数更新，而$\boldsymbol{U}^t$表示通过加权聚合后的参数更新。余弦梯度夏普利值反映了客户端模型参数更新与联邦模型参数更新之间的余弦相似度，$\boldsymbol{u}_n^t$和$\boldsymbol{U}^t$的余弦相似度越大，客户端$n$的对联邦训练的贡献越大，反之则贡献越小。

\begin{equation}
    \label{eq:cos-shapley}
    \psi_n^t:=\cos (\boldsymbol{u}_n^t,\boldsymbol{U}^t)
\end{equation}

为了让客户端的贡献评估更加准确和稳定，其值以迭代的方式进行计算。\ref{subsec:aggregation-design}节将客户端的贡献与其聚合权重联系起来，通过贡献评估调整客户端对联邦训练的参与程度，因此$r_n^{t}$既代表了客户端$n$在通信轮次$t$的聚合权重，也代表了其在联邦训练开始后的贡献。初始聚合权重$r_n^0$设置为客户端$n$的数据量占总数据量的比例，而等式（\ref{eq:important-score}）展示了每个通信轮次中每个客户端的聚合权重的计算方式，其中$\gamma^t$是权衡系数。等式（\ref{eq:gamma}）表明$\gamma^t$随着通信轮数的增加而衰减，当$\gamma^0=1$时，整个联邦学习的框架退化为FedAvg算法。初始权衡系数$\gamma^0$的值越大，则贡献评估更看重训练后期客户端的贡献，有效减轻模型参数随机初始化产生的噪声。$\gamma^0$的值越小，则贡献评估更多地考虑客户端数据量的影响，联邦模型测试准确率的变化更加稳定。\ref{subsec:exp-tradeoff-ratio}节对$\gamma^0$的设置进行了讨论。值得注意的是，在等式（\ref{eq:important-score}）之后，还需要对聚合权重进行归一化，以保证所有客户端的聚合权重之和为1。\ref{sec:contribution-effective}节的实验验证了基于余弦梯度夏普利值的贡献评估方法的有效性。

\begin{equation}
    \label{eq:important-score}
    r_n^{t+1}:=\gamma^t r_n^{t} + (1-\gamma^t)\psi_n^t
\end{equation}

\begin{equation}
    \label{eq:gamma}
    \gamma^t:=1-\frac{1-\gamma^0}{t}
\end{equation}



### \subsection{模型聚合算法的设计}

\label{subsec:aggregation-design}

贡献评估方法常用于联邦学习的激励机制和公平性的设计中\cite{王勇2022联邦学习贡献评估综述}，本节将讨论贡献评估对于调整客户端参与程度和改善联邦大模型训练效果的作用。在客户端之间样本标签非独立同分布且带有不同比例噪声的情况下，样本标签的质量存在差异，并且客户端对于联邦训练的贡献也是有差异的。低贡献客户端的大量参与会对联邦训练产生影响\cite{kairouz2021advances}，具体来说，低贡献客户端的参数更新方向会干扰联邦模型的参数更新方向，增加联邦模型训练收敛的时间，并且可能让联邦模型收敛到一个损失较大的局部最优解。因此，一个直观的想法是在客户端的贡献评估和聚合权重之间建立联系，让联邦模型的参数更新按客户端的贡献进行加权，降低低贡献客户端在联邦训练中的的参与程度，减轻其对于联邦模型参数更新的影响。

\begin{algorithm}[h]
    \KwIn{剪枝模型参数$\hat{\boldsymbol{\theta}}^{t}$，客户端聚合权重$r^{t}$，客户端参数更新$\Delta\hat{\boldsymbol{\theta}}^{t}$，权衡系数$\gamma$}
    \KwOut{更新后的剪枝模型参数$\hat{\boldsymbol{\theta}}^{t+\frac{1}{2}}$，更新后的客户端聚合权重$r^{t+1}$}
    归一化参数更新：$\boldsymbol{u}_n^t\leftarrow\frac{\Delta\hat{\boldsymbol{\theta}}_n^{t}}{\lVert\Delta\hat{\boldsymbol{\theta}}_n^{t}\rVert},n\in\{1,2,\cdots,N\}$\\
    聚合参数更新：$\boldsymbol{U}^t\leftarrow\sum_{n=1}^N r^{t}_n \boldsymbol{u}_n^t$\\
    更新剪枝模型参数：$\hat{\boldsymbol{\theta}}^{t+\frac{1}{2}}\leftarrow\hat{\boldsymbol{\theta}}^{t}+\boldsymbol{U}^t$\\
    根据等式（\ref{eq:cos-shapley}）计算每个客户端的余弦梯度夏普利值\\
    根据等式（\ref{eq:important-score}）计算每个客户端的聚合权重\\
    归一化聚合权重：$r_n^{t+1}\leftarrow \frac{r_n^{t+1}}{\sum_{n\in\{1,2,\cdots,N\}} r_n^{t+1}},n\in\{1,2,\cdots,N\}$\\
    \caption{基于贡献评估的模型聚合算法}
    \label{algo:aggregation}
\end{algorithm}

在每个通信轮次$t=1,2,\cdots,T$，服务器需要将客户端训练好的模型聚合起来，融合成为一个全局模型。在FedAvg算法\cite{mcmahan2017communication}中，模型以加权的方式进行聚合：$\hat{\boldsymbol{\theta}}^{t+\frac{1}{2}}\leftarrow\sum_{n=1}^N r_n^t\hat{\boldsymbol{\theta}}_n^t$。与之稍有不同的是，本文使用参数更新进行聚合，可以通过简单的推导证明两种聚合方式是等效的。$\Delta\hat{\boldsymbol{\theta}}^{t}_n$表示客户端$n$在通信轮次$t$训练前后模型参数的变化，通过训练后的模型参数与训练前的模型参数相减得到，并通过归一化防止梯度爆炸（gradient explosion）。服务器接收到客户端发送的参数更新后，加权聚合得到聚合参数更新，最后更新剪枝模型的参数。算法\ref{algo:aggregation}展示了基于贡献评估的模型聚合算法的流程。

CGSV算法\cite{xu2021gradient}和FOC算法\cite{chen2020dealing}的实验证实了基于贡献评估的聚合算法对于联邦模型训练效果的改善，尤其是在客户端样本标签质量存在差异的情况下。\ref{sec:ablation}节的消融实验也验证了基于余弦梯度夏普利值的模型聚合算法的作用，即降低了低贡献客户端在联邦训练中的参与程度。此外，\ref{subsec:exp-tradeoff-ratio}节的超参数实验对初始权衡系数$\gamma^0$的设置进行了讨论。最后，\ref{sec:exp-contribution-ratio}节的探究性实验则试图在贡献评估和剪枝率之间建立联系，探究基于贡献评估的自适应剪枝对联邦模型训练效果的影响。
