## \section{大模型联邦训练算法框架}

\label{sec:framework}

![image-20230315100513858](https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230315_1678845915.png)

本节将对基于剪枝优化的大模型联邦训练算法的框架进行概述，整个算法的流程已经展示在图\ref{fig:framework}中。首先，服务器上有一个初始的联邦密集模型$\theta^0$，为了让这个大模型能够在资源受限的边缘设备上加载、训练和推理，算法首先对$\theta^0$进行初次剪枝，剪枝率$\alpha$是一个预先设定的超参数。在对模型进行剪枝时，逐层剪枝能根据每层的参数数量按比例进行剪枝，而对全连接层和卷积层分别应用ER公式\cite{mocanu2018scalable}和ERK公式\cite{evci2020rigging}计算剪枝率能使整体剪枝率维持在$\alpha$左右，逐层剪枝算法的设计和实现细节将在\label{sec:dynamic-pruning}节进行介绍。在这然后，算法会以迭代的方式进行，本文称为服务器与客户端之间的多轮通信：$t=1,2,\cdots,T$。每轮通信开始时，服务器向$N$个客户端分发经过剪枝的联邦模型，因为模型经过了剪枝，所以通信的成本和客户端的计算量相比未经过任何模型压缩操作的情况将会有所降低。客户端接收到联邦模型后，利用本地数据集$\mathcal{D}_{n}$和本地的计算资源进行训练，训练的算法是随机梯度下降。客户端使用随机梯度下降算法对本地模型$\theta^{t}_n$进行更新，然后将参数的更新$\Delta\theta^{t}_n$上传给服务器。

服务器接收客户端的参数更新后，就进入了\label{sec:contribution-aggregation}节介绍的基于贡献评估的聚合算法模块。服务器首先会对接收到的参数更新进行归一化，然后加权聚合为全局的参数更新，并利用聚合参数更新对联邦模型的参数进行更新。本文将更能体现客户端数据价值和贡献大小的余弦梯度夏普利值作为客户端模型聚合的权重，而不是FedAvg算法所使用的\cite{mcmahan2017communication}客户端的数据量占总数据量的比例。针对聚合权重计算方式的替代将提升联邦模型在不同分布且带有噪声的样本标签上训练的效果，给联邦模型带来一定的鲁棒性。

若通信轮次$t$仍然处在某个预先设定的允许调整的范围$T_{end}$内，则\label{sec:contribution-aggregation}节介绍的基于动态拓扑的剪枝算法将会每隔$\Delta T$个通信轮次对联邦模型的拓扑进行调整。这种动态剪枝的首先对整体的剪枝率进行放大，剪去模型剩余的部分权重，然后随机恢复相同数量的权重，使得整体的剪枝率恢复到预先设定的大小。这一模块基于动态剪枝的思想，允许在训练过程中对拓扑进行动态调整。充分的实验可以证明，保持相同的参数量和计算量，动态剪枝相比静态剪枝、大型密集模型和参数量相同的小型密集模型有更好的训练效果。

图\ref{fig:framework}形象展示了基于剪枝优化的大模型联邦训练算法的流程，而算法\ref{algo:framework}则展示了更多的细节。

![image-20230315165458977](https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230315_1678870507.png)