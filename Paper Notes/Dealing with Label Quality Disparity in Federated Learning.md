# [FOC] Dealing with Label Quality Disparity in Federated Learning

## Abstract

联邦学习 (FL) 对于遭受筒仓效应和隐私保护的应用程序非常有用，例如医疗保健、金融、教育等。现有的 FL 方法通常不考虑本地数据标签质量的差异。 然而，由于注释者的技能水平不同、偏见或恶意篡改，参与者往往会受到标签噪声的影响。 在本章中，我们提出了一种替代方法来应对这一挑战。 它在 FL 协调器上维护一小组基准样本，并通过计算 FL 模型在本地数据集上的性能与参与者本地模型的性能之间的相互交叉熵来量化参与者本地数据的可信度，而无需直接观察它们 在基准数据集上。 然后，执行信用加权编排以根据他们的可信度值调整分配给 FL 模型中参与者的权重。 通过对合成数据和真实数据进行实验评估，结果表明，所提出的方法有效地识别了带有噪声标签的参与者，并减少了他们对 FL 模型性能的影响，从而显着优于现有的 FL 方法。



## Introduction

随着边缘计算的发展，End-Edge-Cloud系统的增长使得海量个人数据的收集和处理成为可能。 这引起了隐私问题，如果不加以解决，可能会阻碍此类技术的发展。 联合学习 (FL) 已成为一种有用的机器学习范例，有助于以保护隐私的方式利用个人数据 [9]。 在 FL 下，多个参与者在不交换原始数据的情况下协作训练 FL 模型。 然而，仍然存在并阻碍 FL 广泛采用的一个关键挑战是标签质量差异，尤其是在医疗保健领域。

参与者本地数据集中标签的质量会影响 FL 模型的性能。 现有的 FL 方法隐含地假设本地数据集的标签质量没有显着差异 [3]。 因此，流行的 FL 方法（例如 FedAvg）平等对待来自不同参与者的模型参数 [6]。 由于标注者技能的差异、偏见或恶意篡改，标签噪声在 FL 系统收集的数据中很常见 [10、12]。 以医疗保健为例，中国各地的医院水平不一，即使患者病例相同，小医院的误诊病例通常也多于人员配备较好的大医院。 显然，带有噪声标签的参与者可能会对 FL 中的学习模型产生负面影响，因为它提供了错误的知识 [3]。 更具挑战性的是，由于在 FL 设置中禁止共享原始数据，因此很难检测到嘈杂的参与者，更不用说嘈杂的参与者可能没有自我意识。 因此，使 FL 系统能够有效地检测和处理标签质量差异对其成功至关重要。

在本章中，我们提出联合机会计算 (FOC) 方法来解决这一具有挑战性的问题。 它旨在识别带有嘈杂标签的参与者，并以机会主义的方式将他们的模型参数聚合到 FL 模型中。 FOC 适用于跨筒仓联合设置。 它在中央协调器中维护一小组基准样本，这不足以训练一个强大的模型。 在 FL 训练过程中，本地模型（在每个参与者的本地数据上进行训练）和协调器上的 FL 模型（聚合模型）将形成 Twin Network，两者共享相同的模型架构 但参数不同。 通过定义孪生网络的相互交叉熵损失，可以衡量每个参与者数据的可信度，然后用于确定允许相应参与者参与 FL 的程度。 在每一轮中，FOC 都会对协调器执行可信度加权编排，以避免更新损坏。 术语“机会主义”用于表示参与者模型不是通过简单平均（如 FedAvg [5] 的情况）聚合到 FL 模型中，而是按其可信度加权。

为了评估 FOC，我们首先在一个合成的人类活动识别数据集上对其进行测试，其中标签在参与者的一个子集中以不同的方式被篡改。 然后，它在来自具有不同标签质量的医院的真实数据集上进行测试，以检测帕金森病症状。 实验结果表明，与现有的 FL 方法相比，FOC 可以检测带有噪声标签的参与者，并更有效地降低它们对 FL 模型性能的影响。



## Related Work

标签噪声是机器学习中的一个常见问题，可能导致联邦学习参与者之间的标签质量差异。 与联邦学习中参与者可能具有不同数据分布但具有正确标签的非 IID 问题不同，标签质量差异反而关注标签可能不一致的情况，即使参与者被赋予相同的实例集。

在传统的机器学习设置中，有两类方法来处理这个问题：1）在数据级别和 2）在算法级别。 在数据层面，现有方法通常旨在清理噪声标签以减轻其影响。 克雷图等人。 [2] 使用一小部分训练数据生成多个模型并为每个输入生成临时标签。 这用于确定是否存在噪声标签。 谢等。 [8] 设计了拜占庭稳健的聚合器来防御对卷积神经网络的标签翻转数据中毒攻击。 然而，Koh 等人。 [4] 最近发现联合数据清理方法仍然容易受到数据中毒攻击。

在算法层面，现有方法通常旨在训练抗噪声模型。 纳塔拉扬等人。 [7] 从理论角度研究了标签噪声在二元分类中的影响，并提出了一种简单的加权代理损失来建立强大的经验风险界限。 由于深度学习模型很容易过度适应标签噪声，Zhang 等人。 [13] 使用元学习来训练深度模型，其中生成合成噪声标签以在常规梯度更新之前更新模型。 然而，这些现有方法不能直接应用于联邦学习的背景下，因为它们需要访问原始数据。

在 FL 中，标签噪声也与非 IID 问题有关。 赵等。 [14] 发现非 IID 参与者在 FL 中产生了一个糟糕的全球模型，因为参与者数据中的大地球移动距离 (EMD) 使他们的模型多样化。 然而，拟议的数据共享策略需要更多的沟通，并有稀释参与者信息的风险。 此外，EMD 的计算要求 FL 协调员能够访问参与者的原始数据，这在 FL 设置下是不允许的。

据我们所知，目前还没有关于减轻 FL 设置下标签噪声影响的已发表作品。