# [FedDST@AAAI 2022] Federated Dynamic Sparse Training: Computing Less, Communicating Less, Yet Learning Better

## Abstract

联合学习 (FL) 可以将机器学习工作负载从云端分配到资源有限的边缘设备。 不幸的是，当前的深度网络不仅对于边缘设备上的推理和训练来说计算量太大，而且对于通过带宽受限的网络进行更新通信来说也太大了。 在本文中，我们开发、实施并通过实验验证了一种称为联合动态稀疏训练 (FedDST) 的新型 FL 框架，通过该框架可以部署和训练复杂的神经网络，并显着提高设备上计算和网络内通信的效率。 FedDST 的核心是一个从目标全网络中提取和训练稀疏子网络的动态过程。 有了这个方案，“一箭双雕：”而不是完整的模型，每个客户端都对自己的稀疏网络进行高效训练，并且只有稀疏网络在设备和云端之间传输。 此外，我们的结果表明，与固定的共享稀疏掩码相比，FL 训练期间的动态稀疏性更灵活地适应 FL 代理中的局部异质性。 此外，**动态稀疏性**自然地将“及时自集成效应”引入训练动态中，甚至在密集训练中也能提高 FL 性能。 在现实且具有挑战性的非 i.i.d. 在 FL 设置下，FedDST 在我们的实验中始终优于竞争算法：例如，在非 iid CIFAR-10 上的任何固定上传数据上限下，在给定相同的上传数据上限时，它比 FedAvgM 获得了 10% 的令人印象深刻的准确性优势； 即使 FedAvgM 的上传数据上限是 2 倍，准确度差距仍为 3%，进一步证明了 FedDST 的有效性。 代码位于：https://github.com/bibikar/feddst。



## Introduction

在**保护个人数据隐私**和在**边缘启用机器学习** (ML) 的愿望的推动下，联邦学习 (FL)（McMahan 等人 2017 年；Kairouz 等人 2019 年）最近成为了实现分布式的实际范例 ML 在大量客户端设备上。 在 FL 系统中，中央云服务器在客户端网络中调解信息传输，这些客户端必须保持其本地数据的私密性。 FL 中的经典方法 (McMahan et al. 2017) 涉及多个同步回合； 在每一轮中，FL 仅使用每个设备上本地可用的数据在设备子集上运行几个本地训练时期。 在本地训练之后，客户端的模型更新而不是本地数据被发送到中央服务器，然后中央服务器将它们全部聚合以更新全局模型。

在 FL 系统中，繁重的计算工作负载从云端分派到资源有限的边缘设备。 为了在边缘使用，FL 系统必须同时优化设备级**本地训练效率**和**网络内通信效率**。 不幸的是，当前的 ML 模型通常过于复杂，无法在边缘设备上进行推理，更不用说训练了。 除了模型的紧凑性，云和设备之间的通信效率也是可取的。 由于不对称的互联网连接，客户端设备（例如手机）通常具有严重的**上传带宽限制**，因此降低联邦学习算法的上传成本至关重要。 高效通信 FL 的许多先前工作都集中在 FL 更新中的结构化和草图稀疏性（Konecnˇ y et al.´ 2017）、最佳客户端抽样（Ribero 和 Vikalo 2020）和其他经典方法。

为了生成用于边缘设备推理的轻量级模型，人们在优化稀疏神经网络 (NN) 方面做出了重大努力（Gale、Elsen 和 Hooker，2019 年；Chen 等人，2020 年、2021 年；Ma 等人，2021 年）。 这些方法显着减少了推理延迟，但严重影响了训练所需的计算和内存资源。 彩票假说 (Frankle and Carbin 2018) 表明**密集 NN 包含稀疏匹配子网络**，这些子网络能够独立训练以达到完全准确度（Frankle 等人 2020）。 更多作品表明稀疏性可以在初始化时出现（Lee、Ajanthan 和 Torr 2019；Wang、Zhang 和 Grosse 2020）或者可以在训练期间以动态形式被利用（Evci 等人 2020）。

本文的总体目标是开发、实施和实验验证一种称为联合动态稀疏训练 (FedDST) 的新型 FL 框架，通过该框架可以**部署和训练**复杂的神经网络，同时显着提高设备上**计算和内部计算**的效率。 网络通讯。 FedDST 的核心是一种精心设计的动态稀疏训练联邦方法（Evci 等人，2020 年）。 FedDST 传输客户端的高度稀疏匹配子网络而不是完整模型，并允许每个客户端插入高效的稀疏分布式训练——从而“一石二鸟”。 更重要的是，我们发现 FL 训练期间的动态稀疏性比最先进的算法更能适应 FL 中的**局部异质性**。 动态稀疏性本身会导致及时的自集成效应 (Liu et al. 2021c) 并提高 FL 性能，甚至超过密集训练对应物，这与独立训练中的观察结果相呼应 (Liu et al. 2021c)。 我们将我们的贡献总结如下：

我们首次将动态稀疏训练引入联邦学习，从而无缝集成稀疏 NN 和 FL 范式。 我们的框架名为联合动态稀疏训练 (FedDST)，它利用稀疏性作为统一工具来节省通信和本地培训成本。

通过使用灵活的聚合方法，我们在 FedAvg 之上部署了 FedDST（McMahan 等人，2017 年），没有来自客户端的额外传输开销。 作为一般设计原则，我们的方法很容易扩展到其他 FL 框架，例如 FedProx (Li et al. 2018)。 此外，动态稀疏性的概念被发现可以**适应局部异质性**，并产生**及时自集成**的额外效果，即使在密集基线上也能提高 FL 性能。

大量实验表明，FedDST 显着提高了在病理非独立同分布数据分布的难题上的通信效率。 即使在这些非 iid 设置中，FedDST 在 CIFAR-10 上也比 FedAvgM（Hsu、Qi 和 Brown 2019）提高了 3% 的准确性，同时只需要一半的上传带宽。 我们还提供广泛的**消融**研究，显示 FedDST 对其参数的合理变化的**稳健性**。 这些结果表明稀疏训练是未来 FL 的“首选”选项。



## Related Work

据我们所知，只有两个作品解决了整个 FL 过程中的修剪问题。 PruneFL (Jiang et al. 2020) 依赖于在特定客户端选择的初始掩码，然后是类似 FedAvg 的算法，该算法每 ΔR 轮执行掩码重新调整。 然后通过稀疏矩阵操作进行训练。 在掩码调整轮次中，客户端需要上传完整的密集梯度，服务器使用这些梯度来形成聚合梯度 g。 选择掩码时，对应于可修剪权重的索引 j 按 gj2=tj 排序，其中 tj 是在网络中保留连接 j 的时间成本的估计。 通过测量具有各种稀疏性的一轮 FL 的时间成本，通过实验确定估计值 tj。 其次，与 PruneFL 不同，FedDST 是为具有挑战性的、现实的非 iid FL 设置而设计的。 出于这个原因，FedDST 的聚合和动态稀疏训练允许在客户端重新调整掩码，以 PruneFL 的自适应修剪标准无法实现的方式为非 iid 数据提供弹性。 特别是，PruneFL 的客户不会在第一轮之后重新调整掩模； 相反，它们会在某些回合将梯度传输到服务器，服务器使用梯度幅度和层时间来决定下一轮的掩码。 **由于数据异质性意味着无法在客户端之间直接比较梯度大小，因此梯度聚合本质上是不稳定的。** FedDST 通过仅使用客户端提交的权重大小和掩码“投票”来决定服务器上的掩码，从而提供稳定的更新。 我们的实验证明了 FedDST 与 PruneFL 在泛化能力方面的优势。

LotteryFL (Li et al. 2020) 从 LGFedAvg (Liang et al. 2020) 中汲取灵感，并允许客户端通过选择全球网络的本地子集来维护本地表示。 它也可以描述为 FedAvg 的扩展，其中每个客户端 c 维护一个单独的掩码 mc。 在每一轮 r 中，选定的客户端使用本地验证集评估他们的子网络 θr ⊙ mr c。 如果验证精度超过预定义的阈值并且客户端当前的稀疏度 kmr ck0 小于目标稀疏度，则执行幅度剪枝以产生新的掩码 mr c+1 并将相应的权重重置为其初始值。 将 FedDST 与 FL 中的先前修剪工作进行比较。 首先，与 **LotteryFL 生成的稀疏模型系统仅在本地数据集上表现良好**不同，FedDST 生成一个全局稀疏模型，随着时间的推移动态变化，在任何地方都表现良好。 FedDST 在客户端和服务器上执行掩码重新调整，但这些都是相对低开销的操作（逐层幅度修剪和梯度幅度增长）。 而且，FedDST 既不传输密集模型，也不传输梯度，甚至在最开始也不训练密集模型：这与 LotteryFL 形成鲜明对比，使 FedDST 明显更轻。

由于整个训练过程中固定的稀疏预算，FedDST 更新需要非常少的网络带宽，即使在最坏的情况下也是如此。 尽管 PruneFL 也为大多数轮次传输稀疏更新，但它每隔几轮就将全密集梯度传输到服务器以促进掩码重新调整。 LotteryFL 要求客户端传输密集模型，除非其精度达到一定阈值，因此密集传输发生得更频繁。



## Methodology

FedDST 为神经网络的动态稀疏训练提供了一种完全联合的方法。 在这种方法中，我们的目标是**学习一个单一模型，为所有客户端提供良好的准确性**，同时消耗最少的计算、内存和通信资源。 我们的方法旨在即使在病理上非独立同分布的情况下也能表现良好。

我们首先在服务器上初始化服务器网络 θ1 和稀疏掩码 m1，遵循 (Evci et al. 2020) 中描述的逐层稀疏分布。 在每一轮 r，服务器对客户端 Cr 进行采样。 服务器网络和掩码被发送到客户端 c ∈ Cr。 每个客户执行 E 轮的局部训练。 在局部训练的 Ep-th epoch 之后，客户端执行掩码调整，将模型质量的 αr 重新分配给不同的连接。 仅在某些回合进行重新调整，重新调整的频率由ΔR指定

选定的客户端将其新的稀疏网络和掩码（如果需要）上传到服务器，服务器聚合接收到的信息以产生新的全局参数和掩码（θr+1；mr+1）。 服务器端聚合方法将在本节后面讨论。

客户端掩码调整过程很熟悉，灵感来自 RigL (Evci et al. 2020)。 mask 调整的目标是重新分配模型质量的 αr，以寻求更有效的子网络。 我们首先将网络修剪为更高的稀疏度 S + (1 - S)αr，同时保持相同的权重分布。 然后，我们通过梯度 gcr 重新生成相同数量的被修剪的权重，返回到相同的原始稀疏度。 因为一轮中不同的客户端可能会产生不同的掩码，服务器必须聚合多个可能在完全不同的方向探索掩码空间的稀疏网络。 与 (Evci et al. 2020; Dettmers and Zettlemoyer 2019) 一样，我们对 αr 使用余弦衰减更新时间表，

在第一轮，我们有 α1 = α，每次重新分配的权重比例在 Rend 轮衰减到 0。 参数 α 控制掩码空间探索与客户之间就掩码决策达成一致之间的权衡。 较大的 α 值鼓励在掩码空间周围更快地移动，而较小的值鼓励掩码的一致和增量调整。 我们在实验中探索了 α 的影响。

因为服务器不直接从客户端接收梯度，所以它必须仅使用从客户端接收的参数和掩码来决定下一轮的掩码。 由此，我们定义稀疏加权平均值：

该方法的灵感来自 FedAvg（McMahan 等人，2017 年）中使用的加权平均值，其中特定客户端对特定参数的影响由该客户端的数据集大小加权。 但是，稀疏加权平均值也忽略了未提供任何值的客户端的参数值。 特别是，如果客户端已经删除了一个权重，则出于聚合该权重的目的，将忽略该客户端。 特别是在病理性非同源性 FL 设置中，我们发现 FedDST 从这种掩码聚合方法中受益匪浅。 客户端之间不能直接比较随机梯度的大小，因为客户端之间的数据分布差异很大。 出于这个原因，诸如 PruneFL 之类的方法在相同的设置中表现出掩模不稳定问题。 FedDST 使用大量的权重和来自客户的“投票”来解决这个问题。

动态稀疏性带来的准确性增益：时空集成效应。 我们的实验表明，FedDST 不仅节省了通信/计算，而且还提高了性能：这在高度非 i.i.d. 中尤为显着。 设置。 我们将“少即是多”现象归因于 FedDST 独有的潜在时空“集成效应”。

在“空间”方面，我们指的是在 FedDST 中，一个掩码从云端发送到所有客户端，但每个客户端都可以重新调整他们的掩码并根据其非 i.i.d. 重新采样权重。 本地数据。 这些新的稀疏掩码和权重会在云中定期重新组装，让人想起著名的模型子采样和“dropout”的集成效应（Hinton 等人，2012 年），现在沿着 FL 的空间维度（跨客户端）。 也就是说，每个客户端都可以被视为密集云模型的不同采样子网（不是随机的，而是“学习的丢失”），这样可以通过集成这些子网络权重来为云模型训练更强大的权重提供正则化效果 . 请注意，这种类似的效果不会发生在 PruneFL 中，其中所有客户端每次都共享一个掩码。 虽然 LotteryFL 还允许每个客户端拥有自己的掩码，但它会带来沉重的本地计算开销。 在“时间”方面，FedDST 通过时间探索掩码空间，同时还学习权重 θr。 总而言之，它允许跨训练进行连续参数探索，驯服时空过度参数化（Liu et al. 2021c），这可以显着提高稀疏训练的可表达性和泛化性。

从上面的基本示例来看，FedDST 可以轻松适应不同的局部和全局优化器，如 (Reddi et al. 2021) 中所述。 算法 1 显示了 FedDST 的总体轮廓，其中本地训练可以根据需要使用任何优化器。 例如，我们使用 (Hsu, Qi, and Brown 2019) 中描述的具有动量的 SGD 作为我们实验中的局部优化器。 聚合稀疏更新生成的伪梯度也可以与其他全局优化器一起使用。 FedDST 也兼容 FedProx (Li et al. 及其近端惩罚项 kθcr - θrk2。但是，如果此惩罚项直接用于 mask 调整，则该惩罚项将作为已被修剪掉的权重的权重衰减项。这些权重 因此，将不太可能被选择用于再生。因此，在客户端增长中，我们使用与损失相对应的梯度，而没有近端项。
