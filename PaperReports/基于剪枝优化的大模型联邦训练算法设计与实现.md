# 基于剪枝优化的大模型联邦训练算法设计与实现

现有的基于剪枝优化的联邦学习算法主要围绕剪枝的对象和剪枝的程度进行研究。其中一些工作直接将现有的剪枝方法加入联邦训练的过程，或者预先设定剪枝率，忽视了联邦学习中系统异构的场景。另外一些工作采用了自适应剪枝的方式，为不同的客户端设置不同的剪枝率，但仍然回避了数据异构的问题。对基于剪枝优化的联邦学习算法进行研究，使其有效适应**系统异构**和**数据异构**的场景，是该研究方向的一个发展趋势。其余的关注点还包括联邦剪枝中的隐私保护问题，以及对有目标攻击（如后门攻击）的有效防御。



### 基础实验

PruneFL: Model Pruning Enables Efficient Federated Learning on Edge Devices

FedMP: Federated Learning through Adaptive Model Pruning in Heterogeneous Edge Computing

- 自适应模型剪枝：

  - 每轮$k \in\{0,1, \ldots, K\}$，中心服务器根据每个客户端$n$的**能力**来决定特定的剪枝率$\alpha_{n}^{k}$

  - 然后中心服务器根据剪枝率将全局模型$\mathbf{x}^{k}$**结构化**修剪为子模型，每层使用相同的剪枝率，通过重要性分数（L1范数）指标将不重要的filters/neurons剪掉

  - 发送给客户端进行本地训练

- 本地训练：每一次训练，客户端利用本地数据集对子模型进行$\tau$次的迭代更新，当迭代次数$t \in\{0,1, \ldots, I\}$为$\tau$的倍数时，进行模型聚合


- 模型聚合：
  - 中心服务器基于**模型残差**和存储的索引信息对子模型进行恢复
  - 通过聚合恢复后的模型对全局模型进行更新

<img src="D:\github\assets\image-20230207065103956.png" alt="image-20230207065103956" style="zoom: 33%;" />

<img src="D:\github\assets\image-20230207083559579.png" alt="image-20230207083559579" style="zoom:50%;" />



### 场景创新：资源受限 + 系统异构 + 数据异构

建立剪枝率与**客户端计算能力**、**数据non-iid程度**的联系，考虑**效率与准确率**之间的平衡

- **客户端计算能力**：计算时间

- **数据non-iid程度**：模型参数的方差、本地更新的绝对值、本地loss的方差

FedSCR: Structure-Based Communication Reduction for Federated Learning

- 思路：多臂老虎机
  - 中心服务器player，剪枝率arms
  - 客户端计算能力和数据non-iid程度决定reward，从而计算置信区间上界UCB，拥有最大置信区间上界的区域将被选择

FedMP: Federated Learning through Adaptive Model Pruning in Heterogeneous Edge Computing



### 方法创新：剪枝和恢复策略

- Federated Dynamic Sparse Training: Computing Less, Communicating Less, Yet Learning Better：FedDST的聚合和动态稀疏训练允许在客户端重新调整掩码，通过决定服务器上的掩码来提供稳定的更新，由于整个训练过程中固定的稀疏预算，FedDST 更新需要非常少的网络带宽
- Complement Sparsification: Low-Overhead Model Pruning for Federated Learning：在 CS 中，剪枝在客户端的计算开销非常低，因为它们唯一的任务是删除全局稀疏模型中以前非零的权重。这种低开销使得 CS 对于资源受限的设备很实用



### 工作量与创新性

- ”自己工作的篇幅不能低于总篇幅的一半“：
  - 研究系统异构和数据异构对训练时间和准确性的影响？
  - 同步和异步算法？
  - 多种思路和方法？
  - 增加实验对比？