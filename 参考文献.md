## FedMP: Federated Learning through Adaptive Model Pruning in Heterogeneous Edge Computing

联邦学习 (FL) 已被广泛用于在边缘计算的海量分布式数据源上训练机器学习模型。 然而，现有的 FL 框架通常存在资源限制和**边缘异质性**的困难。 在此，我们设计并实现了 FedMP，这是一种通过自适应模型修剪的高效 FL 框架。 我们从理论上分析了剪枝率对模型训练性能的影响，并提出采用基于多臂强盗的在线学习算法来自适应地确定异构边缘节点的不同剪枝率，即使事先不知道它们的计算和通信能力。 通过自适应模型剪枝，FedMP 不仅可以减少资源消耗，还可以实现有希望的准确性。 为了防止剪枝模型的不同结构影响训练收敛，我们进一步提出了一种新的参数同步方案，称为残差恢复同步并行（R2SP），并提供了理论上的收敛保证。 在经典模型和数据集上进行的大量实验表明，FedMP 对于不同的异构场景和数据分布是有效的，并且与现有的 FL 方法相比可以提供高达 4.1 倍的加速。

![image-20230308201823418](https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230308_1678277904.png)

![image-20230308201809144](https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230308_1678277890.png)



## Lottery Aware Sparsity Hunting: Enabling Federated Learning on Resource-Limited Edge

客户端有限的计算和通信能力对资源有限的边缘节点上的联邦学习 (FL) 提出了重大挑战。 这个问题的一个潜在解决方案是部署现成的稀疏学习算法，在每个客户端上训练一个二进制稀疏掩码，期望训练一个一致的稀疏服务器掩码产生稀疏权重张量。 然而，正如我们在本文中调查的那样，与具有密集模型的 FL 相比，这种简单的部署会导致准确性显着下降，尤其是对于资源预算有限的客户。 特别是，我们的调查表明，在客户端训练的稀疏掩码之间严重缺乏共识，这会阻止服务器掩码的收敛，并可能导致模型性能大幅下降。 基于这些关键观察，我们提出了联邦彩票感知稀疏性搜索（FLASH），这是一个统一的稀疏学习框架，使服务器在产生稀疏子模型方面中奖，能够在**资源高度受限**的客户端下保持分类性能 设置。 此外，为了在需要不同参数密度的不同设备上支持 FL，我们利用我们的发现来展示异型闪存，其中客户端可以根据其设备资源限制具有**不同的目标稀疏度预算**。 在各种数据集（独立同分布和非独立同分布）上使用多个模型进行的实验评估表明，与现有替代方案相比，我们的模型在缩小与未修剪基线的差距方面具有优势，同时提高了约 10.1% 的准确性，减少了约 10.26 倍的通信成本， 在类似的超参数设置。

<img src="https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230308_1678278323.png" alt="image-20230308202515682" style="zoom: 50%;" /><img src="https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230308_1678278576.png" alt="image-20230308202926198" style="zoom:50%;" />



## Federated Learning with Non-IID Data

联合学习使资源受限的边缘计算设备（例如手机和物联网设备）能够学习共享模型进行预测，同时将训练数据保持在本地。 这种去中心化的模型训练方法提供了隐私、安全、监管和经济利益。 在这项工作中，我们专注于当本地数据为**非 IID** 时联邦学习的统计挑战。 我们首先表明，联邦学习的准确性会显着降低，对于针对高度倾斜的非 IID 数据训练的神经网络，最高可降低约 55%，其中每个客户端设备仅在单一类别的数据上进行训练。 我们进一步表明，这种精度下降可以用权重差异来解释，权重差异可以通过每个设备上的类别分布与人口分布之间的推土机距离 (EMD) 来量化。 作为解决方案，我们提出了一种策略，通过创建在所有边缘设备之间全局共享的一小部分数据来改进非 IID 数据的训练。 实验表明，对于 CIFAR-10 数据集，只有 5% 的全局共享数据的准确性可以提高约 30%。

<img src="https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230308_1678279118.png" alt="image-20230308203832773" style="zoom:50%;" />



## ZEROFL: EFFICIENT ON-DEVICE TRAINING FOR FEDERATED LEARNING WITH LOCAL SPARSITY

当可用硬件无法满足有效训练高性能机器学习模型的内存和计算要求时，需要在训练质量或模型复杂性方面做出妥协。 在联邦学习 (FL) 中，节点比传统的服务器级硬件受到更多数量级的限制，并且通常由电池供电，严重限制了可以在此范例下训练的模型的复杂性。 虽然大多数研究都集中在设计更好的聚合策略以提高收敛速度和减轻 FL 的通信成本，但很少有人致力于**加速设备上的训练**。 这个阶段重复数百次（即每一轮）并且可能涉及数千台设备，占训练联合模型所需时间的大部分以及客户端的总能耗。 在这项工作中，我们首次研究了在 FL 工作负载的训练时引入稀疏性时出现的独特方面。 然后，我们提出了 ZeroFL，这是一个依赖高度稀疏操作来加速设备上训练的框架。 与通过将最先进的稀疏训练框架应用于 FL 设置而获得的竞争基线相比，使用 ZeroFL 和 95% 稀疏度训练的模型可实现高达 2.3% 的准确性。

<img src="https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230308_1678279886.png" alt="image-20230308205117649" style="zoom: 67%;" />

<img src="https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230308_1678280647.png" alt="image-20230308205200706" style="zoom:67%;" />



## TiFL: A Tier-based Federated Learning System

联合学习 (FL) 可以在不违反隐私要求的情况下跨多个客户端学习共享模型。 FL 的关键属性之一是由于计算和通信能力的差异以及不同客户端之间数据的数量和内容的差异，资源和数据都存在异构性。 我们进行了一个案例研究，以表明**资源和数据的异质性**对传统 FL 系统的训练时间和模型准确性有重大影响。 为此，我们提出了 TiFL，一种基于 Tier 的联邦学习系统，它根据客户的训练表现将客户分成不同的层，并在每一轮训练中从同一层中选择客户，以减轻资源和数据量的异质性造成的散兵游勇问题 . 为了进一步抑制由非 IID（独立和相同分布）数据和资源引起的异质性，TiFL 采用自适应层选择方法，根据观察到的训练性能和准确性动态更新分层。 我们按照 Google 的 FL 架构在 FL 测试台中制作 TiFL 原型，并使用最先进的 FL 基准对其进行评估。 实验评估表明，TiFL 在各种异质条件下优于传统的 FL。 通过提出的自适应层选择策略，我们证明了 TiFL 实现了更快的训练性能，同时全面实现了相同或更好的测试精度。

<img src="https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230308_1678280641.png" alt="image-20230308205527151" style="zoom: 33%;" /><img src="https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230310_1678459461.png" alt="image-20230308210354604" style="zoom:33%;" />



## FedDUAP: Federated Learning with Dynamic Update and Adaptive Pruning Using Shared Data on the Server

尽管取得了显着的性能，联邦学习 (FL) 仍面临两个关键挑战，即**有限的计算资源**和低训练效率。 在本文中，我们提出了一种新颖的 FL 框架，即 FedDUAP，它具有两个原始贡献，以利用服务器上的不敏感数据和边缘设备中的分散数据来进一步提高训练效率。 首先，设计了一种动态服务器更新算法，利用服务器上的不敏感数据，动态确定服务器更新的最佳步骤，以提高全局模型的收敛性和准确性。 其次，开发了一种层自适应模型剪枝方法，以针对多层的不同维度和重要性执行独特的剪枝操作，从而在效率和有效性之间取得良好的平衡。 通过将两种原始技术集成在一起，我们提出的 FL 模型 FedDUAP 在准确性（高出 4.8%）、效率（快 2.8 倍）和计算成本（低 61.9%）方面明显优于基线方法 .

<img src="https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230308_1678280904.png" alt="image-20230308210804229" style="zoom:50%;" />

<img src="https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230308_1678280906.png" alt="image-20230308210819734" style="zoom:50%;" />

<img src="https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230308_1678281027.png" alt="image-20230308210842988" style="zoom: 67%;" />

<img src="https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230308_1678281024.png" alt="image-20230308211016866" style="zoom:50%;" />



## PERSONALIZED FEDERATED LEARNING BY STRUCTURED AND UNSTRUCTURED PRUNING UNDER DATA HETEROGENEITY

FL 中的传统方法试图在中央服务器的编排下，在许多客户端的帮助下协作学习单个全局模型。 然而，在数据异构的情况下，学习单一的全局模型可能不适用于所有参与 FL 的客户端。 因此，全局模型的个性化对于处理**统计异质性和数据的非 IID 分布**带来的挑战至关重要。 与之前的工作不同，在这项工作中，我们提出了一种新方法，用于从客户级目标中获取个性化模型。 这进一步激励所有客户端即使在统计异质性下也参与联邦以提高其性能，而不仅仅是作为中央服务器的数据和模型训练源。 为了实现这种个性化，我们通过应用混合修剪（结构化和非结构化修剪的组合）和非结构化修剪，为每个客户端寻找一个小的子网。 通过对不同基准的一系列实验，我们观察到具有相似数据（标签）的客户共享相似的个人参数。 通过为每个客户端找到一个子网，而不是像传统 FL 那样对整个联邦的所有客户端的所有参数取平均值，我们有效地计算了每个客户端的每个子网的剩余参数的平均值。 我们将这种新颖的参数平均称为 Sub-FedAvg。 此外，在我们提出的方法中，客户不需要了解其他客户之间的任何基础数据分布或标签相似性。 每个客户端本地数据的非 IID 性质提供了不同的子网，而无需共享任何数据。 我们用真实世界的数据集评估我们的联合图像分类方法。 我们的方法优于现有的最先进方法。

<img src="https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230308_1678281209.png" alt="image-20230308211324789" style="zoom:50%;" />

<img src="https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230308_1678281398.png" alt="image-20230308211634883" style="zoom:50%;" />



## FjORD: Fair and Accurate Federated Learning under heterogeneous targets with Ordered Dropout

联邦学习 (FL) 在不同的 ML 任务中获得了显着的吸引力，从视觉到键盘预测。 在大规模部署中，客户端异构性是一个事实，构成了公平性、训练性能和准确性的主要问题。 尽管在解决统计**数据异构性**方面做出了重大努力，但客户端处理能力和网络带宽的多样性（称为**系统异构性**）在很大程度上仍未得到探索。 当前的解决方案要么忽略大部分可用设备，要么对模型的容量设置统一限制，由能力最低的参与者进行限制。 在这项工作中，我们介绍了 Ordered Dropout，这是一种在深度神经网络 (DNN) 中实现有序、嵌套的知识表示的机制，无需重新训练即可提取占用空间较小的子模型。 我们进一步表明，对于线性映射，我们的 Ordered Dropout 等效于 SVD。 我们在 FL 领域的一个名为 FjORD 的框架中采用这种技术以及自蒸馏方法。 FjORD 通过根据客户端的能力定制模型宽度来缓解客户端系统异构性的问题。 跨不同模态对 CNN 和 RNN 的广泛评估表明，FjORD 始终比最先进的基线带来显着的性能提升，同时保持其嵌套结构。

<img src="https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230308_1678282389.png" alt="image-20230308213305251" style="zoom:67%;" />



## WSCC: A Weight-Similarity-Based Client Clustering Approach for Non-IID Federated Learning

物联网 (IoT) 和深度学习的快速发展使得能够从物联网系统中零星节点收集的大量数据中学习有用的模式。 联邦学习在分布式机器学习中受到越来越多的关注，其中只有中间参数与驻留在本地节点的训练样本进行交换。 尽管如此，大多数现有的联邦学习方案都假设数据是均匀分布的。 然而，由于物联网架构的异构性，该假设不适用于物联网系统。 物联网节点的数据量和统计分布的**非独立同分布（非 IID）**属性会影响适合所有节点的聚合全局模型的性能。 现有的非独立同分布数据集的联邦学习解决方案要么必须训练额外的模型，要么需要额外的数据交换来检查节点分布。 然而，由于物联网系统中的资源限制，这些方法将增加有限计算能力的负担并导致网络开销。 为了解决这个问题，在本文中，提出了一种新颖的基于权重相似性的客户端聚类 (WSCC) 方法，该方法根据客户端的数据集分布将客户端分成不同的组。 一种基于亲和力传播的方法，具有客户端权重参数的余弦距离，旨在迭代地自动确定动态集群。 所提出的方法非常适合物联网系统，因为没有辅助模型并且需要额外的数据传输。 通过理论收敛性分析和实证结果，我们表明我们提出的 WSCC 方案在不同的非 IID 设置下优于代表性的联邦学习方案，精度提高了 20%



## FedSCR: Structure-Based Communication Reduction for Federated Learning

联合学习允许边缘设备在其本地数据上协作训练共享模型，而不会泄露用户隐私。 数据分布的非独立同分布 (Non-IID) 属性会导致精度严重下降，并且聚合参数的巨大通信开销应在联邦学习中解决。 在本文中，我们对 Non-IID 数据集上的参数更新进行了详细分析，并比较了与 IID 设置的差异。 实验结果表明参数更新矩阵是结构稀疏的，并且表明更多的梯度可以被识别为对非 IID 数据的可忽略更新。 因此，我们提出了一种基于结构的**通信减少**算法，称为 FedSCR，它减少了通过网络传输的参数数量，同时保持了模型的准确性。 FedSCR 聚合通道和过滤器的参数更新，通过将聚合值与阈值进行比较来识别和删除冗余更新。 与传统的结构化剪枝方法不同，FedSCR 保留了完整的模型，不需要重新训练和微调。 由于数据分布不平衡，每个设备上的局部损失和权重差异差异很大。 我们进一步提出了一种自适应 FedSCR，它动态改变有界阈值，以增强**非 IID 数据上的模型鲁棒性**。 评估结果表明，我们提出的策略在不损失准确性的情况下实现了近 50% 的上游通信减少。 FedSCR 可以集成到最先进的联邦学习算法中，以显着减少推送到全局服务器的参数数量，同时降低可容忍的精度。

<img src="https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230308_1678283608.png" alt="image-20230308214120330" style="zoom: 67%;" />



## Rigging the Lottery: Making All Tickets Winners

由于空间或推理时间限制，许多应用程序需要稀疏神经网络。 关于训练密集网络以产生用于推理的稀疏网络的大量工作，但这将最大可训练稀疏模型的大小限制为最大可训练密集模型的大小。 在本文中，我们介绍了一种在整个训练过程中使用固定参数计数和固定计算成本训练稀疏神经网络的方法，而不会牺牲相对于现有密集到稀疏训练方法的准确性。 我们的方法通过使用参数大小和不频繁的梯度计算在训练期间更新稀疏网络的拓扑结构。 我们表明，与现有技术相比，这种方法需要更少的浮点运算 (FLOP) 来达到给定的精度水平。 我们在各种网络和数据集上展示了最先进的稀疏训练结果，包括 ResNet-50、Imagenet-2012 上的 MobileNet 和 WikiText-103 上的 RNN。 最后，我们提供了一些见解，说明为什么**允许拓扑在优化过程中发生变化可以克服拓扑保持静态*时遇到的局部最小值**。

<img src="https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230308_1678283605.png" alt="image-20230308214943121" style="zoom: 67%;" />



## Model Pruning Enables Efficient Federated Learning on Edge Devices

联邦学习 (FL) 允许根据边缘/移动设备收集的本地数据进行模型训练，同时保护数据隐私，这在图像和视觉应用中具有广泛的适用性。 一个挑战是，与数据中心的服务器相比，FL 中的客户端设备通常具有**更有限的计算和通信资源**。 为了克服这一挑战，我们提出了 PruneFL——一种具有自适应和分布式参数修剪的新型 FL 方法，它在 FL 期间调整模型大小以减少通信和计算开销并最小化整体训练时间，同时保持与原始模型相似的准确性 . PruneFL 包括在选定客户端的初始修剪和作为 FL 过程的一部分的进一步修剪。 在此过程中会调整模型大小，其中包括最大化近似经验风险降低除以一轮 FL 时间。 我们在边缘设备（例如 Raspberry Pi）上对各种数据集进行的实验表明：1）与传统 FL 和其他各种基于剪枝的方法相比，我们显着减少了训练时间，以及 2）具有自动确定大小的剪枝模型收敛到一个准确度 那和原版很像，也是原版的彩票。

<img src="https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230308_1678283601.png" alt="image-20230308215246189" style="zoom: 50%;" />

<img src="https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230308_1678283603.png" alt="image-20230308215308904" style="zoom: 50%;" />



## Federated Dynamic Sparse Training: Computing Less, Communicating Less, Yet Learning Better  

联合学习 (FL) 可以将机器学习工作负载从云端分配到资源有限的边缘设备。 不幸的是，当前的深度网络不仅对于边缘设备上的推理和训练来说计算量太大，而且对于通过带宽受限的网络进行**更新通信**来说也太大了。 在本文中，我们开发、实施并通过实验验证了一种称为联合动态稀疏训练 (FedDST) 的新型 FL 框架，通过该框架可以部署和训练复杂的神经网络，并显着提高设备上计算和网络内通信的效率。 FedDST 的核心是一个从目标全网络中提取和训练稀疏子网络的动态过程。 有了这个方案，“一箭双雕：”而不是完整的模型，每个客户端都对自己的稀疏网络进行高效训练，并且只有稀疏网络在设备和云端之间传输。 此外，我们的结果表明，与固定的共享稀疏掩码相比，FL 训练期间的动态稀疏性更灵活地适应 FL 代理中的**局部异质性**。 此外，动态稀疏性自然地将“及时自集成效应”引入训练动态中，甚至在密集训练中也能提高 FL 性能。 在现实且具有挑战性的非 i.i.d. 在 FL 设置下，FedDST 在我们的实验中始终优于竞争算法：例如，在非 iid CIFAR-10 上的任何固定上传数据上限下，在给定相同的上传数据上限时，它比 FedAvgM 获得了 10% 的令人印象深刻的准确性优势； 即使 FedAvgM 的上传数据上限是 2 倍，准确度差距仍为 3%，进一步证明了 FedDST 的有效性。 代码位于：https://github.com/bibikar/feddst。

<img src="https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230308_1678283796.png" alt="image-20230308215633234" style="zoom:50%;" /><img src="https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230308_1678283860.png" alt="image-20230308215732872" style="zoom: 80%;" />



## Gradient-Driven Rewards to Guarantee Fairness in Collaborative Machine Learning

在协作机器学习 (CML) 中，多个代理将它们的资源（例如数据）集中在一起以完成共同的学习任务。 在代理人自利而非无私的现实 CML 设置中，他们可能不愿意在没有足够奖励的情况下共享数据或模型信息。 此外，由于代理共享的数据/模型信息可能质量不同，因此设计对他们**公平**的奖励很重要，这样他们就不会感到被剥削或不愿分享。 在本文中，我们采用联邦学习作为 CML 范式，提出了一种新颖的余弦梯度沙普利值（CGSV）来公平地评估每个代理上传的模型参数更新/梯度的预期边际贡献，而不需要辅助验证数据集，并且基于 CGSV，通过将从服务器下载的聚合参数更新/梯度稀疏化作为对每个代理的奖励，设计一种具有公平性保证的新型训练时间梯度奖励机制，使其产生的质量与代理上传的参数更新/梯度的质量相当。 我们在公平性、预测性能和时间开销方面凭经验证明了我们的公平梯度奖励机制在多个基准数据集上的有效性。

<img src="https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230310_1678459499.png" alt="image-20230308215933939" style="zoom:67%;" />



## HETEROFL: COMPUTATION AND COMMUNICATION EFFICIENT FEDERATED LEARNING FOR HETEROGENEOUS CLIENTS

联合学习 (FL) 是一种在分布在大量可能异构的客户端（例如手机和物联网设备）上的私有数据上训练机器学习模型的方法。 在这项工作中，我们提出了一个名为 HeteroFL 的新联邦学习框架，以解决配备非常不同**的计算和通信能力的异构客户端**。 我们的解决方案可以训练具有不同计算复杂性的异构本地模型，并且仍然可以生成单一的全局推理模型。 我们的方法首次挑战了现有工作的基本假设，即局部模型必须与全局模型共享相同的架构。 我们展示了几种增强 FL 训练和进行广泛实证评估的策略，包括三个数据集上三个模型架构的五个计算复杂度级别。 我们表明，根据客户端的能力自适应地分布子网在计算和通信方面都是高效的。 我们的代码可在此处获得。



## Expanding the Reach of Federated Learning by Reducing Client Resource Requirements

异构边缘网络上的通信是联邦学习 (FL) 的基本瓶颈，限制了模型容量和用户参与。 为了解决这个问题，我们引入了两种**降低通信成本**的新策略：（1）对发送服务器到客户端的全局模型使用有损压缩； (2) Federated Dropout，它允许用户在全局模型的较小子集上进行有效的本地训练，还可以减少客户端到服务器的通信和本地计算。 我们凭经验表明，这些策略与现有的客户端到服务器通信的压缩方法相结合，共同将服务器到客户端的通信减少了 14 倍，本地计算减少了 1.7 倍，而本地计算减少了 28 倍 上传通信，所有这些都不会降低最终模型的质量。 因此，我们全面减少了 FL 对客户端设备资源的影响，允许训练更高容量的模型，并覆盖更多样化的用户群。

<img src="https://raw.githubusercontent.com/ailianligit/ailianligit.github.io/main/images/202303/20230310_1678459505.png" alt="image-20230308221048136" style="zoom:67%;" />