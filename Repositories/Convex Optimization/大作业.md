一、考虑一个10节点的分布式系统。节点$i$有线性测量$b_i=A_ix+e_i$，其中$b_i$为5维的测量值，$A_i$为5*100维的测量矩阵，$x$为100维的未知稀疏向量且稀疏度为5，$e_i$为5维的测量噪声。从所有$b_i$与$A_i$中恢复$x$的一范数规范化最小二乘模型如下：
$$
\min\frac{1}{2}\lVert{A_1x-b_1}\rVert^2_2+\cdots+\frac{1}{2}\lVert{A_{10}x-b_{10}}\rVert^2_2+p\lVert{x}\rVert_1
$$
其中$p$为非负的正则化参数。请设计下述分布式算法求解该问题：
1、邻近点梯度法；
2、交替方向乘子法；
3、次梯度法；
4、邻近点牛顿法（选做）。
在实验中，设$x$的真值中的非零元素服从均值为0方差为1的高斯分布，$A_i$中的元素服从均值为0方差为1的高斯分布，$e_i$中的元素服从均值为0方差为0.1的高斯分布。对于每种算法，请给出每步计算结果与真值的距离以及每步计算结果与最优解的距离。此外，请讨论正则化参数$p$对计算结果的影响。



1.1 算法设计

1.1.1 邻近点梯度法

将目标函数划分为$S(x)=\frac{1}{2}\sum^{10}_{i=1}\lVert{A_ix-b_i}\rVert^2_2(i=1,\cdots,10)$和$g(x)=p\lVert{x}\rVert_1$，优化问题变形为：
$$
\min S(x)+g(x)
$$
这个形式中$S(x)$可微且容易求导，$g(x)$是不可微函数，因此可以用邻近点梯度法逐步迭代逼近最优解。形式为：
$$
\begin{cases}
x^{k+\frac{1}{2}}=x^k-\alpha\nabla S(x^k)\\
x^{k+1}=\text{argmin}_xg(x)+\frac{1}{2\alpha}\lVert{x-x^{k+\frac{1}{2}}}\rVert^2
\end{cases}
$$
其中，对$S(x)$求梯度：
$$
\nabla S(x)=\sum^{10}_{i=1}A_i^T(A_ix-b_i)
$$
求解$\min p\lVert{x}\rVert_1+\frac{1}{2\alpha}\lVert{x-x^{k+\frac{1}{2}}}\rVert^2=p\sum^{100}_{i=1}|{x_i}|+\frac{1}{2\alpha}\sum^{100}_{i=1}(x_i-x_i^{k+\frac{1}{2}})^2$，可转化为求解$\min p|{x_i}|+\frac{1}{2\alpha}(x_i-x_i^{k+\frac{1}{2}})^2$。可得：
$$
x_i=\begin{cases}
x_i^{k+\frac{1}{2}}-\alpha p,x_i^{k+\frac{1}{2}}\ge\alpha p\\
x_i^{k+\frac{1}{2}}+\alpha p,x_i^{k+\frac{1}{2}}\le\alpha p\\
0,x_i^{k+\frac{1}{2}}\in[-\alpha p,\alpha p]
\end{cases}
$$
因此，邻近点梯度法迭代方程为：
$$
\begin{cases}
x^{k+\frac{1}{2}}=x^k-\alpha\sum^{10}_{i=1}A_i^T(A_ix^k-b_i)\\
x^{k+1}=\text{Proj}[-\alpha p,\alpha p]x^{k+\frac{1}{2}}
\end{cases}
$$



1.1.2 交替方向乘子法

因为交替方向乘子法是有约束算法，因此需要对优化问题进行变换：
$$
\min \frac{1}{2}\sum^{10}_{i=1}\lVert{A_ix_i-b_i}\rVert^2_2+p\lVert{x_0}\rVert_1
$$
约束为$x_i-x_0=0(i=1,\cdots,10)$。可以写出增广拉格朗日函数：
$$
L_c=\frac{1}{2}\sum^{10}_{i=1}\lVert{A_ix_i-b_i}\rVert^2_2+p\lVert{x_0}\rVert_1+\sum^{10}_{i=1}v^T_i(x_i-x_0)+\frac{c}{2}\sum^{10}_{i=1}\lVert{x_i-x_0}\rVert^2_2
$$
交替方向乘子法形式为：
$$
\begin{cases}
x_i^{k+1}=\text{argmin}_{x_i}L_c(x_0^{k},x_1,\cdots,x_{10},v_1^k,\cdots,v_{10}^k)\\
x_0^{k+1}=\text{argmin}_{x_0}L_c(x_0,x_1^{k+1},\cdots,x_{10}^{k+1},v_1^k,\cdots,v_{10}^k)\\
v_i^{k+1}=v_{i}^{k}+c(x_i^{k+1}-x_0^{k+1})
\end{cases}
$$
第一步为：
$$
x_i^{k+1}=\text{argmin}_{x_{i}}\frac{1}{2}\sum^{10}_{i=1}\lVert{A_ix_i-b_i}\rVert^2_2+\sum^{10}_{i=1}{v^k}^T_i(x_i-x_0^k)+\frac{c}{2}\sum^{10}_{i=1}\lVert{x_i-x_0^k}\rVert^2_2=\text{argmin}_{x_{i}}\frac{1}{2}\lVert{A_ix_i-b_i}\rVert^2_2+\frac{c}{2}\lVert{x_i-x_0^k+\frac{v_i^k}{c}}\rVert^2_2
$$
通过使上式一阶梯度为0，可得：
$$
x_i^{k+1}=(A_i^TA_i+cI)^{-1}(A_i^Tb_i+cx_0^k-v_i^k)
$$
第二步为：
$$
x_0^{k+1}=\text{argmin}_{x_{0}}p\lVert{x_0}\rVert_1+\sum^{10}_{i=1}{v^k}^T_i(x_i^{k+1}-x_0)+\frac{c}{2}\sum^{10}_{i=1}\lVert{x_i^{k+1}-x_0}\rVert^2_2=\text{argmin}_{x_{0}}p\lVert{x_0}\rVert_1+\frac{c}{2}\sum_{i=1}^{10}\lVert{x_0-x_i^{k+1}-\frac{v_i^k}{c}}\rVert^2_2
$$
因为式中同时包含可微项和不可微项，因此可以使用邻近点梯度法求解$x_0^{k+1}$，即：
$$
\begin{cases}
x_0^{k+\frac{1}{2}}=x_0^k-\frac{\alpha}{10}\sum^{10}_{i=1}(x_i^{k+1}+\frac{v_i^k}{c})\\
x_0^{k+1}=\text{Proj}[-\alpha p,\alpha p]x_0^{k+\frac{1}{2}}
\end{cases}
$$
第三步为：
$$
v_i^{k+1}=v_{i}^{k}+c(x_i^{k+1}-x_0^{k+1})
$$



1.1.3 次梯度法

将目标函数划分为$S(x)=\frac{1}{2}\sum^{10}_{i=1}\lVert{A_ix-b_i}\rVert^2_2(i=1,\cdots,10)$和$g(x)=p\lVert{x}\rVert_1$，优化问题变形为：
$$
\min S(x)+g(x)
$$
这个形式中$S(x)$可微且容易求导，$g(x)$是不可微函数，令其次梯度为$G(x)$，因此可以用次梯度法逐步迭代逼近最优解。形式为：
$$
x^{k+1}=x^k-\alpha\sum^{10}_{i=1}A_i^T(A_ix^k-b_i)-\alpha G(x^k)
$$
其中：
$$
G(x_i^k)=
\begin{cases}
1,x_i^k>0\\
-1,x_i^k<0\\
0,x_i^k=0\\
\end{cases}
$$



1.2 数值实验

经过参数调试，选择的超参数有步长$\alpha=0.01$，$p=100$，交替方向乘子法中的参数$c=100$。

$x$的真值中的非零元素在均值为0，方差为1的高斯分布上采样。下图显示了每步计算结果与真值的距离。

【图1】

经过多次实验，可以发现次梯度方法（SGM）在固定步长下与真值的距离无法收敛，交替方向乘子法（ADMM）因为需要初始化的参数较多，前5步的结果较差，最终的精度略优于次梯度法，但不如邻近点梯度法（PGM）。

在收敛速度方面，更接近真值的邻近点梯度法收敛速度也更快，平均在3步左右能收敛，交替方向乘子法平均在5步左右能收敛，而次梯度方法无法收敛。

因为目标函数中含有不可微项，不易求解问题的精确解，因此考虑用2-范数正则项替代1-范数正则项，求解下面近似问题的最优解：
$$
\min\frac{1}{2}\sum^{10}_{i=1}\lVert{A_ix-b_i}\rVert^2_2+\frac{1}{2}p\lVert{x}\rVert^2_2
$$
对目标函数求梯度即可得到解析解形式：
$$
x=(\sum^{10}_{i=1}A_i^TA_i+pI)^{-1}(\sum^{10}_{i=1}A_i^Tb)
$$

下图显示了每步计算结果与近似最优解的距离。

【图2】

经过多次实验，可以发现三种方法的收敛情况与前一步的收敛情况相似，交替方向乘子法（ADMM）的精度优于次梯度法（SGM），稍劣于邻近点梯度法（PGM），但交替方向乘子法的计算结果与近似最优解之间的距离小于其与真值之间的距离。

在收敛速度方面，邻近点梯度法收敛速度快于交替方向乘子法，而次梯度方法无法收敛。

对于相同的$A$、$x$的真值、$e$、步长$\alpha$，$p$取1到200，因为较小的$p$值可能导致过大的距离，因此对所有距离取$\log$，图像本质上是对数距离关于$p$值的变化情况。

下图显示了不同$p$值在20次迭代后计算结果与真值的距离。

【图3】

经过多次实验，可以发现在$p$值较小时，邻近点梯度法（PGM）与真值距离相差多个指数级，在$p$为20左右时，达到最小距离，此时的计算结果与真值几乎在同一个指数级，此后$p$值增大，距离缓慢增大，但仍是三种方法中距离真值最近的。

交替方向乘子法（AGMM）在$p$值为10左右便达到了最小的距离，此时计算结果与真值的距离在2个指数级左右。

次梯度法在前面的测试中未收敛，而在该图以及后面与最优解距离的曲线图中可以看出$p$为7左右效果较好。为此进行测试，发现参数$p=7$时次梯度法收敛，而其他方法发散。

【图5】

下图显示了不同$p$值在20次迭代后计算结果与近似最优解的距离。

【图4】

三种方法的精度随$p$值的变化趋势与图3相似，但是在交替方向乘子法和邻近点梯度法中，精度随$p$值增大而继续减小。交替方向乘子法计算结果与近似最优解的距离已经在同一个数量级，而邻近点梯度法的精度更高。

值得一提的是在交替方向乘子法中，调整参数$c$主要影响到的是前几步的精度，当$c=0.1$时，计算结果与最优解的最大距离可以达到300多，而当$c=1$时，最大距离为40，当$c=10$时，最大距离为30。



1.3 结果分析

本节对上述结果作简要的分析。

由理论分析可知，在固定步长的情况下，次梯度法是次线性收敛的，甚至可能无法保证算法收敛。在上述的大部分实验中都无法使次梯度法收敛，证实了这一说法。由于邻近点梯度法在中心节点，也就是算法的第二步中有求邻近点投影的过程，这是一个求最优解的步骤，因此邻近点梯度法的收敛性质更好。此外，邻近点梯度法的收敛性质也比单纯使用次梯度法要好，收敛速度更快。

对于给定的目标函数，随着$p$值的增大，问题的最优解更接近于0。在实验中可以发现，交替方向乘子法在$p\ge10$时的结果接近最优解，邻近点梯度法在$p\ge20$时的结果接近最优解，证实了这一说法。



二、请设计下述算法，求解MNIST数据集上的分类问题：
1、梯度下降法；
2、随机梯度法。
对于每种算法，请给出每步计算结果在测试集上所对应的分类精度。对于随机梯度法，请讨论mini-batch大小的影响。可采用Logistic Regression模型或神经网络模型。



2.1 算法设计

2.1.1 Logistic Regression模型

逻辑回归模型是一种单层神经网络，用下面的形式表达输入和输出的关系：
$$
o=Wx+b
$$
因为输出得到的$o$落在实数域中，因此可以使用softmax函数确保输出非负且总和为1，从而使输出能够表示每个分类的概率。
$$
\widehat{y}=\text{softmax}(o),\widehat{y}_j=\frac{\exp(o_j)}{\sum_k\exp(o_k)}
$$
在参数优化过程中，模型将使用梯度下降法和随机梯度法对参数进行优化。在此之前，需要使用逻辑回归模型中常用的交叉熵作为损失函数。
$$
l(y,\widehat{y})=-\sum_jy_j\log\widehat{y}_j
$$
将该式对$o_j$微分：
$$
\partial_{o_j}l(y,\widehat{y})=\frac{\exp(o_j)}{\sum_k\exp(o_k)}-y_j=\text{softmax}(o)_j-y_j
$$
利用这个微分结果就可以对参数$W$和$b$作梯度下降法和随机梯度法的优化。



2.1.2 神经网络模型

因为MNIST数据集是一个二维图像数据集，因此可以利用卷积神经网络在处理计算机视觉任务上的优势，来对数据集进行训练和测试。

图像的大小是$28*28$。首先通过一个10通道的卷积核为$5*5$的卷积层，输出大小为$10*24*24$。然后经过一个滑动窗口为$2*2$的最大池化层，输出大小为$10*12*12$。接着经过一个20通道的卷积核为$5*5$的卷积层，输出大小为$20*8*8$。最后经过一个全连接层，分别对应10个分类输出。

在每一个卷积层后所做的非线性化操作是ReLU函数，这种激活函数的优势是梯度好求，从而使得网络训练更快，此外还可以防止梯度消失。
$$
f(x)=\begin{cases}
x,x>0\\
0,\text{otherwise}
\end{cases}
$$
在全连接层后需要使用softmax函数将得到的结果从实数域变换到$[0,1]$，且各个维度之和为1，实现了将输出变为概率分布的功能，从而得到预测结果。

在反向传播算法中，损失函数使用的是负对数似然损失函数，在PyTorch中对应的是NLLLoss方法。模型将使用梯度下降法和随机梯度法对参数进行优化。



2.2 数值实验

下图显示了逻辑回归模型使用梯度下降法时每步计算结果在测试集上所对应的分类精度，此时使用的学习率是0.1。随着迭代步数的增加，分类精度增加先快后慢。

【图8】

下图显示了逻辑回归模型使用随机梯度法时每步计算结果在测试集上所对应的分类精度，此时使用的学习率是0.1，batch size为64。batch size为64时的随机梯度法每步的分类精度都比梯度下降法要好。

【图6】

下图显示了CNN模型使用梯度下降法时每步计算结果在测试集上所对应的分类精度，此时使用的学习率是0.01。随着迭代步数的增加，分类精度增加先快后慢。

【图9】

下图显示了CNN模型使用随机梯度法时每步计算结果在测试集上所对应的分类精度，此时使用的学习率是0.01，batch size为64。batch size为64时的随机梯度法每步的分类精度都比梯度下降法要好。此外，卷积神经网络的分类精度要比简单的逻辑回归模型好。

【图7】

在保证运行环境相似和其他超参数完全相同的情况下，研究不同batch size下逻辑回归模型平均每次迭代的运行时间。可以看出，随着$p=\text{batch size}$的增大，平均每次迭代运行时间更短，但当batch size增大到一定值时下降缓慢。

【图10】

不同batch size下CNN模型平均每次迭代的运行时间变化趋势与逻辑回归模型相似，但CNN模型平均每次迭代所需的时间更长。

【图12】

在保证运行环境相似和其他超参数完全相同的情况下，研究不同batch size下逻辑回归模型迭代10次后的分类精度。可以看出，随着$p=\text{batch size}$的增大，测试集分类精度先增大后减小，说明收敛速度先变快后变慢，在batch size为64和128时分类精度最高。

【图11】

CNN模型在小batch size情况下也能保持较好的分类精度，随着$p=\text{batch size}$的增大，测试集分类精度逐渐减小。

【图13】



2.3 结果分析

因为深度神经网络模型引入了更多的参数和非线性操作，使得CNN模型的分类精度显著高于逻辑回归模型。

随机梯度法每次迭代随机抽取数据集的一小部分，因此会导致抽样数据不一定完美符合完整数据的分布。小批量数据的方差能够帮助非凸的深度学习任务跳出局部最优解，实现更好的分类精度和泛化性能。

随着batch size的增大，由于内存利用率提高、矩阵乘法并行效率提高，实验的结果也表明了每步迭代的用时会随batch size增大而减小。此外，由于batch size越大，梯度下降的方向越准确，因此在某种程度上会减小精度的振荡。

然而，由于batch size下降到一定程度时，下降方向基本不再变化，此时大批量导致模型泛化性能下降的缺点显现出来，导致分类精度降低。



附录一：问题一的Python实现代码

```python
import numpy as np
from random import sample
import matplotlib.pyplot as plt

p = 100    #non-negetive
A = np.random.normal(0, 1, size=(10, 5, 100))
x = np.zeros(shape=(100, 1))
for i in sample(range(0, 100), 5):
    x[i] = np.random.normal(0, 1)
e = np.random.normal(0, np.sqrt(0.1), size=(10, 5, 1))
b = np.zeros(shape=(10, 5, 1))
for i in range(10):
    b[i] = np.dot(A[i], x) + e[i]

tmp1 = np.zeros(shape=(100, 100))
tmp2 = np.zeros(shape=(100, 1))
for i in range(10):
    tmp1 += np.dot(A[i].T, A[i])
    tmp2 += np.dot(A[i].T, b[i])
optim = np.dot(np.linalg.inv(tmp1+p*np.identity(100)), tmp2)

# proximal gradient method
def PGM(x0, epoch, lr):
    real_dist = np.zeros(shape=(epoch+1, 1))
    opti_dist = np.zeros(shape=(epoch+1, 1))
    xk = x0.copy()
    real_dist[0] = np.linalg.norm(x0-x)
    opti_dist[0] = np.linalg.norm(x0-optim)
    for i in range(epoch):
        xmid = xk.copy()
        for j in range(10):
            xmid -= lr * np.dot(A[j].T, np.dot(A[j], xk)-b[j])
        for j in range(100):
            if xmid[j] >= lr * p:
                xk[j] = xmid[j] - lr * p
            elif xmid[j] <= -lr * p:
                xk[j] = xmid[j] + lr * p
            else:
                xk[j] = 0
        real_dist[i+1] = np.linalg.norm(xk-x)
        opti_dist[i+1] = np.linalg.norm(xk-optim)
    return real_dist, opti_dist

# alternating direction method of multipliers
def ADMM(x0, xi, vi, epoch, lr, c):
    real_dist = np.zeros(shape=(epoch+1, 1))
    opti_dist = np.zeros(shape=(epoch+1, 1))
    x0_k = x0.copy()
    xi_k = xi.copy()
    vi_k = vi.copy()
    real_dist[0] = np.linalg.norm(x0-x)
    opti_dist[0] = np.linalg.norm(x0-optim)
    B = np.zeros(shape=(10, 100, 100))
    for i in range(10):
        B[i] = np.linalg.inv(np.dot(A[i].T, A[i])+c*np.identity(100))
    for i in range(epoch):
        for j in range(10):
            xi_k[j] = np.dot(B[j], np.dot(A[j].T, b[j])+c*x0_k-vi_k[j])
        x0_mid = x0_k.copy()
        for j in range(10):
            x0_mid -= lr / 10 * (xi_k[j] + vi_k[j] / c)
        for j in range(100):
            if x0_mid[j] >= lr * p:
                x0_k[j] = x0_mid[j] - lr * p
            elif x0_mid[j] <= -lr * p:
                x0_k[j] = x0_mid[j] + lr * p
            else:
                x0_k[j] = 0
        for j in range(10):
            vi_k[j] += c * (xi_k[j] - x0_k)
        real_dist[i+1] = np.linalg.norm(xi_k-x)
        opti_dist[i+1] = np.linalg.norm(xi_k-optim)
    return real_dist, opti_dist

# subgradient method
def SGM(x0, epoch, lr):
    real_dist = np.zeros(shape=(epoch+1, 1))
    opti_dist = np.zeros(shape=(epoch+1, 1))
    xk = x0.copy()
    real_dist[0] = np.linalg.norm(x0-x)
    opti_dist[0] = np.linalg.norm(x0-optim)
    for i in range(epoch):
        xtmp = xk.copy()
        for j in range(10):
            xk -= lr * np.dot(A[j].T, np.dot(A[j], xk)-b[j])
        for j in range(100):
            if xtmp[j] > 0:
                xk[j] = xk[j] - lr * p
            elif xtmp[j] < 0:
                xk[j] = xk[j] + lr * p
        real_dist[i+1] = np.linalg.norm(xk-x)
        opti_dist[i+1] = np.linalg.norm(xk-optim)
    return real_dist, opti_dist

epoch = 50
lr = 0.01
x0 = np.random.normal(0, 1, size=(100, 1))
xi = np.random.normal(0, 1, size=(10, 100, 1))
vi = np.random.normal(0, 1, size=(10, 100, 1))
PGMrd, PGMod = PGM(x0, epoch, lr)
ADMMrd, ADMMod = ADMM(x0, xi, vi, epoch, lr, c=10)
SGMrd, SGMod = SGM(x0, epoch, lr)
```



附录二：问题二的逻辑回归的Python实现代码

```python
import torch
import torchvision
from torch import nn
from IPython import display
from torchvision.transforms import ToTensor
import matplotlib.pyplot as plt
import numpy as np
import time

def accuracy(y_hat, y):
    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:
        y_hat = y_hat.argmax(axis=1)
    cmp = y_hat.type(y.dtype) == y
    return float(cmp.type(y.dtype).sum())

def train_epoch(net, train_loader, loss, updater):
    if isinstance(net, torch.nn.Module):
        net.train()
    total_loss, acc, count = 0, 0, 0
    for X, y in train_loader:
        X = X.to(device)
        y = y.to(device)
        y_hat = net(X)
        l = loss(y_hat, y)
        if isinstance(updater, torch.optim.Optimizer):
            updater.zero_grad()
            l.sum().backward()
            updater.step()
        else:
            l.sum().backward()
            updater(X.shape[0])
        total_loss += float(l.sum())
        acc += accuracy(y_hat, y)
        count += y.numel()
    return total_loss/count, acc/count

def evaluate_accuracy(net, data_iter, loss):
    if isinstance(net, torch.nn.Module):
        net.eval()
    total_loss, acc, count = 0, 0, 0
    with torch.no_grad():
        for X, y in data_iter:
            X = X.to(device)
            y = y.to(device)
            y_hat = net(X)
            total_loss += loss(y_hat, y)
            acc += accuracy(y_hat, y)
            count += y.numel()
    return total_loss/count, acc/count

def train(net, train_loader, test_loader, loss, num_epochs, updater):
    res = {'train_loss' : [], 'train_acc': [], 'val_loss': [], 'val_acc': []}
    for ep in range(num_epochs):
        tl, ta = train_epoch(net, train_loader, loss, updater)
        vl, va = evaluate_accuracy(net, test_loader, loss)
        print(f"Epoch {ep:2}, Train acc={ta:.3f}, Val acc={va:.3f}, Train loss={tl:.3f}, Val loss={vl:.3f}")
        res['train_loss'].append(tl)
        res['train_acc'].append(ta)
        res['val_loss'].append(vl)
        res['val_acc'].append(va)
    return res

device = "cuda" if torch.cuda.is_available() else "cpu"
print("Using {} device".format(device))

batch_size = 64
data_train = torchvision.datasets.MNIST('./data', download=True, train=True, transform=ToTensor())
data_test = torchvision.datasets.MNIST('./data', download=True, train=False, transform=ToTensor())
train_loader = torch.utils.data.DataLoader(data_train, batch_size, pin_memory=True)
test_loader = torch.utils.data.DataLoader(data_test, batch_size, pin_memory=True)

net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10)).to(device)
def init_weights(m):
    if type(m) == nn.Linear:
        nn.init.normal_(m.weight, std=0.01)
net.apply(init_weights)

loss = nn.CrossEntropyLoss()
trainer = torch.optim.SGD(net.parameters(), lr=0.1)
num_epochs = 21
start = time.time()
res = train(net, train_loader, test_loader, loss, num_epochs, trainer)
end = time.time()
print('Running time: %s Seconds'%(end-start))
```



附录三：问题二的卷积神经网络的Python实现代码

```python
import torch
import torch.nn as nn
import torchvision
import matplotlib.pyplot as plt
from torchvision.transforms import ToTensor
import matplotlib.pyplot as plt
import numpy as np
import time

class MultiLayerCNN(nn.Module):
    def __init__(self):
        super(MultiLayerCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 10, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(10, 20, 5)
        self.fc = nn.Linear(320, 10)

    def forward(self, x):
        x = self.pool(nn.functional.relu(self.conv1(x)))
        x = self.pool(nn.functional.relu(self.conv2(x)))
        x = x.view(-1, 320)
        x = nn.functional.log_softmax(self.fc(x),dim=1)
        return x

def train_epoch(net, dataloader, optimizer, loss_fn):
    net.train()
    total_loss, acc, count = 0, 0, 0
    for features, labels in dataloader:
        features = features.to(device)
        labels = labels.to(device)
        optimizer.zero_grad()
        out = net(features)
        loss = loss_fn(out, labels)
        loss.backward()
        optimizer.step()
        total_loss += loss
        _, predicted = torch.max(out,1)
        acc += (predicted==labels).sum()
        count += len(labels)
    return total_loss.item()/count, acc.item()/count

def validate(net, dataloader, loss_fn):
    net.eval()
    count, acc, loss = 0, 0, 0
    with torch.no_grad():
        for features, labels in dataloader:
            features = features.to(device)
            labels = labels.to(device)
            out = net(features)
            loss += loss_fn(out, labels) 
            pred = torch.max(out, 1)[1]
            acc += (pred==labels).sum()
            count += len(labels)
    return loss.item()/count, acc.item()/count

def train(net, train_loader, test_loader, optimizer, epochs, loss_fn):
    res = {'train_loss' : [], 'train_acc': [], 'val_loss': [], 'val_acc': []}
    for ep in range(epochs):
        tl, ta = train_epoch(net, train_loader, optimizer, loss_fn)
        vl, va = validate(net, test_loader, loss_fn)
        print(f"Epoch {ep:2}, Train acc={ta:.3f}, Val acc={va:.3f}, Train loss={tl:.3f}, Val loss={vl:.3f}")
        res['train_loss'].append(tl)
        res['train_acc'].append(ta)
        res['val_loss'].append(vl)
        res['val_acc'].append(va)
    return res

device = "cuda" if torch.cuda.is_available() else "cpu"
print("Using {} device".format(device))
net = MultiLayerCNN().to(device)
batch_size = 46
data_train = torchvision.datasets.MNIST('./data', download=True, train=True, transform=ToTensor())
data_test = torchvision.datasets.MNIST('./data', download=True, train=False, transform=ToTensor())
train_loader = torch.utils.data.DataLoader(data_train, batch_size, pin_memory=True)
test_loader = torch.utils.data.DataLoader(data_test, batch_size, pin_memory=True)
lr = 0.01
optimizer = torch.optim.SGD(net.parameters(), lr=lr)
epochs = 21
loss_fn = nn.NLLLoss()
start = time.time()
res = train(net, train_loader, test_loader, optimizer, epochs, loss_fn)
end = time.time()
print('Running time: %s Seconds'%(end-start))
print(res['val_acc'][-1])
```